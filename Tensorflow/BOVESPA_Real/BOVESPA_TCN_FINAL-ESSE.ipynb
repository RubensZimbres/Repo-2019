{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe39cb162e8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_datareader import data\n",
    "#pip install pandas-datareader\n",
    "\n",
    "stock = 'VALE3.SA'\n",
    "source = 'yahoo'\n",
    "\n",
    "# Set date range (Google went public August 19, 2004)\n",
    "start = datetime.datetime(2005, 8, 19)\n",
    "end = datetime.datetime(2019, 8, 8)\n",
    "\n",
    "# Collect Google stock data\n",
    "goog_df = data.DataReader(stock, source, start, end)\n",
    "\n",
    "dataset = goog_df['Adj Close']\n",
    "print(len(dataset))\n",
    "goog_df['Adj Close'].plot(kind='line', grid=True, title='GOOG Adjusted Closes, IPO through 2016')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.18000030517578"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goog_df['Adj Close'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3422 35\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "\n",
    "dataset = np.array(dataset.astype('float32')).reshape(-1,1)\n",
    "\n",
    "def norm(x):\n",
    "    return (x-np.min(x))/(np.max(x)-np.min(x))\n",
    "\n",
    "#dataset=norm(dataset)\n",
    "\n",
    "look_back=4\n",
    "np.random.seed(7)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "train_size = int(len(dataset) * 0.99)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print(len(train), len(test))\n",
    "\n",
    "def create_dataset(dataset, look_back=look_back):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn np.array(dataX), np.array(dataY)\n",
    "\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "trainX\n",
    "\n",
    "trainY = trainY.reshape(len(trainY), 1)\n",
    "testY = testY.reshape(len(testY), 1)\n",
    "trainY\n",
    "\n",
    "X0=trainX\n",
    "Y0=trainY\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rubensvectomobile_gmail_com/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py:1735: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense/BiasAdd:0\", shape=(?, 4, 1), dtype=float32)\n",
      "All parameters: 328200.0\n",
      "Trainable parameters: 109446\n"
     ]
    }
   ],
   "source": [
    "tfd = tfp.distributions\n",
    "\n",
    "class TemporalConvNet(tf.layers.Layer):\n",
    "    def __init__(self, num_channels, kernel_size=2, dropout=0.2,\n",
    "                 trainable=True, name=None, dtype=None, \n",
    "                 activity_regularizer=None, **kwargs):\n",
    "        super(TemporalConvNet, self).__init__(\n",
    "            trainable=trainable, dtype=dtype,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            name=name, **kwargs\n",
    "        )\n",
    "        self.layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            out_channels = num_channels[i]\n",
    "            self.layers.append(\n",
    "                TemporalBlock(out_channels, kernel_size, strides=1, dilation_rate=dilation_size,\n",
    "                              dropout=dropout, name=\"tblock_{}\".format(i))\n",
    "            )\n",
    "    \n",
    "    def call(self, inputs, training=True):\n",
    "        outputs = inputs\n",
    "        for layer in self.layers:\n",
    "            outputs = layer(outputs, training=training)\n",
    "        return outputs\n",
    "\n",
    "learning_rate = 0.001\n",
    "display_step = 10\n",
    "num_input = 1\n",
    "num_hidden = 35\n",
    "num_classes = 1\n",
    "\n",
    "dropout = 0\n",
    "kernel_size = 8\n",
    "levels = 6\n",
    "\n",
    "class CausalConv1D(tf.layers.Conv1D):\n",
    "    def __init__(self, filters,\n",
    "               kernel_size,\n",
    "               strides=1,\n",
    "               dilation_rate=1,\n",
    "               activation=None,\n",
    "               use_bias=True,\n",
    "               kernel_initializer=None,\n",
    "               bias_initializer=tf.zeros_initializer(),\n",
    "               kernel_regularizer=None,\n",
    "               bias_regularizer=None,\n",
    "               activity_regularizer=None,\n",
    "               kernel_constraint=None,\n",
    "               bias_constraint=None,\n",
    "               trainable=True,\n",
    "               name=None,\n",
    "               **kwargs):\n",
    "        super(CausalConv1D, self).__init__(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding='valid',\n",
    "            data_format='channels_last',\n",
    "            dilation_rate=dilation_rate,\n",
    "            activation=activation,\n",
    "            use_bias=use_bias,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=bias_regularizer,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=bias_constraint,\n",
    "            trainable=trainable,\n",
    "            name=name, **kwargs\n",
    "        )\n",
    "       \n",
    "    def call(self, inputs):\n",
    "        padding = (self.kernel_size[0] - 1) * self.dilation_rate[0]\n",
    "        inputs = tf.pad(inputs, tf.constant([(0, 0,), (1, 0), (0, 0)]) * padding)\n",
    "        return super(CausalConv1D, self).call(inputs)\n",
    "\n",
    "\n",
    "\n",
    "class TemporalBlock(tf.layers.Layer):\n",
    "    def __init__(self, n_outputs, kernel_size, strides, dilation_rate, dropout=0.2, \n",
    "                 trainable=True, name=None, dtype=None, \n",
    "                 activity_regularizer=None, **kwargs):\n",
    "        super(TemporalBlock, self).__init__(\n",
    "            trainable=trainable, dtype=dtype,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            name=name, **kwargs\n",
    "        )        \n",
    "        self.dropout = dropout\n",
    "        self.n_outputs = n_outputs\n",
    "        self.conv1 = CausalConv1D(\n",
    "            n_outputs, kernel_size, strides=strides, \n",
    "            dilation_rate=dilation_rate, activation=tf.nn.relu, \n",
    "            name=\"conv1\")\n",
    "        self.conv2 = CausalConv1D(\n",
    "            n_outputs, kernel_size, strides=strides, \n",
    "            dilation_rate=dilation_rate, activation=tf.nn.relu, \n",
    "            name=\"conv2\")\n",
    "        self.down_sample = None\n",
    "\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        channel_dim = 2\n",
    "        self.dropout1 = tf.layers.Dropout(self.dropout, [tf.constant(1), tf.constant(1), tf.constant(self.n_outputs)])\n",
    "        self.dropout2 = tf.layers.Dropout(self.dropout, [tf.constant(1), tf.constant(1), tf.constant(self.n_outputs)])\n",
    "        if input_shape[channel_dim] != self.n_outputs:\n",
    "            self.down_sample = tf.layers.Dense(self.n_outputs, activation=None)\n",
    "    \n",
    "    def call(self, inputs, training=True):\n",
    "        x = self.conv1(inputs)\n",
    "        x = tf.contrib.layers.layer_norm(x)\n",
    "        x = self.dropout1(x, training=training)\n",
    "        x = self.conv2(x)\n",
    "        x = tf.contrib.layers.layer_norm(x)\n",
    "        x = self.dropout2(x, training=training)\n",
    "        #x = tfp.layers.DistributionLambda(make_distribution_fn=lambda t: tfd.Normal(loc=t, scale=1))(x)\n",
    "        #x = tf.contrib.layers.layer_norm(x)\n",
    "        #x = tf.layers.dense(inputs=x,units=3)\n",
    "        if self.down_sample is not None:\n",
    "          inputs = self.down_sample(inputs)\n",
    "        return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    tf.set_random_seed(2)\n",
    "    \n",
    "    X = tf.placeholder(\"float\", [None, look_back,1])\n",
    "    Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "    is_training = tf.placeholder(\"bool\")\n",
    "    \n",
    "    logits = tf.layers.dense(\n",
    "        TemporalConvNet([num_hidden] * levels, kernel_size, dropout)(\n",
    "            X, training=is_training),\n",
    "        num_classes, activation=None, \n",
    "        kernel_initializer=tf.glorot_uniform_initializer()\n",
    "    )\n",
    "    print(logits)\n",
    "\n",
    "    mm,_=tf.nn.moments(tf.reshape(tf.nn.relu(logits),[-1,look_back]),axes=[1])\n",
    "    prediction=tf.nn.relu(logits)\n",
    "    \n",
    "    prediction2 = tf.reshape(tf.cast(mm,tf.float32),[-1,1])\n",
    "    \n",
    "    loss_op = tf.reduce_mean(tf.losses.mean_squared_error(\n",
    "        labels=Y,predictions=prediction2))\n",
    "    \n",
    "    accuracy=1-tf.sqrt(loss_op)\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    print(\"All parameters:\", np.sum([np.product([xi.value for xi in x.get_shape()]) for x in tf.global_variables()]))\n",
    "    print(\"Trainable parameters:\", np.sum([np.product([xi.value for xi in x.get_shape()]) for x in tf.trainable_variables()]))\n",
    "\n",
    "def next_batch(num, data, labels):\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "    return np.asarray(data_shuffle).astype(np.float32), np.asarray(labels_shuffle).astype(np.float32)\n",
    "\n",
    "log_dir = \"/home/rubensvectomobile/BOVESPA/\"\n",
    "tb_writer = tf.summary.FileWriter(log_dir, graph)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "best_val_acc = 0.93\n",
    "\n",
    "training_epochs = 8000\n",
    "batch_size = int(trainX.shape[0]/4)\n",
    "\n",
    "\n",
    "X0=X0.reshape(-1,look_back,1)\n",
    "testX=testX.reshape(-1,look_back,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 0.1020, Training Accuracy= 0.6806, Test Accuracy= 0.3538\n",
      "Step 10, Minibatch Loss= 0.0274, Training Accuracy= 0.8345, Test Accuracy= 0.5984\n",
      "Step 20, Minibatch Loss= 0.0091, Training Accuracy= 0.9045, Test Accuracy= 0.8300\n",
      "Step 30, Minibatch Loss= 0.0032, Training Accuracy= 0.9435, Test Accuracy= 0.8706\n",
      "Step 40, Minibatch Loss= 0.0019, Training Accuracy= 0.9563, Test Accuracy= 0.9261\n",
      "Step 50, Minibatch Loss= 0.0010, Training Accuracy= 0.9685, Test Accuracy= 0.9663\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 60, Minibatch Loss= 0.0009, Training Accuracy= 0.9703, Test Accuracy= 0.9639\n",
      "Step 70, Minibatch Loss= 0.0006, Training Accuracy= 0.9754, Test Accuracy= 0.9685\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 80, Minibatch Loss= 0.0006, Training Accuracy= 0.9747, Test Accuracy= 0.9733\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 90, Minibatch Loss= 0.0007, Training Accuracy= 0.9731, Test Accuracy= 0.9722\n",
      "Step 100, Minibatch Loss= 0.0008, Training Accuracy= 0.9716, Test Accuracy= 0.9592\n",
      "Step 110, Minibatch Loss= 0.0005, Training Accuracy= 0.9767, Test Accuracy= 0.9727\n",
      "Step 120, Minibatch Loss= 0.0006, Training Accuracy= 0.9765, Test Accuracy= 0.9728\n",
      "Step 130, Minibatch Loss= 0.0005, Training Accuracy= 0.9783, Test Accuracy= 0.9744\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 140, Minibatch Loss= 0.0013, Training Accuracy= 0.9643, Test Accuracy= 0.9463\n",
      "Step 150, Minibatch Loss= 0.0008, Training Accuracy= 0.9721, Test Accuracy= 0.9592\n",
      "Step 160, Minibatch Loss= 0.0004, Training Accuracy= 0.9804, Test Accuracy= 0.9784\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 170, Minibatch Loss= 0.0011, Training Accuracy= 0.9669, Test Accuracy= 0.9500\n",
      "Step 180, Minibatch Loss= 0.0020, Training Accuracy= 0.9549, Test Accuracy= 0.9344\n",
      "Step 190, Minibatch Loss= 0.0004, Training Accuracy= 0.9792, Test Accuracy= 0.9786\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 200, Minibatch Loss= 0.0006, Training Accuracy= 0.9749, Test Accuracy= 0.9779\n",
      "Step 210, Minibatch Loss= 0.0004, Training Accuracy= 0.9794, Test Accuracy= 0.9758\n",
      "Step 220, Minibatch Loss= 0.0004, Training Accuracy= 0.9799, Test Accuracy= 0.9788\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 230, Minibatch Loss= 0.0005, Training Accuracy= 0.9775, Test Accuracy= 0.9766\n",
      "Step 240, Minibatch Loss= 0.0006, Training Accuracy= 0.9757, Test Accuracy= 0.9742\n",
      "Step 250, Minibatch Loss= 0.0005, Training Accuracy= 0.9788, Test Accuracy= 0.9733\n",
      "Step 260, Minibatch Loss= 0.0006, Training Accuracy= 0.9755, Test Accuracy= 0.9742\n",
      "Step 270, Minibatch Loss= 0.0004, Training Accuracy= 0.9792, Test Accuracy= 0.9773\n",
      "Step 280, Minibatch Loss= 0.0004, Training Accuracy= 0.9802, Test Accuracy= 0.9795\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 290, Minibatch Loss= 0.0007, Training Accuracy= 0.9740, Test Accuracy= 0.9575\n",
      "Step 300, Minibatch Loss= 0.0047, Training Accuracy= 0.9313, Test Accuracy= 0.8840\n",
      "Step 310, Minibatch Loss= 0.0012, Training Accuracy= 0.9658, Test Accuracy= 0.9528\n",
      "Step 320, Minibatch Loss= 0.0006, Training Accuracy= 0.9764, Test Accuracy= 0.9716\n",
      "Step 330, Minibatch Loss= 0.0004, Training Accuracy= 0.9799, Test Accuracy= 0.9765\n",
      "Step 340, Minibatch Loss= 0.0003, Training Accuracy= 0.9814, Test Accuracy= 0.9793\n",
      "Step 350, Minibatch Loss= 0.0003, Training Accuracy= 0.9823, Test Accuracy= 0.9793\n",
      "Step 360, Minibatch Loss= 0.0004, Training Accuracy= 0.9790, Test Accuracy= 0.9642\n",
      "Step 370, Minibatch Loss= 0.0010, Training Accuracy= 0.9691, Test Accuracy= 0.9429\n",
      "Step 380, Minibatch Loss= 0.0004, Training Accuracy= 0.9797, Test Accuracy= 0.9698\n",
      "Step 390, Minibatch Loss= 0.0003, Training Accuracy= 0.9819, Test Accuracy= 0.9810\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 400, Minibatch Loss= 0.0003, Training Accuracy= 0.9824, Test Accuracy= 0.9800\n",
      "Step 410, Minibatch Loss= 0.0003, Training Accuracy= 0.9814, Test Accuracy= 0.9730\n",
      "Step 420, Minibatch Loss= 0.0004, Training Accuracy= 0.9793, Test Accuracy= 0.9809\n",
      "Step 430, Minibatch Loss= 0.0004, Training Accuracy= 0.9807, Test Accuracy= 0.9661\n",
      "Step 440, Minibatch Loss= 0.0003, Training Accuracy= 0.9836, Test Accuracy= 0.9807\n",
      "Step 450, Minibatch Loss= 0.0003, Training Accuracy= 0.9839, Test Accuracy= 0.9809\n",
      "Step 460, Minibatch Loss= 0.0004, Training Accuracy= 0.9801, Test Accuracy= 0.9801\n",
      "Step 470, Minibatch Loss= 0.0003, Training Accuracy= 0.9826, Test Accuracy= 0.9814\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 480, Minibatch Loss= 0.0004, Training Accuracy= 0.9810, Test Accuracy= 0.9820\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 490, Minibatch Loss= 0.0002, Training Accuracy= 0.9847, Test Accuracy= 0.9789\n",
      "Step 500, Minibatch Loss= 0.0003, Training Accuracy= 0.9836, Test Accuracy= 0.9821\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 510, Minibatch Loss= 0.0005, Training Accuracy= 0.9779, Test Accuracy= 0.9664\n",
      "Step 520, Minibatch Loss= 0.0003, Training Accuracy= 0.9834, Test Accuracy= 0.9806\n",
      "Step 530, Minibatch Loss= 0.0004, Training Accuracy= 0.9805, Test Accuracy= 0.9734\n",
      "Step 540, Minibatch Loss= 0.0003, Training Accuracy= 0.9830, Test Accuracy= 0.9827\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 550, Minibatch Loss= 0.0003, Training Accuracy= 0.9833, Test Accuracy= 0.9828\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 560, Minibatch Loss= 0.0002, Training Accuracy= 0.9845, Test Accuracy= 0.9755\n",
      "Step 570, Minibatch Loss= 0.0003, Training Accuracy= 0.9840, Test Accuracy= 0.9819\n",
      "Step 580, Minibatch Loss= 0.0003, Training Accuracy= 0.9826, Test Accuracy= 0.9821\n",
      "Step 590, Minibatch Loss= 0.0007, Training Accuracy= 0.9735, Test Accuracy= 0.9596\n",
      "Step 600, Minibatch Loss= 0.0002, Training Accuracy= 0.9844, Test Accuracy= 0.9808\n",
      "Step 610, Minibatch Loss= 0.0003, Training Accuracy= 0.9833, Test Accuracy= 0.9826\n",
      "Step 620, Minibatch Loss= 0.0003, Training Accuracy= 0.9838, Test Accuracy= 0.9810\n",
      "Step 630, Minibatch Loss= 0.0004, Training Accuracy= 0.9793, Test Accuracy= 0.9609\n",
      "Step 640, Minibatch Loss= 0.0002, Training Accuracy= 0.9842, Test Accuracy= 0.9765\n",
      "Step 650, Minibatch Loss= 0.0004, Training Accuracy= 0.9797, Test Accuracy= 0.9768\n",
      "Step 660, Minibatch Loss= 0.0008, Training Accuracy= 0.9716, Test Accuracy= 0.9561\n",
      "Step 670, Minibatch Loss= 0.0005, Training Accuracy= 0.9768, Test Accuracy= 0.9537\n",
      "Step 680, Minibatch Loss= 0.0003, Training Accuracy= 0.9817, Test Accuracy= 0.9693\n",
      "Step 690, Minibatch Loss= 0.0004, Training Accuracy= 0.9809, Test Accuracy= 0.9686\n",
      "Step 700, Minibatch Loss= 0.0003, Training Accuracy= 0.9827, Test Accuracy= 0.9720\n",
      "Step 710, Minibatch Loss= 0.0002, Training Accuracy= 0.9843, Test Accuracy= 0.9728\n",
      "Step 720, Minibatch Loss= 0.0002, Training Accuracy= 0.9863, Test Accuracy= 0.9840\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 730, Minibatch Loss= 0.0002, Training Accuracy= 0.9849, Test Accuracy= 0.9842\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 740, Minibatch Loss= 0.0006, Training Accuracy= 0.9751, Test Accuracy= 0.9618\n",
      "Step 750, Minibatch Loss= 0.0003, Training Accuracy= 0.9817, Test Accuracy= 0.9796\n",
      "Step 760, Minibatch Loss= 0.0002, Training Accuracy= 0.9864, Test Accuracy= 0.9832\n",
      "Step 770, Minibatch Loss= 0.0004, Training Accuracy= 0.9808, Test Accuracy= 0.9793\n",
      "Step 780, Minibatch Loss= 0.0002, Training Accuracy= 0.9851, Test Accuracy= 0.9841\n",
      "Step 790, Minibatch Loss= 0.0003, Training Accuracy= 0.9823, Test Accuracy= 0.9710\n",
      "Step 800, Minibatch Loss= 0.0005, Training Accuracy= 0.9767, Test Accuracy= 0.9682\n",
      "Step 810, Minibatch Loss= 0.0003, Training Accuracy= 0.9838, Test Accuracy= 0.9828\n",
      "Step 820, Minibatch Loss= 0.0002, Training Accuracy= 0.9860, Test Accuracy= 0.9782\n",
      "Step 830, Minibatch Loss= 0.0002, Training Accuracy= 0.9864, Test Accuracy= 0.9788\n",
      "Step 840, Minibatch Loss= 0.0003, Training Accuracy= 0.9836, Test Accuracy= 0.9834\n",
      "Step 850, Minibatch Loss= 0.0004, Training Accuracy= 0.9803, Test Accuracy= 0.9628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 860, Minibatch Loss= 0.0004, Training Accuracy= 0.9807, Test Accuracy= 0.9778\n",
      "Step 870, Minibatch Loss= 0.0004, Training Accuracy= 0.9792, Test Accuracy= 0.9651\n",
      "Step 880, Minibatch Loss= 0.0003, Training Accuracy= 0.9816, Test Accuracy= 0.9691\n",
      "Step 890, Minibatch Loss= 0.0002, Training Accuracy= 0.9847, Test Accuracy= 0.9770\n",
      "Step 900, Minibatch Loss= 0.0003, Training Accuracy= 0.9835, Test Accuracy= 0.9819\n",
      "Step 910, Minibatch Loss= 0.0002, Training Accuracy= 0.9846, Test Accuracy= 0.9846\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 920, Minibatch Loss= 0.0003, Training Accuracy= 0.9828, Test Accuracy= 0.9794\n",
      "Step 930, Minibatch Loss= 0.0006, Training Accuracy= 0.9764, Test Accuracy= 0.9557\n",
      "Step 940, Minibatch Loss= 0.0006, Training Accuracy= 0.9757, Test Accuracy= 0.9566\n",
      "Step 950, Minibatch Loss= 0.0004, Training Accuracy= 0.9790, Test Accuracy= 0.9664\n",
      "Step 960, Minibatch Loss= 0.0002, Training Accuracy= 0.9848, Test Accuracy= 0.9797\n",
      "Step 970, Minibatch Loss= 0.0002, Training Accuracy= 0.9870, Test Accuracy= 0.9824\n",
      "Step 980, Minibatch Loss= 0.0003, Training Accuracy= 0.9831, Test Accuracy= 0.9814\n",
      "Step 990, Minibatch Loss= 0.0003, Training Accuracy= 0.9827, Test Accuracy= 0.9729\n",
      "Step 1000, Minibatch Loss= 0.0003, Training Accuracy= 0.9839, Test Accuracy= 0.9685\n",
      "Step 1010, Minibatch Loss= 0.0003, Training Accuracy= 0.9840, Test Accuracy= 0.9708\n",
      "Step 1020, Minibatch Loss= 0.0002, Training Accuracy= 0.9843, Test Accuracy= 0.9722\n",
      "Step 1030, Minibatch Loss= 0.0002, Training Accuracy= 0.9853, Test Accuracy= 0.9843\n",
      "Step 1040, Minibatch Loss= 0.0002, Training Accuracy= 0.9858, Test Accuracy= 0.9752\n",
      "Step 1050, Minibatch Loss= 0.0002, Training Accuracy= 0.9857, Test Accuracy= 0.9779\n",
      "Step 1060, Minibatch Loss= 0.0002, Training Accuracy= 0.9845, Test Accuracy= 0.9837\n",
      "Step 1070, Minibatch Loss= 0.0002, Training Accuracy= 0.9853, Test Accuracy= 0.9804\n",
      "Step 1080, Minibatch Loss= 0.0009, Training Accuracy= 0.9693, Test Accuracy= 0.9580\n",
      "Step 1090, Minibatch Loss= 0.0002, Training Accuracy= 0.9844, Test Accuracy= 0.9725\n",
      "Step 1100, Minibatch Loss= 0.0003, Training Accuracy= 0.9813, Test Accuracy= 0.9737\n",
      "Step 1110, Minibatch Loss= 0.0003, Training Accuracy= 0.9823, Test Accuracy= 0.9805\n",
      "Step 1120, Minibatch Loss= 0.0002, Training Accuracy= 0.9842, Test Accuracy= 0.9833\n",
      "Step 1130, Minibatch Loss= 0.0002, Training Accuracy= 0.9860, Test Accuracy= 0.9831\n",
      "Step 1140, Minibatch Loss= 0.0002, Training Accuracy= 0.9844, Test Accuracy= 0.9844\n",
      "Step 1150, Minibatch Loss= 0.0006, Training Accuracy= 0.9747, Test Accuracy= 0.9622\n",
      "Step 1160, Minibatch Loss= 0.0003, Training Accuracy= 0.9839, Test Accuracy= 0.9723\n",
      "Step 1170, Minibatch Loss= 0.0002, Training Accuracy= 0.9864, Test Accuracy= 0.9831\n",
      "Step 1180, Minibatch Loss= 0.0002, Training Accuracy= 0.9842, Test Accuracy= 0.9834\n",
      "Step 1190, Minibatch Loss= 0.0006, Training Accuracy= 0.9746, Test Accuracy= 0.9639\n",
      "Step 1200, Minibatch Loss= 0.0003, Training Accuracy= 0.9837, Test Accuracy= 0.9828\n",
      "Step 1210, Minibatch Loss= 0.0002, Training Accuracy= 0.9848, Test Accuracy= 0.9852\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 1220, Minibatch Loss= 0.0002, Training Accuracy= 0.9848, Test Accuracy= 0.9787\n",
      "Step 1230, Minibatch Loss= 0.0003, Training Accuracy= 0.9838, Test Accuracy= 0.9765\n",
      "Step 1240, Minibatch Loss= 0.0003, Training Accuracy= 0.9829, Test Accuracy= 0.9780\n",
      "Step 1250, Minibatch Loss= 0.0002, Training Accuracy= 0.9856, Test Accuracy= 0.9851\n",
      "Step 1260, Minibatch Loss= 0.0004, Training Accuracy= 0.9811, Test Accuracy= 0.9710\n",
      "Step 1270, Minibatch Loss= 0.0008, Training Accuracy= 0.9724, Test Accuracy= 0.9580\n",
      "Step 1280, Minibatch Loss= 0.0003, Training Accuracy= 0.9832, Test Accuracy= 0.9823\n",
      "Step 1290, Minibatch Loss= 0.0003, Training Accuracy= 0.9834, Test Accuracy= 0.9847\n",
      "Step 1300, Minibatch Loss= 0.0003, Training Accuracy= 0.9817, Test Accuracy= 0.9746\n",
      "Step 1310, Minibatch Loss= 0.0005, Training Accuracy= 0.9771, Test Accuracy= 0.9674\n",
      "Step 1320, Minibatch Loss= 0.0002, Training Accuracy= 0.9853, Test Accuracy= 0.9796\n",
      "Step 1330, Minibatch Loss= 0.0002, Training Accuracy= 0.9850, Test Accuracy= 0.9761\n",
      "Step 1340, Minibatch Loss= 0.0002, Training Accuracy= 0.9868, Test Accuracy= 0.9849\n",
      "Step 1350, Minibatch Loss= 0.0002, Training Accuracy= 0.9842, Test Accuracy= 0.9842\n",
      "Step 1360, Minibatch Loss= 0.0003, Training Accuracy= 0.9825, Test Accuracy= 0.9778\n",
      "Step 1370, Minibatch Loss= 0.0006, Training Accuracy= 0.9764, Test Accuracy= 0.9691\n",
      "Step 1380, Minibatch Loss= 0.0003, Training Accuracy= 0.9825, Test Accuracy= 0.9804\n",
      "Step 1390, Minibatch Loss= 0.0004, Training Accuracy= 0.9794, Test Accuracy= 0.9612\n",
      "Step 1400, Minibatch Loss= 0.0003, Training Accuracy= 0.9834, Test Accuracy= 0.9826\n",
      "Step 1410, Minibatch Loss= 0.0003, Training Accuracy= 0.9827, Test Accuracy= 0.9737\n",
      "Step 1420, Minibatch Loss= 0.0003, Training Accuracy= 0.9841, Test Accuracy= 0.9843\n",
      "Step 1430, Minibatch Loss= 0.0002, Training Accuracy= 0.9855, Test Accuracy= 0.9777\n",
      "Step 1440, Minibatch Loss= 0.0003, Training Accuracy= 0.9815, Test Accuracy= 0.9654\n",
      "Step 1450, Minibatch Loss= 0.0002, Training Accuracy= 0.9846, Test Accuracy= 0.9850\n",
      "Step 1460, Minibatch Loss= 0.0002, Training Accuracy= 0.9844, Test Accuracy= 0.9841\n",
      "Step 1470, Minibatch Loss= 0.0002, Training Accuracy= 0.9844, Test Accuracy= 0.9852\n",
      "Step 1480, Minibatch Loss= 0.0002, Training Accuracy= 0.9843, Test Accuracy= 0.9851\n",
      "Step 1490, Minibatch Loss= 0.0002, Training Accuracy= 0.9864, Test Accuracy= 0.9842\n",
      "Step 1500, Minibatch Loss= 0.0003, Training Accuracy= 0.9842, Test Accuracy= 0.9850\n",
      "Step 1510, Minibatch Loss= 0.0003, Training Accuracy= 0.9834, Test Accuracy= 0.9818\n",
      "Step 1520, Minibatch Loss= 0.0006, Training Accuracy= 0.9756, Test Accuracy= 0.9648\n",
      "Step 1530, Minibatch Loss= 0.0002, Training Accuracy= 0.9850, Test Accuracy= 0.9782\n",
      "Step 1540, Minibatch Loss= 0.0002, Training Accuracy= 0.9846, Test Accuracy= 0.9759\n",
      "Step 1550, Minibatch Loss= 0.0003, Training Accuracy= 0.9831, Test Accuracy= 0.9806\n",
      "Step 1560, Minibatch Loss= 0.0002, Training Accuracy= 0.9865, Test Accuracy= 0.9844\n",
      "Step 1570, Minibatch Loss= 0.0002, Training Accuracy= 0.9873, Test Accuracy= 0.9850\n",
      "Step 1580, Minibatch Loss= 0.0002, Training Accuracy= 0.9875, Test Accuracy= 0.9826\n",
      "Step 1590, Minibatch Loss= 0.0003, Training Accuracy= 0.9833, Test Accuracy= 0.9767\n",
      "Step 1600, Minibatch Loss= 0.0002, Training Accuracy= 0.9863, Test Accuracy= 0.9808\n",
      "Step 1610, Minibatch Loss= 0.0003, Training Accuracy= 0.9829, Test Accuracy= 0.9735\n",
      "Step 1620, Minibatch Loss= 0.0002, Training Accuracy= 0.9852, Test Accuracy= 0.9793\n",
      "Step 1630, Minibatch Loss= 0.0002, Training Accuracy= 0.9872, Test Accuracy= 0.9844\n",
      "Step 1640, Minibatch Loss= 0.0004, Training Accuracy= 0.9810, Test Accuracy= 0.9753\n",
      "Step 1650, Minibatch Loss= 0.0002, Training Accuracy= 0.9857, Test Accuracy= 0.9841\n",
      "Step 1660, Minibatch Loss= 0.0003, Training Accuracy= 0.9839, Test Accuracy= 0.9811\n",
      "Step 1670, Minibatch Loss= 0.0002, Training Accuracy= 0.9859, Test Accuracy= 0.9815\n",
      "Step 1680, Minibatch Loss= 0.0003, Training Accuracy= 0.9819, Test Accuracy= 0.9789\n",
      "Step 1690, Minibatch Loss= 0.0002, Training Accuracy= 0.9860, Test Accuracy= 0.9823\n",
      "Step 1700, Minibatch Loss= 0.0004, Training Accuracy= 0.9795, Test Accuracy= 0.9669\n",
      "Step 1710, Minibatch Loss= 0.0002, Training Accuracy= 0.9855, Test Accuracy= 0.9838\n",
      "Step 1720, Minibatch Loss= 0.0002, Training Accuracy= 0.9848, Test Accuracy= 0.9830\n",
      "Step 1730, Minibatch Loss= 0.0002, Training Accuracy= 0.9859, Test Accuracy= 0.9850\n",
      "Step 1740, Minibatch Loss= 0.0002, Training Accuracy= 0.9843, Test Accuracy= 0.9847\n",
      "Step 1750, Minibatch Loss= 0.0002, Training Accuracy= 0.9845, Test Accuracy= 0.9780\n",
      "Step 1760, Minibatch Loss= 0.0002, Training Accuracy= 0.9869, Test Accuracy= 0.9847\n",
      "Step 1770, Minibatch Loss= 0.0005, Training Accuracy= 0.9780, Test Accuracy= 0.9722\n",
      "Step 1780, Minibatch Loss= 0.0002, Training Accuracy= 0.9843, Test Accuracy= 0.9720\n",
      "Step 1790, Minibatch Loss= 0.0005, Training Accuracy= 0.9781, Test Accuracy= 0.9671\n",
      "Step 1800, Minibatch Loss= 0.0003, Training Accuracy= 0.9829, Test Accuracy= 0.9804\n",
      "Step 1810, Minibatch Loss= 0.0003, Training Accuracy= 0.9814, Test Accuracy= 0.9775\n",
      "Step 1820, Minibatch Loss= 0.0002, Training Accuracy= 0.9867, Test Accuracy= 0.9848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1830, Minibatch Loss= 0.0002, Training Accuracy= 0.9855, Test Accuracy= 0.9840\n",
      "Step 1840, Minibatch Loss= 0.0003, Training Accuracy= 0.9840, Test Accuracy= 0.9824\n",
      "Step 1850, Minibatch Loss= 0.0002, Training Accuracy= 0.9869, Test Accuracy= 0.9847\n",
      "Step 1860, Minibatch Loss= 0.0002, Training Accuracy= 0.9866, Test Accuracy= 0.9850\n",
      "Step 1870, Minibatch Loss= 0.0002, Training Accuracy= 0.9864, Test Accuracy= 0.9849\n",
      "Step 1880, Minibatch Loss= 0.0003, Training Accuracy= 0.9841, Test Accuracy= 0.9777\n",
      "Step 1890, Minibatch Loss= 0.0005, Training Accuracy= 0.9768, Test Accuracy= 0.9730\n",
      "Step 1900, Minibatch Loss= 0.0002, Training Accuracy= 0.9862, Test Accuracy= 0.9849\n",
      "Step 1910, Minibatch Loss= 0.0002, Training Accuracy= 0.9849, Test Accuracy= 0.9838\n",
      "Step 1920, Minibatch Loss= 0.0005, Training Accuracy= 0.9787, Test Accuracy= 0.9765\n",
      "Step 1930, Minibatch Loss= 0.0003, Training Accuracy= 0.9818, Test Accuracy= 0.9773\n",
      "Step 1940, Minibatch Loss= 0.0002, Training Accuracy= 0.9848, Test Accuracy= 0.9846\n",
      "Step 1950, Minibatch Loss= 0.0002, Training Accuracy= 0.9869, Test Accuracy= 0.9808\n",
      "Step 1960, Minibatch Loss= 0.0002, Training Accuracy= 0.9860, Test Accuracy= 0.9830\n",
      "Step 1970, Minibatch Loss= 0.0002, Training Accuracy= 0.9865, Test Accuracy= 0.9848\n",
      "Step 1980, Minibatch Loss= 0.0009, Training Accuracy= 0.9699, Test Accuracy= 0.9441\n",
      "Step 1990, Minibatch Loss= 0.0007, Training Accuracy= 0.9742, Test Accuracy= 0.9630\n",
      "Step 2000, Minibatch Loss= 0.0004, Training Accuracy= 0.9800, Test Accuracy= 0.9808\n",
      "Step 2010, Minibatch Loss= 0.0002, Training Accuracy= 0.9864, Test Accuracy= 0.9848\n",
      "Step 2020, Minibatch Loss= 0.0003, Training Accuracy= 0.9832, Test Accuracy= 0.9822\n",
      "Step 2030, Minibatch Loss= 0.0003, Training Accuracy= 0.9842, Test Accuracy= 0.9832\n",
      "Step 2040, Minibatch Loss= 0.0004, Training Accuracy= 0.9803, Test Accuracy= 0.9788\n",
      "Step 2050, Minibatch Loss= 0.0002, Training Accuracy= 0.9860, Test Accuracy= 0.9847\n",
      "Step 2060, Minibatch Loss= 0.0003, Training Accuracy= 0.9837, Test Accuracy= 0.9827\n",
      "Step 2070, Minibatch Loss= 0.0003, Training Accuracy= 0.9833, Test Accuracy= 0.9822\n",
      "Step 2080, Minibatch Loss= 0.0003, Training Accuracy= 0.9839, Test Accuracy= 0.9832\n",
      "Step 2090, Minibatch Loss= 0.0003, Training Accuracy= 0.9822, Test Accuracy= 0.9707\n",
      "Step 2100, Minibatch Loss= 0.0005, Training Accuracy= 0.9775, Test Accuracy= 0.9699\n",
      "Step 2110, Minibatch Loss= 0.0004, Training Accuracy= 0.9810, Test Accuracy= 0.9777\n",
      "Step 2120, Minibatch Loss= 0.0002, Training Accuracy= 0.9853, Test Accuracy= 0.9846\n",
      "Step 2130, Minibatch Loss= 0.0004, Training Accuracy= 0.9805, Test Accuracy= 0.9731\n",
      "Step 2140, Minibatch Loss= 0.0002, Training Accuracy= 0.9850, Test Accuracy= 0.9841\n",
      "Step 2150, Minibatch Loss= 0.0002, Training Accuracy= 0.9856, Test Accuracy= 0.9823\n",
      "Step 2160, Minibatch Loss= 0.0002, Training Accuracy= 0.9860, Test Accuracy= 0.9847\n",
      "Step 2170, Minibatch Loss= 0.0002, Training Accuracy= 0.9866, Test Accuracy= 0.9847\n",
      "Step 2180, Minibatch Loss= 0.0004, Training Accuracy= 0.9801, Test Accuracy= 0.9699\n",
      "Step 2190, Minibatch Loss= 0.0004, Training Accuracy= 0.9796, Test Accuracy= 0.9717\n",
      "Step 2200, Minibatch Loss= 0.0002, Training Accuracy= 0.9846, Test Accuracy= 0.9795\n",
      "Step 2210, Minibatch Loss= 0.0002, Training Accuracy= 0.9845, Test Accuracy= 0.9742\n",
      "Step 2220, Minibatch Loss= 0.0002, Training Accuracy= 0.9866, Test Accuracy= 0.9845\n",
      "Step 2230, Minibatch Loss= 0.0003, Training Accuracy= 0.9824, Test Accuracy= 0.9762\n",
      "Step 2240, Minibatch Loss= 0.0002, Training Accuracy= 0.9842, Test Accuracy= 0.9848\n",
      "Step 2250, Minibatch Loss= 0.0004, Training Accuracy= 0.9795, Test Accuracy= 0.9732\n",
      "Step 2260, Minibatch Loss= 0.0002, Training Accuracy= 0.9870, Test Accuracy= 0.9846\n",
      "Step 2270, Minibatch Loss= 0.0010, Training Accuracy= 0.9678, Test Accuracy= 0.9478\n",
      "Step 2280, Minibatch Loss= 0.0005, Training Accuracy= 0.9776, Test Accuracy= 0.9611\n",
      "Step 2290, Minibatch Loss= 0.0003, Training Accuracy= 0.9834, Test Accuracy= 0.9727\n",
      "Step 2300, Minibatch Loss= 0.0002, Training Accuracy= 0.9851, Test Accuracy= 0.9780\n",
      "Step 2310, Minibatch Loss= 0.0002, Training Accuracy= 0.9855, Test Accuracy= 0.9755\n",
      "Step 2320, Minibatch Loss= 0.0006, Training Accuracy= 0.9754, Test Accuracy= 0.9636\n",
      "Step 2330, Minibatch Loss= 0.0002, Training Accuracy= 0.9847, Test Accuracy= 0.9786\n",
      "Step 2340, Minibatch Loss= 0.0003, Training Accuracy= 0.9820, Test Accuracy= 0.9801\n",
      "Step 2350, Minibatch Loss= 0.0002, Training Accuracy= 0.9845, Test Accuracy= 0.9812\n",
      "Step 2360, Minibatch Loss= 0.0004, Training Accuracy= 0.9809, Test Accuracy= 0.9769\n",
      "Step 2370, Minibatch Loss= 0.0004, Training Accuracy= 0.9806, Test Accuracy= 0.9797\n",
      "Step 2380, Minibatch Loss= 0.0003, Training Accuracy= 0.9829, Test Accuracy= 0.9811\n",
      "Step 2390, Minibatch Loss= 0.0002, Training Accuracy= 0.9871, Test Accuracy= 0.9832\n",
      "Step 2400, Minibatch Loss= 0.0003, Training Accuracy= 0.9816, Test Accuracy= 0.9845\n",
      "Step 2410, Minibatch Loss= 0.0006, Training Accuracy= 0.9760, Test Accuracy= 0.9608\n",
      "Step 2420, Minibatch Loss= 0.0008, Training Accuracy= 0.9726, Test Accuracy= 0.9447\n",
      "Step 2430, Minibatch Loss= 0.0005, Training Accuracy= 0.9781, Test Accuracy= 0.9662\n",
      "Step 2440, Minibatch Loss= 0.0004, Training Accuracy= 0.9813, Test Accuracy= 0.9733\n",
      "Step 2450, Minibatch Loss= 0.0002, Training Accuracy= 0.9861, Test Accuracy= 0.9841\n",
      "Step 2460, Minibatch Loss= 0.0002, Training Accuracy= 0.9855, Test Accuracy= 0.9841\n",
      "Step 2470, Minibatch Loss= 0.0002, Training Accuracy= 0.9849, Test Accuracy= 0.9814\n",
      "Step 2480, Minibatch Loss= 0.0002, Training Accuracy= 0.9867, Test Accuracy= 0.9837\n",
      "Step 2490, Minibatch Loss= 0.0002, Training Accuracy= 0.9867, Test Accuracy= 0.9816\n",
      "Step 2500, Minibatch Loss= 0.0002, Training Accuracy= 0.9871, Test Accuracy= 0.9809\n",
      "Step 2510, Minibatch Loss= 0.0002, Training Accuracy= 0.9850, Test Accuracy= 0.9768\n",
      "Step 2520, Minibatch Loss= 0.0004, Training Accuracy= 0.9806, Test Accuracy= 0.9725\n",
      "Step 2530, Minibatch Loss= 0.0002, Training Accuracy= 0.9845, Test Accuracy= 0.9850\n",
      "Step 2540, Minibatch Loss= 0.0002, Training Accuracy= 0.9842, Test Accuracy= 0.9850\n",
      "Step 2550, Minibatch Loss= 0.0003, Training Accuracy= 0.9836, Test Accuracy= 0.9769\n",
      "Step 2560, Minibatch Loss= 0.0002, Training Accuracy= 0.9876, Test Accuracy= 0.9836\n",
      "Step 2570, Minibatch Loss= 0.0002, Training Accuracy= 0.9870, Test Accuracy= 0.9836\n",
      "Step 2580, Minibatch Loss= 0.0003, Training Accuracy= 0.9841, Test Accuracy= 0.9809\n",
      "Step 2590, Minibatch Loss= 0.0004, Training Accuracy= 0.9792, Test Accuracy= 0.9706\n",
      "Step 2600, Minibatch Loss= 0.0003, Training Accuracy= 0.9827, Test Accuracy= 0.9805\n",
      "Step 2610, Minibatch Loss= 0.0002, Training Accuracy= 0.9851, Test Accuracy= 0.9814\n",
      "Step 2620, Minibatch Loss= 0.0002, Training Accuracy= 0.9862, Test Accuracy= 0.9827\n",
      "Step 2630, Minibatch Loss= 0.0002, Training Accuracy= 0.9861, Test Accuracy= 0.9768\n",
      "Step 2640, Minibatch Loss= 0.0002, Training Accuracy= 0.9857, Test Accuracy= 0.9784\n",
      "Step 2650, Minibatch Loss= 0.0003, Training Accuracy= 0.9825, Test Accuracy= 0.9779\n",
      "Step 2660, Minibatch Loss= 0.0002, Training Accuracy= 0.9842, Test Accuracy= 0.9813\n",
      "Step 2670, Minibatch Loss= 0.0003, Training Accuracy= 0.9831, Test Accuracy= 0.9783\n",
      "Step 2680, Minibatch Loss= 0.0003, Training Accuracy= 0.9819, Test Accuracy= 0.9794\n",
      "Step 2690, Minibatch Loss= 0.0002, Training Accuracy= 0.9870, Test Accuracy= 0.9823\n",
      "Step 2700, Minibatch Loss= 0.0002, Training Accuracy= 0.9857, Test Accuracy= 0.9821\n",
      "Step 2710, Minibatch Loss= 0.0003, Training Accuracy= 0.9835, Test Accuracy= 0.9828\n",
      "Step 2720, Minibatch Loss= 0.0002, Training Accuracy= 0.9861, Test Accuracy= 0.9835\n",
      "Step 2730, Minibatch Loss= 0.0004, Training Accuracy= 0.9810, Test Accuracy= 0.9681\n",
      "Step 2740, Minibatch Loss= 0.0003, Training Accuracy= 0.9824, Test Accuracy= 0.9693\n",
      "Step 2750, Minibatch Loss= 0.0002, Training Accuracy= 0.9866, Test Accuracy= 0.9842\n",
      "Step 2760, Minibatch Loss= 0.0002, Training Accuracy= 0.9857, Test Accuracy= 0.9816\n",
      "Step 2770, Minibatch Loss= 0.0002, Training Accuracy= 0.9871, Test Accuracy= 0.9831\n",
      "Step 2780, Minibatch Loss= 0.0002, Training Accuracy= 0.9852, Test Accuracy= 0.9794\n",
      "Step 2790, Minibatch Loss= 0.0003, Training Accuracy= 0.9822, Test Accuracy= 0.9818\n",
      "Step 2800, Minibatch Loss= 0.0004, Training Accuracy= 0.9811, Test Accuracy= 0.9799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2810, Minibatch Loss= 0.0004, Training Accuracy= 0.9802, Test Accuracy= 0.9714\n",
      "Step 2820, Minibatch Loss= 0.0002, Training Accuracy= 0.9865, Test Accuracy= 0.9849\n",
      "Step 2830, Minibatch Loss= 0.0002, Training Accuracy= 0.9853, Test Accuracy= 0.9800\n",
      "Step 2840, Minibatch Loss= 0.0002, Training Accuracy= 0.9867, Test Accuracy= 0.9826\n",
      "Step 2850, Minibatch Loss= 0.0002, Training Accuracy= 0.9868, Test Accuracy= 0.9833\n",
      "Step 2860, Minibatch Loss= 0.0004, Training Accuracy= 0.9803, Test Accuracy= 0.9622\n",
      "Step 2870, Minibatch Loss= 0.0002, Training Accuracy= 0.9845, Test Accuracy= 0.9836\n",
      "Step 2880, Minibatch Loss= 0.0003, Training Accuracy= 0.9816, Test Accuracy= 0.9762\n",
      "Step 2890, Minibatch Loss= 0.0008, Training Accuracy= 0.9724, Test Accuracy= 0.9557\n",
      "Step 2900, Minibatch Loss= 0.0005, Training Accuracy= 0.9781, Test Accuracy= 0.9746\n",
      "Step 2910, Minibatch Loss= 0.0002, Training Accuracy= 0.9872, Test Accuracy= 0.9806\n",
      "Step 2920, Minibatch Loss= 0.0002, Training Accuracy= 0.9862, Test Accuracy= 0.9818\n",
      "Step 2930, Minibatch Loss= 0.0002, Training Accuracy= 0.9865, Test Accuracy= 0.9850\n",
      "Step 2940, Minibatch Loss= 0.0002, Training Accuracy= 0.9855, Test Accuracy= 0.9815\n",
      "Step 2950, Minibatch Loss= 0.0002, Training Accuracy= 0.9862, Test Accuracy= 0.9846\n",
      "Step 2960, Minibatch Loss= 0.0002, Training Accuracy= 0.9850, Test Accuracy= 0.9839\n",
      "Step 2970, Minibatch Loss= 0.0003, Training Accuracy= 0.9822, Test Accuracy= 0.9793\n",
      "Step 2980, Minibatch Loss= 0.0004, Training Accuracy= 0.9810, Test Accuracy= 0.9672\n",
      "Step 2990, Minibatch Loss= 0.0004, Training Accuracy= 0.9792, Test Accuracy= 0.9740\n",
      "Step 3000, Minibatch Loss= 0.0002, Training Accuracy= 0.9864, Test Accuracy= 0.9839\n",
      "Step 3010, Minibatch Loss= 0.0002, Training Accuracy= 0.9867, Test Accuracy= 0.9787\n",
      "Step 3020, Minibatch Loss= 0.0002, Training Accuracy= 0.9863, Test Accuracy= 0.9845\n",
      "Step 3030, Minibatch Loss= 0.0002, Training Accuracy= 0.9865, Test Accuracy= 0.9843\n",
      "Step 3040, Minibatch Loss= 0.0002, Training Accuracy= 0.9860, Test Accuracy= 0.9843\n",
      "Step 3050, Minibatch Loss= 0.0003, Training Accuracy= 0.9818, Test Accuracy= 0.9752\n",
      "Step 3060, Minibatch Loss= 0.0004, Training Accuracy= 0.9797, Test Accuracy= 0.9719\n",
      "Step 3070, Minibatch Loss= 0.0002, Training Accuracy= 0.9868, Test Accuracy= 0.9820\n",
      "Step 3080, Minibatch Loss= 0.0007, Training Accuracy= 0.9734, Test Accuracy= 0.9549\n",
      "Step 3090, Minibatch Loss= 0.0002, Training Accuracy= 0.9853, Test Accuracy= 0.9750\n",
      "Step 3100, Minibatch Loss= 0.0003, Training Accuracy= 0.9838, Test Accuracy= 0.9835\n",
      "Step 3110, Minibatch Loss= 0.0002, Training Accuracy= 0.9852, Test Accuracy= 0.9844\n",
      "Step 3120, Minibatch Loss= 0.0003, Training Accuracy= 0.9815, Test Accuracy= 0.9761\n",
      "Step 3130, Minibatch Loss= 0.0002, Training Accuracy= 0.9875, Test Accuracy= 0.9849\n",
      "Step 3140, Minibatch Loss= 0.0003, Training Accuracy= 0.9820, Test Accuracy= 0.9709\n",
      "Step 3150, Minibatch Loss= 0.0003, Training Accuracy= 0.9840, Test Accuracy= 0.9802\n",
      "Step 3160, Minibatch Loss= 0.0002, Training Accuracy= 0.9867, Test Accuracy= 0.9850\n",
      "Step 3170, Minibatch Loss= 0.0003, Training Accuracy= 0.9840, Test Accuracy= 0.9850\n",
      "Step 3180, Minibatch Loss= 0.0002, Training Accuracy= 0.9856, Test Accuracy= 0.9813\n",
      "Step 3190, Minibatch Loss= 0.0006, Training Accuracy= 0.9759, Test Accuracy= 0.9595\n",
      "Step 3200, Minibatch Loss= 0.0002, Training Accuracy= 0.9861, Test Accuracy= 0.9838\n",
      "Step 3210, Minibatch Loss= 0.0002, Training Accuracy= 0.9852, Test Accuracy= 0.9786\n",
      "Step 3220, Minibatch Loss= 0.0002, Training Accuracy= 0.9870, Test Accuracy= 0.9851\n",
      "Step 3230, Minibatch Loss= 0.0002, Training Accuracy= 0.9861, Test Accuracy= 0.9838\n",
      "Step 3240, Minibatch Loss= 0.0004, Training Accuracy= 0.9800, Test Accuracy= 0.9783\n",
      "Step 3250, Minibatch Loss= 0.0003, Training Accuracy= 0.9821, Test Accuracy= 0.9725\n",
      "Step 3260, Minibatch Loss= 0.0003, Training Accuracy= 0.9833, Test Accuracy= 0.9783\n",
      "Step 3270, Minibatch Loss= 0.0002, Training Accuracy= 0.9848, Test Accuracy= 0.9845\n",
      "Step 3280, Minibatch Loss= 0.0003, Training Accuracy= 0.9841, Test Accuracy= 0.9749\n",
      "Step 3290, Minibatch Loss= 0.0004, Training Accuracy= 0.9791, Test Accuracy= 0.9690\n",
      "Step 3300, Minibatch Loss= 0.0003, Training Accuracy= 0.9834, Test Accuracy= 0.9812\n",
      "Step 3310, Minibatch Loss= 0.0002, Training Accuracy= 0.9857, Test Accuracy= 0.9804\n",
      "Step 3320, Minibatch Loss= 0.0002, Training Accuracy= 0.9857, Test Accuracy= 0.9852\n",
      "Step 3330, Minibatch Loss= 0.0002, Training Accuracy= 0.9855, Test Accuracy= 0.9850\n",
      "Step 3340, Minibatch Loss= 0.0002, Training Accuracy= 0.9868, Test Accuracy= 0.9851\n",
      "Step 3350, Minibatch Loss= 0.0003, Training Accuracy= 0.9837, Test Accuracy= 0.9851\n",
      "Step 3360, Minibatch Loss= 0.0002, Training Accuracy= 0.9873, Test Accuracy= 0.9847\n",
      "Step 3370, Minibatch Loss= 0.0002, Training Accuracy= 0.9847, Test Accuracy= 0.9820\n",
      "Step 3380, Minibatch Loss= 0.0006, Training Accuracy= 0.9756, Test Accuracy= 0.9626\n",
      "Step 3390, Minibatch Loss= 0.0004, Training Accuracy= 0.9803, Test Accuracy= 0.9746\n",
      "Step 3400, Minibatch Loss= 0.0003, Training Accuracy= 0.9824, Test Accuracy= 0.9798\n",
      "Step 3410, Minibatch Loss= 0.0003, Training Accuracy= 0.9828, Test Accuracy= 0.9845\n",
      "Step 3420, Minibatch Loss= 0.0003, Training Accuracy= 0.9827, Test Accuracy= 0.9677\n",
      "Step 3430, Minibatch Loss= 0.0002, Training Accuracy= 0.9866, Test Accuracy= 0.9834\n",
      "Step 3440, Minibatch Loss= 0.0003, Training Accuracy= 0.9838, Test Accuracy= 0.9835\n",
      "Step 3450, Minibatch Loss= 0.0003, Training Accuracy= 0.9831, Test Accuracy= 0.9811\n",
      "Step 3460, Minibatch Loss= 0.0002, Training Accuracy= 0.9849, Test Accuracy= 0.9839\n",
      "Step 3470, Minibatch Loss= 0.0002, Training Accuracy= 0.9865, Test Accuracy= 0.9848\n",
      "Step 3480, Minibatch Loss= 0.0003, Training Accuracy= 0.9825, Test Accuracy= 0.9841\n",
      "Step 3490, Minibatch Loss= 0.0002, Training Accuracy= 0.9853, Test Accuracy= 0.9825\n",
      "Step 3500, Minibatch Loss= 0.0003, Training Accuracy= 0.9839, Test Accuracy= 0.9819\n",
      "Step 3510, Minibatch Loss= 0.0002, Training Accuracy= 0.9871, Test Accuracy= 0.9850\n",
      "Step 3520, Minibatch Loss= 0.0003, Training Accuracy= 0.9842, Test Accuracy= 0.9844\n",
      "Step 3530, Minibatch Loss= 0.0003, Training Accuracy= 0.9819, Test Accuracy= 0.9706\n",
      "Step 3540, Minibatch Loss= 0.0003, Training Accuracy= 0.9822, Test Accuracy= 0.9711\n",
      "Step 3550, Minibatch Loss= 0.0002, Training Accuracy= 0.9851, Test Accuracy= 0.9773\n",
      "Step 3560, Minibatch Loss= 0.0002, Training Accuracy= 0.9856, Test Accuracy= 0.9812\n",
      "Step 3570, Minibatch Loss= 0.0003, Training Accuracy= 0.9827, Test Accuracy= 0.9788\n",
      "Step 3580, Minibatch Loss= 0.0002, Training Accuracy= 0.9864, Test Accuracy= 0.9847\n",
      "Step 3590, Minibatch Loss= 0.0002, Training Accuracy= 0.9860, Test Accuracy= 0.9836\n",
      "Step 3600, Minibatch Loss= 0.0002, Training Accuracy= 0.9853, Test Accuracy= 0.9816\n",
      "Step 3610, Minibatch Loss= 0.0002, Training Accuracy= 0.9863, Test Accuracy= 0.9848\n",
      "Step 3620, Minibatch Loss= 0.0002, Training Accuracy= 0.9845, Test Accuracy= 0.9851\n",
      "Step 3630, Minibatch Loss= 0.0002, Training Accuracy= 0.9843, Test Accuracy= 0.9782\n",
      "Step 3640, Minibatch Loss= 0.0002, Training Accuracy= 0.9875, Test Accuracy= 0.9850\n",
      "Step 3650, Minibatch Loss= 0.0003, Training Accuracy= 0.9834, Test Accuracy= 0.9799\n",
      "Step 3660, Minibatch Loss= 0.0002, Training Accuracy= 0.9843, Test Accuracy= 0.9847\n",
      "Step 3670, Minibatch Loss= 0.0002, Training Accuracy= 0.9842, Test Accuracy= 0.9823\n",
      "Step 3680, Minibatch Loss= 0.0004, Training Accuracy= 0.9805, Test Accuracy= 0.9823\n",
      "Step 3690, Minibatch Loss= 0.0003, Training Accuracy= 0.9838, Test Accuracy= 0.9782\n",
      "Step 3700, Minibatch Loss= 0.0003, Training Accuracy= 0.9822, Test Accuracy= 0.9725\n",
      "Step 3710, Minibatch Loss= 0.0003, Training Accuracy= 0.9815, Test Accuracy= 0.9765\n",
      "Step 3720, Minibatch Loss= 0.0002, Training Accuracy= 0.9842, Test Accuracy= 0.9831\n",
      "Step 3730, Minibatch Loss= 0.0002, Training Accuracy= 0.9848, Test Accuracy= 0.9716\n",
      "Step 3740, Minibatch Loss= 0.0002, Training Accuracy= 0.9843, Test Accuracy= 0.9823\n",
      "Step 3750, Minibatch Loss= 0.0002, Training Accuracy= 0.9866, Test Accuracy= 0.9838\n",
      "Step 3760, Minibatch Loss= 0.0004, Training Accuracy= 0.9800, Test Accuracy= 0.9780\n",
      "Step 3770, Minibatch Loss= 0.0002, Training Accuracy= 0.9871, Test Accuracy= 0.9843\n",
      "Step 3780, Minibatch Loss= 0.0002, Training Accuracy= 0.9866, Test Accuracy= 0.9840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3790, Minibatch Loss= 0.0002, Training Accuracy= 0.9864, Test Accuracy= 0.9836\n",
      "Step 3800, Minibatch Loss= 0.0008, Training Accuracy= 0.9715, Test Accuracy= 0.9545\n",
      "Step 3810, Minibatch Loss= 0.0003, Training Accuracy= 0.9820, Test Accuracy= 0.9761\n",
      "Step 3820, Minibatch Loss= 0.0003, Training Accuracy= 0.9826, Test Accuracy= 0.9847\n",
      "Step 3830, Minibatch Loss= 0.0003, Training Accuracy= 0.9838, Test Accuracy= 0.9807\n",
      "Step 3840, Minibatch Loss= 0.0003, Training Accuracy= 0.9828, Test Accuracy= 0.9787\n",
      "Step 3850, Minibatch Loss= 0.0002, Training Accuracy= 0.9846, Test Accuracy= 0.9810\n",
      "Step 3860, Minibatch Loss= 0.0002, Training Accuracy= 0.9858, Test Accuracy= 0.9821\n",
      "Step 3870, Minibatch Loss= 0.0002, Training Accuracy= 0.9858, Test Accuracy= 0.9783\n",
      "Step 3880, Minibatch Loss= 0.0002, Training Accuracy= 0.9860, Test Accuracy= 0.9817\n",
      "Step 3890, Minibatch Loss= 0.0004, Training Accuracy= 0.9791, Test Accuracy= 0.9622\n",
      "Step 3900, Minibatch Loss= 0.0003, Training Accuracy= 0.9836, Test Accuracy= 0.9701\n",
      "Step 3910, Minibatch Loss= 0.0002, Training Accuracy= 0.9875, Test Accuracy= 0.9844\n",
      "Step 3920, Minibatch Loss= 0.0002, Training Accuracy= 0.9863, Test Accuracy= 0.9846\n",
      "Step 3930, Minibatch Loss= 0.0002, Training Accuracy= 0.9869, Test Accuracy= 0.9828\n",
      "Step 3940, Minibatch Loss= 0.0002, Training Accuracy= 0.9851, Test Accuracy= 0.9851\n",
      "Step 3950, Minibatch Loss= 0.0004, Training Accuracy= 0.9802, Test Accuracy= 0.9669\n",
      "Step 3960, Minibatch Loss= 0.0003, Training Accuracy= 0.9835, Test Accuracy= 0.9708\n",
      "Step 3970, Minibatch Loss= 0.0002, Training Accuracy= 0.9867, Test Accuracy= 0.9820\n",
      "Step 3980, Minibatch Loss= 0.0002, Training Accuracy= 0.9850, Test Accuracy= 0.9783\n",
      "Step 3990, Minibatch Loss= 0.0003, Training Accuracy= 0.9825, Test Accuracy= 0.9737\n",
      "Step 4000, Minibatch Loss= 0.0002, Training Accuracy= 0.9851, Test Accuracy= 0.9793\n",
      "Step 4010, Minibatch Loss= 0.0003, Training Accuracy= 0.9822, Test Accuracy= 0.9712\n",
      "Step 4020, Minibatch Loss= 0.0002, Training Accuracy= 0.9848, Test Accuracy= 0.9754\n",
      "Step 4030, Minibatch Loss= 0.0003, Training Accuracy= 0.9819, Test Accuracy= 0.9707\n",
      "Step 4040, Minibatch Loss= 0.0004, Training Accuracy= 0.9805, Test Accuracy= 0.9629\n",
      "Step 4050, Minibatch Loss= 0.0002, Training Accuracy= 0.9867, Test Accuracy= 0.9810\n",
      "Step 4060, Minibatch Loss= 0.0002, Training Accuracy= 0.9846, Test Accuracy= 0.9850\n",
      "Step 4070, Minibatch Loss= 0.0002, Training Accuracy= 0.9868, Test Accuracy= 0.9849\n",
      "Step 4080, Minibatch Loss= 0.0003, Training Accuracy= 0.9840, Test Accuracy= 0.9850\n",
      "Step 4090, Minibatch Loss= 0.0002, Training Accuracy= 0.9845, Test Accuracy= 0.9850\n",
      "Step 4100, Minibatch Loss= 0.0003, Training Accuracy= 0.9842, Test Accuracy= 0.9842\n",
      "Step 4110, Minibatch Loss= 0.0003, Training Accuracy= 0.9838, Test Accuracy= 0.9841\n",
      "Step 4120, Minibatch Loss= 0.0004, Training Accuracy= 0.9802, Test Accuracy= 0.9731\n",
      "Step 4130, Minibatch Loss= 0.0005, Training Accuracy= 0.9770, Test Accuracy= 0.9663\n",
      "Step 4140, Minibatch Loss= 0.0003, Training Accuracy= 0.9818, Test Accuracy= 0.9831\n",
      "Step 4150, Minibatch Loss= 0.0003, Training Accuracy= 0.9830, Test Accuracy= 0.9739\n",
      "Step 4160, Minibatch Loss= 0.0002, Training Accuracy= 0.9864, Test Accuracy= 0.9849\n",
      "Step 4170, Minibatch Loss= 0.0002, Training Accuracy= 0.9850, Test Accuracy= 0.9790\n",
      "Step 4180, Minibatch Loss= 0.0003, Training Accuracy= 0.9825, Test Accuracy= 0.9650\n",
      "Step 4190, Minibatch Loss= 0.0007, Training Accuracy= 0.9737, Test Accuracy= 0.9539\n",
      "Step 4200, Minibatch Loss= 0.0007, Training Accuracy= 0.9734, Test Accuracy= 0.9615\n",
      "Step 4210, Minibatch Loss= 0.0005, Training Accuracy= 0.9767, Test Accuracy= 0.9676\n",
      "Step 4220, Minibatch Loss= 0.0002, Training Accuracy= 0.9853, Test Accuracy= 0.9852\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 4230, Minibatch Loss= 0.0002, Training Accuracy= 0.9859, Test Accuracy= 0.9850\n",
      "Step 4240, Minibatch Loss= 0.0003, Training Accuracy= 0.9828, Test Accuracy= 0.9828\n",
      "Step 4250, Minibatch Loss= 0.0002, Training Accuracy= 0.9859, Test Accuracy= 0.9851\n",
      "Step 4260, Minibatch Loss= 0.0002, Training Accuracy= 0.9870, Test Accuracy= 0.9821\n",
      "Step 4270, Minibatch Loss= 0.0002, Training Accuracy= 0.9869, Test Accuracy= 0.9845\n",
      "Step 4280, Minibatch Loss= 0.0002, Training Accuracy= 0.9870, Test Accuracy= 0.9847\n",
      "Step 4290, Minibatch Loss= 0.0002, Training Accuracy= 0.9855, Test Accuracy= 0.9750\n",
      "Step 4300, Minibatch Loss= 0.0002, Training Accuracy= 0.9868, Test Accuracy= 0.9843\n",
      "Step 4310, Minibatch Loss= 0.0002, Training Accuracy= 0.9872, Test Accuracy= 0.9850\n",
      "Step 4320, Minibatch Loss= 0.0002, Training Accuracy= 0.9855, Test Accuracy= 0.9823\n",
      "Step 4330, Minibatch Loss= 0.0002, Training Accuracy= 0.9870, Test Accuracy= 0.9849\n",
      "Step 4340, Minibatch Loss= 0.0002, Training Accuracy= 0.9847, Test Accuracy= 0.9774\n",
      "Step 4350, Minibatch Loss= 0.0002, Training Accuracy= 0.9851, Test Accuracy= 0.9800\n",
      "Step 4360, Minibatch Loss= 0.0003, Training Accuracy= 0.9827, Test Accuracy= 0.9836\n",
      "Step 4370, Minibatch Loss= 0.0002, Training Accuracy= 0.9866, Test Accuracy= 0.9833\n",
      "Step 4380, Minibatch Loss= 0.0003, Training Accuracy= 0.9835, Test Accuracy= 0.9832\n",
      "Step 4390, Minibatch Loss= 0.0002, Training Accuracy= 0.9869, Test Accuracy= 0.9844\n",
      "Step 4400, Minibatch Loss= 0.0002, Training Accuracy= 0.9869, Test Accuracy= 0.9830\n",
      "Step 4410, Minibatch Loss= 0.0002, Training Accuracy= 0.9875, Test Accuracy= 0.9837\n",
      "Step 4420, Minibatch Loss= 0.0003, Training Accuracy= 0.9831, Test Accuracy= 0.9801\n",
      "Step 4430, Minibatch Loss= 0.0002, Training Accuracy= 0.9870, Test Accuracy= 0.9850\n",
      "Step 4440, Minibatch Loss= 0.0002, Training Accuracy= 0.9872, Test Accuracy= 0.9849\n",
      "Step 4450, Minibatch Loss= 0.0003, Training Accuracy= 0.9827, Test Accuracy= 0.9799\n",
      "Step 4460, Minibatch Loss= 0.0002, Training Accuracy= 0.9867, Test Accuracy= 0.9851\n",
      "Step 4470, Minibatch Loss= 0.0002, Training Accuracy= 0.9848, Test Accuracy= 0.9755\n",
      "Step 4480, Minibatch Loss= 0.0002, Training Accuracy= 0.9868, Test Accuracy= 0.9822\n",
      "Step 4490, Minibatch Loss= 0.0002, Training Accuracy= 0.9849, Test Accuracy= 0.9837\n",
      "Step 4500, Minibatch Loss= 0.0002, Training Accuracy= 0.9865, Test Accuracy= 0.9794\n",
      "Step 4510, Minibatch Loss= 0.0003, Training Accuracy= 0.9819, Test Accuracy= 0.9805\n",
      "Step 4520, Minibatch Loss= 0.0002, Training Accuracy= 0.9864, Test Accuracy= 0.9829\n",
      "Step 4530, Minibatch Loss= 0.0003, Training Accuracy= 0.9833, Test Accuracy= 0.9681\n",
      "Step 4540, Minibatch Loss= 0.0003, Training Accuracy= 0.9837, Test Accuracy= 0.9740\n",
      "Step 4550, Minibatch Loss= 0.0002, Training Accuracy= 0.9851, Test Accuracy= 0.9851\n",
      "Step 4560, Minibatch Loss= 0.0002, Training Accuracy= 0.9874, Test Accuracy= 0.9851\n",
      "Step 4570, Minibatch Loss= 0.0002, Training Accuracy= 0.9870, Test Accuracy= 0.9838\n",
      "Step 4580, Minibatch Loss= 0.0004, Training Accuracy= 0.9792, Test Accuracy= 0.9771\n",
      "Step 4590, Minibatch Loss= 0.0013, Training Accuracy= 0.9645, Test Accuracy= 0.9658\n",
      "Step 4600, Minibatch Loss= 0.0003, Training Accuracy= 0.9814, Test Accuracy= 0.9776\n",
      "Step 4610, Minibatch Loss= 0.0002, Training Accuracy= 0.9853, Test Accuracy= 0.9845\n",
      "Step 4620, Minibatch Loss= 0.0003, Training Accuracy= 0.9841, Test Accuracy= 0.9847\n",
      "Step 4630, Minibatch Loss= 0.0003, Training Accuracy= 0.9830, Test Accuracy= 0.9742\n",
      "Step 4640, Minibatch Loss= 0.0002, Training Accuracy= 0.9844, Test Accuracy= 0.9853\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 4650, Minibatch Loss= 0.0002, Training Accuracy= 0.9869, Test Accuracy= 0.9849\n",
      "Step 4660, Minibatch Loss= 0.0002, Training Accuracy= 0.9850, Test Accuracy= 0.9822\n",
      "Step 4670, Minibatch Loss= 0.0002, Training Accuracy= 0.9870, Test Accuracy= 0.9833\n",
      "Step 4680, Minibatch Loss= 0.0002, Training Accuracy= 0.9866, Test Accuracy= 0.9852\n",
      "Step 4690, Minibatch Loss= 0.0002, Training Accuracy= 0.9854, Test Accuracy= 0.9828\n",
      "Step 4700, Minibatch Loss= 0.0002, Training Accuracy= 0.9854, Test Accuracy= 0.9798\n",
      "Step 4710, Minibatch Loss= 0.0002, Training Accuracy= 0.9873, Test Accuracy= 0.9837\n",
      "Step 4720, Minibatch Loss= 0.0002, Training Accuracy= 0.9859, Test Accuracy= 0.9847\n",
      "Step 4730, Minibatch Loss= 0.0002, Training Accuracy= 0.9866, Test Accuracy= 0.9832\n",
      "Step 4740, Minibatch Loss= 0.0002, Training Accuracy= 0.9860, Test Accuracy= 0.9804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4750, Minibatch Loss= 0.0002, Training Accuracy= 0.9868, Test Accuracy= 0.9822\n",
      "Step 4760, Minibatch Loss= 0.0002, Training Accuracy= 0.9856, Test Accuracy= 0.9787\n",
      "Step 4770, Minibatch Loss= 0.0002, Training Accuracy= 0.9866, Test Accuracy= 0.9817\n",
      "Step 4780, Minibatch Loss= 0.0002, Training Accuracy= 0.9866, Test Accuracy= 0.9850\n",
      "Step 4790, Minibatch Loss= 0.0002, Training Accuracy= 0.9847, Test Accuracy= 0.9841\n",
      "Step 4800, Minibatch Loss= 0.0002, Training Accuracy= 0.9867, Test Accuracy= 0.9851\n",
      "Step 4810, Minibatch Loss= 0.0002, Training Accuracy= 0.9867, Test Accuracy= 0.9828\n",
      "Step 4820, Minibatch Loss= 0.0002, Training Accuracy= 0.9865, Test Accuracy= 0.9840\n",
      "Step 4830, Minibatch Loss= 0.0002, Training Accuracy= 0.9861, Test Accuracy= 0.9850\n",
      "Step 4840, Minibatch Loss= 0.0006, Training Accuracy= 0.9765, Test Accuracy= 0.9670\n",
      "Step 4850, Minibatch Loss= 0.0005, Training Accuracy= 0.9784, Test Accuracy= 0.9725\n",
      "Step 4860, Minibatch Loss= 0.0002, Training Accuracy= 0.9863, Test Accuracy= 0.9829\n",
      "Step 4870, Minibatch Loss= 0.0002, Training Accuracy= 0.9843, Test Accuracy= 0.9792\n",
      "Step 4880, Minibatch Loss= 0.0002, Training Accuracy= 0.9855, Test Accuracy= 0.9740\n",
      "Step 4890, Minibatch Loss= 0.0002, Training Accuracy= 0.9861, Test Accuracy= 0.9827\n",
      "Step 4900, Minibatch Loss= 0.0002, Training Accuracy= 0.9852, Test Accuracy= 0.9777\n",
      "Step 4910, Minibatch Loss= 0.0002, Training Accuracy= 0.9864, Test Accuracy= 0.9841\n",
      "Step 4920, Minibatch Loss= 0.0002, Training Accuracy= 0.9842, Test Accuracy= 0.9814\n",
      "Step 4930, Minibatch Loss= 0.0002, Training Accuracy= 0.9869, Test Accuracy= 0.9849\n",
      "Step 4940, Minibatch Loss= 0.0002, Training Accuracy= 0.9866, Test Accuracy= 0.9849\n",
      "Step 4950, Minibatch Loss= 0.0002, Training Accuracy= 0.9869, Test Accuracy= 0.9841\n",
      "Step 4960, Minibatch Loss= 0.0002, Training Accuracy= 0.9858, Test Accuracy= 0.9793\n",
      "Step 4970, Minibatch Loss= 0.0002, Training Accuracy= 0.9866, Test Accuracy= 0.9848\n",
      "Step 4980, Minibatch Loss= 0.0002, Training Accuracy= 0.9869, Test Accuracy= 0.9833\n",
      "Step 4990, Minibatch Loss= 0.0002, Training Accuracy= 0.9853, Test Accuracy= 0.9835\n",
      "Step 5000, Minibatch Loss= 0.0003, Training Accuracy= 0.9838, Test Accuracy= 0.9755\n",
      "Step 5010, Minibatch Loss= 0.0002, Training Accuracy= 0.9875, Test Accuracy= 0.9827\n",
      "Step 5020, Minibatch Loss= 0.0003, Training Accuracy= 0.9839, Test Accuracy= 0.9707\n",
      "Step 5030, Minibatch Loss= 0.0003, Training Accuracy= 0.9838, Test Accuracy= 0.9755\n",
      "Step 5040, Minibatch Loss= 0.0002, Training Accuracy= 0.9842, Test Accuracy= 0.9841\n",
      "Step 5050, Minibatch Loss= 0.0003, Training Accuracy= 0.9829, Test Accuracy= 0.9750\n",
      "Step 5060, Minibatch Loss= 0.0004, Training Accuracy= 0.9810, Test Accuracy= 0.9791\n",
      "Step 5070, Minibatch Loss= 0.0003, Training Accuracy= 0.9830, Test Accuracy= 0.9734\n",
      "Step 5080, Minibatch Loss= 0.0003, Training Accuracy= 0.9841, Test Accuracy= 0.9844\n",
      "Step 5090, Minibatch Loss= 0.0002, Training Accuracy= 0.9873, Test Accuracy= 0.9819\n",
      "Step 5100, Minibatch Loss= 0.0002, Training Accuracy= 0.9867, Test Accuracy= 0.9845\n",
      "Step 5110, Minibatch Loss= 0.0003, Training Accuracy= 0.9826, Test Accuracy= 0.9788\n",
      "Step 5120, Minibatch Loss= 0.0002, Training Accuracy= 0.9866, Test Accuracy= 0.9816\n",
      "Step 5130, Minibatch Loss= 0.0004, Training Accuracy= 0.9810, Test Accuracy= 0.9604\n",
      "Step 5140, Minibatch Loss= 0.0005, Training Accuracy= 0.9775, Test Accuracy= 0.9638\n",
      "Step 5150, Minibatch Loss= 0.0003, Training Accuracy= 0.9836, Test Accuracy= 0.9782\n",
      "Step 5160, Minibatch Loss= 0.0002, Training Accuracy= 0.9869, Test Accuracy= 0.9847\n",
      "Step 5170, Minibatch Loss= 0.0002, Training Accuracy= 0.9869, Test Accuracy= 0.9801\n",
      "Step 5180, Minibatch Loss= 0.0002, Training Accuracy= 0.9861, Test Accuracy= 0.9832\n",
      "Step 5190, Minibatch Loss= 0.0002, Training Accuracy= 0.9869, Test Accuracy= 0.9849\n",
      "Step 5200, Minibatch Loss= 0.0003, Training Accuracy= 0.9842, Test Accuracy= 0.9824\n",
      "Step 5210, Minibatch Loss= 0.0002, Training Accuracy= 0.9863, Test Accuracy= 0.9837\n",
      "Step 5220, Minibatch Loss= 0.0002, Training Accuracy= 0.9870, Test Accuracy= 0.9817\n",
      "Step 5230, Minibatch Loss= 0.0002, Training Accuracy= 0.9862, Test Accuracy= 0.9835\n",
      "Step 5240, Minibatch Loss= 0.0002, Training Accuracy= 0.9863, Test Accuracy= 0.9846\n",
      "Step 5250, Minibatch Loss= 0.0002, Training Accuracy= 0.9847, Test Accuracy= 0.9850\n",
      "Step 5260, Minibatch Loss= 0.0003, Training Accuracy= 0.9822, Test Accuracy= 0.9824\n",
      "Step 5270, Minibatch Loss= 0.0005, Training Accuracy= 0.9778, Test Accuracy= 0.9783\n",
      "Step 5280, Minibatch Loss= 0.0003, Training Accuracy= 0.9823, Test Accuracy= 0.9759\n",
      "Step 5290, Minibatch Loss= 0.0003, Training Accuracy= 0.9828, Test Accuracy= 0.9793\n",
      "Step 5300, Minibatch Loss= 0.0002, Training Accuracy= 0.9865, Test Accuracy= 0.9841\n",
      "Step 5310, Minibatch Loss= 0.0002, Training Accuracy= 0.9873, Test Accuracy= 0.9806\n",
      "Step 5320, Minibatch Loss= 0.0002, Training Accuracy= 0.9864, Test Accuracy= 0.9832\n",
      "Step 5330, Minibatch Loss= 0.0002, Training Accuracy= 0.9859, Test Accuracy= 0.9842\n",
      "Step 5340, Minibatch Loss= 0.0002, Training Accuracy= 0.9844, Test Accuracy= 0.9847\n",
      "Step 5350, Minibatch Loss= 0.0002, Training Accuracy= 0.9857, Test Accuracy= 0.9791\n",
      "Step 5360, Minibatch Loss= 0.0003, Training Accuracy= 0.9831, Test Accuracy= 0.9813\n",
      "Step 5370, Minibatch Loss= 0.0003, Training Accuracy= 0.9836, Test Accuracy= 0.9763\n",
      "Step 5380, Minibatch Loss= 0.0002, Training Accuracy= 0.9856, Test Accuracy= 0.9844\n",
      "Step 5390, Minibatch Loss= 0.0003, Training Accuracy= 0.9814, Test Accuracy= 0.9759\n",
      "Step 5400, Minibatch Loss= 0.0002, Training Accuracy= 0.9865, Test Accuracy= 0.9847\n",
      "Step 5410, Minibatch Loss= 0.0002, Training Accuracy= 0.9873, Test Accuracy= 0.9817\n",
      "Step 5420, Minibatch Loss= 0.0002, Training Accuracy= 0.9862, Test Accuracy= 0.9809\n",
      "Step 5430, Minibatch Loss= 0.0002, Training Accuracy= 0.9845, Test Accuracy= 0.9842\n",
      "Step 5440, Minibatch Loss= 0.0002, Training Accuracy= 0.9851, Test Accuracy= 0.9816\n",
      "Step 5450, Minibatch Loss= 0.0002, Training Accuracy= 0.9869, Test Accuracy= 0.9835\n",
      "Step 5460, Minibatch Loss= 0.0002, Training Accuracy= 0.9853, Test Accuracy= 0.9807\n",
      "Step 5470, Minibatch Loss= 0.0002, Training Accuracy= 0.9874, Test Accuracy= 0.9828\n",
      "Step 5480, Minibatch Loss= 0.0002, Training Accuracy= 0.9854, Test Accuracy= 0.9741\n",
      "Step 5490, Minibatch Loss= 0.0003, Training Accuracy= 0.9829, Test Accuracy= 0.9767\n",
      "Step 5500, Minibatch Loss= 0.0003, Training Accuracy= 0.9832, Test Accuracy= 0.9795\n",
      "Step 5510, Minibatch Loss= 0.0003, Training Accuracy= 0.9826, Test Accuracy= 0.9754\n",
      "Step 5520, Minibatch Loss= 0.0010, Training Accuracy= 0.9691, Test Accuracy= 0.9261\n",
      "Step 5530, Minibatch Loss= 0.0005, Training Accuracy= 0.9768, Test Accuracy= 0.9638\n",
      "Step 5540, Minibatch Loss= 0.0003, Training Accuracy= 0.9828, Test Accuracy= 0.9841\n",
      "Step 5550, Minibatch Loss= 0.0002, Training Accuracy= 0.9860, Test Accuracy= 0.9841\n",
      "Step 5560, Minibatch Loss= 0.0003, Training Accuracy= 0.9823, Test Accuracy= 0.9782\n",
      "Step 5570, Minibatch Loss= 0.0003, Training Accuracy= 0.9840, Test Accuracy= 0.9792\n",
      "Step 5580, Minibatch Loss= 0.0002, Training Accuracy= 0.9851, Test Accuracy= 0.9842\n",
      "Step 5590, Minibatch Loss= 0.0003, Training Accuracy= 0.9829, Test Accuracy= 0.9836\n",
      "Step 5600, Minibatch Loss= 0.0002, Training Accuracy= 0.9856, Test Accuracy= 0.9780\n",
      "Step 5610, Minibatch Loss= 0.0002, Training Accuracy= 0.9873, Test Accuracy= 0.9843\n",
      "Step 5620, Minibatch Loss= 0.0002, Training Accuracy= 0.9871, Test Accuracy= 0.9818\n",
      "Step 5630, Minibatch Loss= 0.0002, Training Accuracy= 0.9859, Test Accuracy= 0.9847\n",
      "Step 5640, Minibatch Loss= 0.0002, Training Accuracy= 0.9865, Test Accuracy= 0.9850\n",
      "Step 5650, Minibatch Loss= 0.0002, Training Accuracy= 0.9859, Test Accuracy= 0.9850\n",
      "Step 5660, Minibatch Loss= 0.0003, Training Accuracy= 0.9841, Test Accuracy= 0.9727\n",
      "Step 5670, Minibatch Loss= 0.0002, Training Accuracy= 0.9856, Test Accuracy= 0.9784\n",
      "Step 5680, Minibatch Loss= 0.0002, Training Accuracy= 0.9856, Test Accuracy= 0.9797\n",
      "Step 5690, Minibatch Loss= 0.0002, Training Accuracy= 0.9861, Test Accuracy= 0.9833\n",
      "Step 5700, Minibatch Loss= 0.0002, Training Accuracy= 0.9873, Test Accuracy= 0.9804\n",
      "Step 5710, Minibatch Loss= 0.0002, Training Accuracy= 0.9862, Test Accuracy= 0.9810\n",
      "Step 5720, Minibatch Loss= 0.0003, Training Accuracy= 0.9832, Test Accuracy= 0.9719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5730, Minibatch Loss= 0.0003, Training Accuracy= 0.9825, Test Accuracy= 0.9739\n",
      "Step 5740, Minibatch Loss= 0.0002, Training Accuracy= 0.9845, Test Accuracy= 0.9851\n",
      "Step 5750, Minibatch Loss= 0.0002, Training Accuracy= 0.9846, Test Accuracy= 0.9820\n",
      "Step 5760, Minibatch Loss= 0.0002, Training Accuracy= 0.9871, Test Accuracy= 0.9834\n",
      "Step 5770, Minibatch Loss= 0.0002, Training Accuracy= 0.9858, Test Accuracy= 0.9796\n",
      "Step 5780, Minibatch Loss= 0.0003, Training Accuracy= 0.9839, Test Accuracy= 0.9846\n",
      "Step 5790, Minibatch Loss= 0.0002, Training Accuracy= 0.9852, Test Accuracy= 0.9842\n",
      "Step 5800, Minibatch Loss= 0.0003, Training Accuracy= 0.9814, Test Accuracy= 0.9756\n",
      "Step 5810, Minibatch Loss= 0.0002, Training Accuracy= 0.9872, Test Accuracy= 0.9807\n",
      "Step 5820, Minibatch Loss= 0.0002, Training Accuracy= 0.9843, Test Accuracy= 0.9779\n",
      "Step 5830, Minibatch Loss= 0.0002, Training Accuracy= 0.9846, Test Accuracy= 0.9779\n",
      "Step 5840, Minibatch Loss= 0.0004, Training Accuracy= 0.9791, Test Accuracy= 0.9756\n",
      "Step 5850, Minibatch Loss= 0.0002, Training Accuracy= 0.9854, Test Accuracy= 0.9767\n",
      "Step 5860, Minibatch Loss= 0.0002, Training Accuracy= 0.9862, Test Accuracy= 0.9795\n",
      "Step 5870, Minibatch Loss= 0.0002, Training Accuracy= 0.9862, Test Accuracy= 0.9772\n",
      "Step 5880, Minibatch Loss= 0.0002, Training Accuracy= 0.9867, Test Accuracy= 0.9803\n",
      "Step 5890, Minibatch Loss= 0.0002, Training Accuracy= 0.9854, Test Accuracy= 0.9822\n",
      "Step 5900, Minibatch Loss= 0.0002, Training Accuracy= 0.9846, Test Accuracy= 0.9798\n",
      "Step 5910, Minibatch Loss= 0.0002, Training Accuracy= 0.9877, Test Accuracy= 0.9847\n",
      "Step 5920, Minibatch Loss= 0.0002, Training Accuracy= 0.9873, Test Accuracy= 0.9842\n",
      "Step 5930, Minibatch Loss= 0.0003, Training Accuracy= 0.9840, Test Accuracy= 0.9847\n",
      "Step 5940, Minibatch Loss= 0.0002, Training Accuracy= 0.9853, Test Accuracy= 0.9790\n",
      "Step 5950, Minibatch Loss= 0.0003, Training Accuracy= 0.9820, Test Accuracy= 0.9764\n",
      "Step 5960, Minibatch Loss= 0.0003, Training Accuracy= 0.9815, Test Accuracy= 0.9797\n",
      "Step 5970, Minibatch Loss= 0.0003, Training Accuracy= 0.9818, Test Accuracy= 0.9749\n",
      "Step 5980, Minibatch Loss= 0.0002, Training Accuracy= 0.9864, Test Accuracy= 0.9848\n",
      "Step 5990, Minibatch Loss= 0.0003, Training Accuracy= 0.9821, Test Accuracy= 0.9746\n",
      "Step 6000, Minibatch Loss= 0.0003, Training Accuracy= 0.9814, Test Accuracy= 0.9655\n",
      "Step 6010, Minibatch Loss= 0.0004, Training Accuracy= 0.9791, Test Accuracy= 0.9725\n",
      "Step 6020, Minibatch Loss= 0.0002, Training Accuracy= 0.9866, Test Accuracy= 0.9811\n",
      "Step 6030, Minibatch Loss= 0.0002, Training Accuracy= 0.9870, Test Accuracy= 0.9812\n",
      "Step 6040, Minibatch Loss= 0.0002, Training Accuracy= 0.9858, Test Accuracy= 0.9844\n",
      "Step 6050, Minibatch Loss= 0.0002, Training Accuracy= 0.9848, Test Accuracy= 0.9844\n",
      "Step 6060, Minibatch Loss= 0.0002, Training Accuracy= 0.9863, Test Accuracy= 0.9780\n",
      "Step 6070, Minibatch Loss= 0.0002, Training Accuracy= 0.9874, Test Accuracy= 0.9847\n",
      "Step 6080, Minibatch Loss= 0.0002, Training Accuracy= 0.9862, Test Accuracy= 0.9767\n",
      "Step 6090, Minibatch Loss= 0.0002, Training Accuracy= 0.9861, Test Accuracy= 0.9839\n",
      "Step 6100, Minibatch Loss= 0.0002, Training Accuracy= 0.9846, Test Accuracy= 0.9838\n",
      "Step 6110, Minibatch Loss= 0.0003, Training Accuracy= 0.9829, Test Accuracy= 0.9747\n",
      "Step 6120, Minibatch Loss= 0.0002, Training Accuracy= 0.9866, Test Accuracy= 0.9849\n",
      "Step 6130, Minibatch Loss= 0.0002, Training Accuracy= 0.9860, Test Accuracy= 0.9742\n",
      "Step 6140, Minibatch Loss= 0.0003, Training Accuracy= 0.9840, Test Accuracy= 0.9849\n",
      "Step 6150, Minibatch Loss= 0.0002, Training Accuracy= 0.9859, Test Accuracy= 0.9843\n",
      "Step 6160, Minibatch Loss= 0.0002, Training Accuracy= 0.9851, Test Accuracy= 0.9831\n",
      "Step 6170, Minibatch Loss= 0.0003, Training Accuracy= 0.9834, Test Accuracy= 0.9788\n",
      "Step 6180, Minibatch Loss= 0.0002, Training Accuracy= 0.9867, Test Accuracy= 0.9798\n",
      "Step 6190, Minibatch Loss= 0.0003, Training Accuracy= 0.9836, Test Accuracy= 0.9807\n",
      "Step 6200, Minibatch Loss= 0.0001, Training Accuracy= 0.9878, Test Accuracy= 0.9829\n",
      "Step 6210, Minibatch Loss= 0.0002, Training Accuracy= 0.9862, Test Accuracy= 0.9772\n",
      "Step 6220, Minibatch Loss= 0.0005, Training Accuracy= 0.9777, Test Accuracy= 0.9637\n",
      "Step 6230, Minibatch Loss= 0.0002, Training Accuracy= 0.9867, Test Accuracy= 0.9837\n",
      "Step 6240, Minibatch Loss= 0.0002, Training Accuracy= 0.9858, Test Accuracy= 0.9831\n",
      "Step 6250, Minibatch Loss= 0.0005, Training Accuracy= 0.9773, Test Accuracy= 0.9590\n",
      "Step 6260, Minibatch Loss= 0.0002, Training Accuracy= 0.9863, Test Accuracy= 0.9842\n",
      "Step 6270, Minibatch Loss= 0.0003, Training Accuracy= 0.9828, Test Accuracy= 0.9626\n",
      "Step 6280, Minibatch Loss= 0.0002, Training Accuracy= 0.9853, Test Accuracy= 0.9744\n",
      "Step 6290, Minibatch Loss= 0.0002, Training Accuracy= 0.9867, Test Accuracy= 0.9835\n",
      "Step 6300, Minibatch Loss= 0.0002, Training Accuracy= 0.9845, Test Accuracy= 0.9737\n",
      "Step 6310, Minibatch Loss= 0.0002, Training Accuracy= 0.9862, Test Accuracy= 0.9833\n",
      "Step 6320, Minibatch Loss= 0.0002, Training Accuracy= 0.9867, Test Accuracy= 0.9846\n",
      "Step 6330, Minibatch Loss= 0.0002, Training Accuracy= 0.9862, Test Accuracy= 0.9827\n",
      "Step 6340, Minibatch Loss= 0.0005, Training Accuracy= 0.9774, Test Accuracy= 0.9734\n",
      "Step 6350, Minibatch Loss= 0.0003, Training Accuracy= 0.9820, Test Accuracy= 0.9688\n",
      "Step 6360, Minibatch Loss= 0.0002, Training Accuracy= 0.9862, Test Accuracy= 0.9781\n",
      "Step 6370, Minibatch Loss= 0.0002, Training Accuracy= 0.9869, Test Accuracy= 0.9824\n",
      "Step 6380, Minibatch Loss= 0.0003, Training Accuracy= 0.9841, Test Accuracy= 0.9846\n",
      "Step 6390, Minibatch Loss= 0.0002, Training Accuracy= 0.9867, Test Accuracy= 0.9829\n",
      "Step 6400, Minibatch Loss= 0.0002, Training Accuracy= 0.9843, Test Accuracy= 0.9847\n",
      "Step 6410, Minibatch Loss= 0.0002, Training Accuracy= 0.9861, Test Accuracy= 0.9799\n",
      "Step 6420, Minibatch Loss= 0.0004, Training Accuracy= 0.9795, Test Accuracy= 0.9555\n",
      "Step 6430, Minibatch Loss= 0.0004, Training Accuracy= 0.9804, Test Accuracy= 0.9823\n",
      "Step 6440, Minibatch Loss= 0.0003, Training Accuracy= 0.9833, Test Accuracy= 0.9843\n",
      "Step 6450, Minibatch Loss= 0.0003, Training Accuracy= 0.9831, Test Accuracy= 0.9850\n",
      "Step 6460, Minibatch Loss= 0.0002, Training Accuracy= 0.9842, Test Accuracy= 0.9801\n",
      "Step 6470, Minibatch Loss= 0.0002, Training Accuracy= 0.9844, Test Accuracy= 0.9791\n",
      "Step 6480, Minibatch Loss= 0.0003, Training Accuracy= 0.9836, Test Accuracy= 0.9837\n",
      "Step 6490, Minibatch Loss= 0.0002, Training Accuracy= 0.9861, Test Accuracy= 0.9830\n",
      "Step 6500, Minibatch Loss= 0.0003, Training Accuracy= 0.9836, Test Accuracy= 0.9715\n",
      "Step 6510, Minibatch Loss= 0.0002, Training Accuracy= 0.9855, Test Accuracy= 0.9729\n",
      "Step 6520, Minibatch Loss= 0.0002, Training Accuracy= 0.9873, Test Accuracy= 0.9847\n",
      "Step 6530, Minibatch Loss= 0.0002, Training Accuracy= 0.9868, Test Accuracy= 0.9850\n",
      "Step 6540, Minibatch Loss= 0.0003, Training Accuracy= 0.9818, Test Accuracy= 0.9824\n",
      "Step 6550, Minibatch Loss= 0.0002, Training Accuracy= 0.9852, Test Accuracy= 0.9832\n",
      "Step 6560, Minibatch Loss= 0.0002, Training Accuracy= 0.9870, Test Accuracy= 0.9840\n",
      "Step 6570, Minibatch Loss= 0.0002, Training Accuracy= 0.9865, Test Accuracy= 0.9809\n",
      "Step 6580, Minibatch Loss= 0.0002, Training Accuracy= 0.9844, Test Accuracy= 0.9827\n",
      "Step 6590, Minibatch Loss= 0.0002, Training Accuracy= 0.9850, Test Accuracy= 0.9839\n",
      "Step 6600, Minibatch Loss= 0.0003, Training Accuracy= 0.9833, Test Accuracy= 0.9828\n",
      "Step 6610, Minibatch Loss= 0.0002, Training Accuracy= 0.9863, Test Accuracy= 0.9825\n",
      "Step 6620, Minibatch Loss= 0.0002, Training Accuracy= 0.9857, Test Accuracy= 0.9761\n",
      "Step 6630, Minibatch Loss= 0.0002, Training Accuracy= 0.9867, Test Accuracy= 0.9820\n",
      "Step 6640, Minibatch Loss= 0.0002, Training Accuracy= 0.9866, Test Accuracy= 0.9843\n",
      "Step 6650, Minibatch Loss= 0.0002, Training Accuracy= 0.9867, Test Accuracy= 0.9847\n",
      "Step 6660, Minibatch Loss= 0.0002, Training Accuracy= 0.9876, Test Accuracy= 0.9848\n",
      "Step 6670, Minibatch Loss= 0.0002, Training Accuracy= 0.9869, Test Accuracy= 0.9841\n",
      "Step 6680, Minibatch Loss= 0.0002, Training Accuracy= 0.9866, Test Accuracy= 0.9798\n",
      "Step 6690, Minibatch Loss= 0.0002, Training Accuracy= 0.9848, Test Accuracy= 0.9814\n",
      "Step 6700, Minibatch Loss= 0.0003, Training Accuracy= 0.9837, Test Accuracy= 0.9785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6710, Minibatch Loss= 0.0002, Training Accuracy= 0.9868, Test Accuracy= 0.9837\n",
      "Step 6720, Minibatch Loss= 0.0002, Training Accuracy= 0.9867, Test Accuracy= 0.9805\n",
      "Step 6730, Minibatch Loss= 0.0004, Training Accuracy= 0.9812, Test Accuracy= 0.9732\n",
      "Step 6740, Minibatch Loss= 0.0003, Training Accuracy= 0.9840, Test Accuracy= 0.9820\n",
      "Step 6750, Minibatch Loss= 0.0003, Training Accuracy= 0.9840, Test Accuracy= 0.9778\n",
      "Step 6760, Minibatch Loss= 0.0002, Training Accuracy= 0.9856, Test Accuracy= 0.9758\n",
      "Step 6770, Minibatch Loss= 0.0002, Training Accuracy= 0.9868, Test Accuracy= 0.9830\n",
      "Step 6780, Minibatch Loss= 0.0002, Training Accuracy= 0.9860, Test Accuracy= 0.9836\n",
      "Step 6790, Minibatch Loss= 0.0002, Training Accuracy= 0.9844, Test Accuracy= 0.9842\n",
      "Step 6800, Minibatch Loss= 0.0002, Training Accuracy= 0.9869, Test Accuracy= 0.9843\n",
      "Step 6810, Minibatch Loss= 0.0002, Training Accuracy= 0.9853, Test Accuracy= 0.9722\n",
      "Step 6820, Minibatch Loss= 0.0002, Training Accuracy= 0.9866, Test Accuracy= 0.9842\n",
      "Step 6830, Minibatch Loss= 0.0003, Training Accuracy= 0.9826, Test Accuracy= 0.9799\n",
      "Step 6840, Minibatch Loss= 0.0002, Training Accuracy= 0.9869, Test Accuracy= 0.9841\n",
      "Step 6850, Minibatch Loss= 0.0003, Training Accuracy= 0.9834, Test Accuracy= 0.9690\n",
      "Step 6860, Minibatch Loss= 0.0003, Training Accuracy= 0.9835, Test Accuracy= 0.9846\n",
      "Step 6870, Minibatch Loss= 0.0002, Training Accuracy= 0.9849, Test Accuracy= 0.9843\n",
      "Step 6880, Minibatch Loss= 0.0003, Training Accuracy= 0.9823, Test Accuracy= 0.9745\n",
      "Step 6890, Minibatch Loss= 0.0004, Training Accuracy= 0.9790, Test Accuracy= 0.9692\n",
      "Step 6900, Minibatch Loss= 0.0003, Training Accuracy= 0.9830, Test Accuracy= 0.9834\n",
      "Step 6910, Minibatch Loss= 0.0003, Training Accuracy= 0.9829, Test Accuracy= 0.9842\n",
      "Step 6920, Minibatch Loss= 0.0002, Training Accuracy= 0.9870, Test Accuracy= 0.9839\n",
      "Step 6930, Minibatch Loss= 0.0002, Training Accuracy= 0.9866, Test Accuracy= 0.9786\n",
      "Step 6940, Minibatch Loss= 0.0002, Training Accuracy= 0.9856, Test Accuracy= 0.9754\n",
      "Step 6950, Minibatch Loss= 0.0002, Training Accuracy= 0.9869, Test Accuracy= 0.9837\n",
      "Step 6960, Minibatch Loss= 0.0002, Training Accuracy= 0.9867, Test Accuracy= 0.9789\n",
      "Step 6970, Minibatch Loss= 0.0004, Training Accuracy= 0.9799, Test Accuracy= 0.9780\n",
      "Step 6980, Minibatch Loss= 0.0004, Training Accuracy= 0.9805, Test Accuracy= 0.9565\n",
      "Step 6990, Minibatch Loss= 0.0003, Training Accuracy= 0.9827, Test Accuracy= 0.9805\n",
      "Step 7000, Minibatch Loss= 0.0002, Training Accuracy= 0.9871, Test Accuracy= 0.9839\n",
      "Step 7010, Minibatch Loss= 0.0002, Training Accuracy= 0.9868, Test Accuracy= 0.9831\n",
      "Step 7020, Minibatch Loss= 0.0002, Training Accuracy= 0.9867, Test Accuracy= 0.9813\n",
      "Step 7030, Minibatch Loss= 0.0002, Training Accuracy= 0.9865, Test Accuracy= 0.9840\n",
      "Step 7040, Minibatch Loss= 0.0002, Training Accuracy= 0.9853, Test Accuracy= 0.9768\n",
      "Step 7050, Minibatch Loss= 0.0002, Training Accuracy= 0.9866, Test Accuracy= 0.9843\n",
      "Step 7060, Minibatch Loss= 0.0002, Training Accuracy= 0.9856, Test Accuracy= 0.9839\n",
      "Step 7070, Minibatch Loss= 0.0002, Training Accuracy= 0.9867, Test Accuracy= 0.9818\n",
      "Step 7080, Minibatch Loss= 0.0003, Training Accuracy= 0.9835, Test Accuracy= 0.9836\n",
      "Step 7090, Minibatch Loss= 0.0004, Training Accuracy= 0.9789, Test Accuracy= 0.9797\n",
      "Step 7100, Minibatch Loss= 0.0004, Training Accuracy= 0.9799, Test Accuracy= 0.9603\n",
      "Step 7110, Minibatch Loss= 0.0002, Training Accuracy= 0.9859, Test Accuracy= 0.9837\n",
      "Step 7120, Minibatch Loss= 0.0002, Training Accuracy= 0.9867, Test Accuracy= 0.9838\n",
      "Step 7130, Minibatch Loss= 0.0004, Training Accuracy= 0.9798, Test Accuracy= 0.9789\n",
      "Step 7140, Minibatch Loss= 0.0002, Training Accuracy= 0.9846, Test Accuracy= 0.9764\n",
      "Step 7150, Minibatch Loss= 0.0002, Training Accuracy= 0.9854, Test Accuracy= 0.9731\n",
      "Step 7160, Minibatch Loss= 0.0003, Training Accuracy= 0.9835, Test Accuracy= 0.9776\n",
      "Step 7170, Minibatch Loss= 0.0002, Training Accuracy= 0.9852, Test Accuracy= 0.9755\n",
      "Step 7180, Minibatch Loss= 0.0002, Training Accuracy= 0.9872, Test Accuracy= 0.9836\n",
      "Step 7190, Minibatch Loss= 0.0002, Training Accuracy= 0.9848, Test Accuracy= 0.9812\n",
      "Step 7200, Minibatch Loss= 0.0003, Training Accuracy= 0.9837, Test Accuracy= 0.9849\n",
      "Step 7210, Minibatch Loss= 0.0002, Training Accuracy= 0.9864, Test Accuracy= 0.9837\n",
      "Step 7220, Minibatch Loss= 0.0002, Training Accuracy= 0.9876, Test Accuracy= 0.9838\n",
      "Step 7230, Minibatch Loss= 0.0002, Training Accuracy= 0.9869, Test Accuracy= 0.9839\n",
      "Step 7240, Minibatch Loss= 0.0002, Training Accuracy= 0.9846, Test Accuracy= 0.9815\n",
      "Step 7250, Minibatch Loss= 0.0003, Training Accuracy= 0.9841, Test Accuracy= 0.9785\n",
      "Step 7260, Minibatch Loss= 0.0003, Training Accuracy= 0.9840, Test Accuracy= 0.9826\n",
      "Step 7270, Minibatch Loss= 0.0005, Training Accuracy= 0.9786, Test Accuracy= 0.9649\n",
      "Step 7280, Minibatch Loss= 0.0003, Training Accuracy= 0.9825, Test Accuracy= 0.9773\n",
      "Step 7290, Minibatch Loss= 0.0002, Training Accuracy= 0.9866, Test Accuracy= 0.9847\n",
      "Step 7300, Minibatch Loss= 0.0002, Training Accuracy= 0.9852, Test Accuracy= 0.9771\n",
      "Step 7310, Minibatch Loss= 0.0002, Training Accuracy= 0.9858, Test Accuracy= 0.9798\n",
      "Step 7320, Minibatch Loss= 0.0003, Training Accuracy= 0.9833, Test Accuracy= 0.9733\n",
      "Step 7330, Minibatch Loss= 0.0003, Training Accuracy= 0.9829, Test Accuracy= 0.9838\n",
      "Step 7340, Minibatch Loss= 0.0002, Training Accuracy= 0.9862, Test Accuracy= 0.9845\n",
      "Step 7350, Minibatch Loss= 0.0003, Training Accuracy= 0.9834, Test Accuracy= 0.9842\n",
      "Step 7360, Minibatch Loss= 0.0003, Training Accuracy= 0.9832, Test Accuracy= 0.9813\n",
      "Step 7370, Minibatch Loss= 0.0003, Training Accuracy= 0.9842, Test Accuracy= 0.9841\n",
      "Step 7380, Minibatch Loss= 0.0003, Training Accuracy= 0.9841, Test Accuracy= 0.9838\n",
      "Step 7390, Minibatch Loss= 0.0003, Training Accuracy= 0.9836, Test Accuracy= 0.9832\n",
      "Step 7400, Minibatch Loss= 0.0002, Training Accuracy= 0.9846, Test Accuracy= 0.9833\n",
      "Step 7410, Minibatch Loss= 0.0003, Training Accuracy= 0.9838, Test Accuracy= 0.9793\n",
      "Step 7420, Minibatch Loss= 0.0004, Training Accuracy= 0.9804, Test Accuracy= 0.9754\n",
      "Step 7430, Minibatch Loss= 0.0002, Training Accuracy= 0.9866, Test Accuracy= 0.9842\n",
      "Step 7440, Minibatch Loss= 0.0002, Training Accuracy= 0.9865, Test Accuracy= 0.9772\n",
      "Step 7450, Minibatch Loss= 0.0003, Training Accuracy= 0.9831, Test Accuracy= 0.9779\n",
      "Step 7460, Minibatch Loss= 0.0003, Training Accuracy= 0.9842, Test Accuracy= 0.9815\n",
      "Step 7470, Minibatch Loss= 0.0002, Training Accuracy= 0.9844, Test Accuracy= 0.9844\n",
      "Step 7480, Minibatch Loss= 0.0002, Training Accuracy= 0.9861, Test Accuracy= 0.9825\n",
      "Step 7490, Minibatch Loss= 0.0002, Training Accuracy= 0.9854, Test Accuracy= 0.9823\n",
      "Step 7500, Minibatch Loss= 0.0004, Training Accuracy= 0.9794, Test Accuracy= 0.9748\n",
      "Step 7510, Minibatch Loss= 0.0002, Training Accuracy= 0.9864, Test Accuracy= 0.9769\n",
      "Step 7520, Minibatch Loss= 0.0002, Training Accuracy= 0.9869, Test Accuracy= 0.9850\n",
      "Step 7530, Minibatch Loss= 0.0002, Training Accuracy= 0.9871, Test Accuracy= 0.9828\n",
      "Step 7540, Minibatch Loss= 0.0003, Training Accuracy= 0.9833, Test Accuracy= 0.9714\n",
      "Step 7550, Minibatch Loss= 0.0002, Training Accuracy= 0.9845, Test Accuracy= 0.9829\n",
      "Step 7560, Minibatch Loss= 0.0004, Training Accuracy= 0.9788, Test Accuracy= 0.9744\n",
      "Step 7570, Minibatch Loss= 0.0003, Training Accuracy= 0.9830, Test Accuracy= 0.9848\n",
      "Step 7580, Minibatch Loss= 0.0002, Training Accuracy= 0.9868, Test Accuracy= 0.9853\n",
      "Step 7590, Minibatch Loss= 0.0002, Training Accuracy= 0.9859, Test Accuracy= 0.9813\n",
      "Step 7600, Minibatch Loss= 0.0004, Training Accuracy= 0.9813, Test Accuracy= 0.9701\n",
      "Step 7610, Minibatch Loss= 0.0002, Training Accuracy= 0.9849, Test Accuracy= 0.9844\n",
      "Step 7620, Minibatch Loss= 0.0002, Training Accuracy= 0.9845, Test Accuracy= 0.9816\n",
      "Step 7630, Minibatch Loss= 0.0002, Training Accuracy= 0.9870, Test Accuracy= 0.9841\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session(graph=graph, config=config) as sess:\n",
    "    init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    sess.run(init)\n",
    "    for step in range(1, training_epochs+1):\n",
    "        Xt, Yt = next_batch(batch_size, X0, Y0)\n",
    "        batch_x, batch_y = Xt,Yt\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, is_training: True})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={\n",
    "                X: batch_x, Y: batch_y, is_training: False})\n",
    "            test_data = testX\n",
    "            test_label = testY\n",
    "            val_acc = sess.run(accuracy, feed_dict={X: test_data, Y: test_label, is_training: False})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.4f}\".format(acc) + \", Test Accuracy= \" + \\\n",
    "                  \"{:.4f}\".format(val_acc))\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                save_path = saver.save(sess, \"/home/rubensvectomobile/BOVESPA/real/model.ckpt\")\n",
    "                print(\"Model saved in path: %s\" % save_path)\n",
    "    pred00 = sess.run([prediction], feed_dict={X: test_data, is_training: False})\n",
    "    pred01 = sess.run([prediction2], feed_dict={X: test_data, is_training: False})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph, config=config) as session:\n",
    "    ckpt = \"/home/rubensvectomobile/BOVESPA/real/model.ckpt\"\n",
    "    saver.restore(session, ckpt)\n",
    "    pred00 = session.run([prediction], feed_dict={X: test_data, is_training: False})\n",
    "    pred01 = session.run([prediction2], feed_dict={X: test_data, is_training: False})\n",
    "    pred02 = session.run([prediction2], feed_dict={X: trainX.reshape(-1,look_back,1), is_training: False})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.array(pred02).reshape(-1,1)[-200:])\n",
    "plt.plot(np.array(trainX).reshape(-1,)[-200:],c='black')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.array(pred01).reshape(-1,1))\n",
    "plt.plot(np.array(testY).reshape(-1,),c='black')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.show()\n",
    "\n",
    "x=list(range(0,len(pred00[0])))\n",
    "y1=np.array(pred01).reshape(1,-1)[0]+2*np.std(np.array(pred01).reshape(1,-1))\n",
    "y2=np.array(pred01).reshape(1,-1)[0]-2*np.std(np.array(pred01).reshape(1,-1))\n",
    "fig, ax1 = plt.subplots(1, 1, sharex=True)\n",
    "ax1.plot(np.array(pred01).reshape(1,-1)[0],'--',color='blue',alpha=0.5)\n",
    "ax1.fill_between(x, y1, y2,color='blue',alpha=0.3)\n",
    "ax1.plot(x,np.array(testY).reshape(-1,),c='red')\n",
    "plt.xlabel('Days')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print('R2',r2_score(testY.reshape(1,-1)[0],np.array(pred01).reshape(1,-1)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=testX[0].reshape(-1,look_back,1)\n",
    "prev=[]\n",
    "with tf.Session(graph=graph, config=config) as session:\n",
    "    ckpt = \"/home/rubensvectomobile/BOVESPA/real/model.ckpt\"\n",
    "    saver.restore(session, ckpt)\n",
    "    for i in range(0,21):\n",
    "        pred02 = session.run([prediction2], feed_dict={X: x_test, is_training: False})[0][0]\n",
    "        prev.append(pred02)\n",
    "        #print(pred02)\n",
    "        x_test=np.concatenate([x_test[0][1:look_back],[pred02]],axis=0).reshape(-1,look_back,1)\n",
    "        #print(x_test)\n",
    "        \n",
    "plt.plot(np.array(prev)[0:limit].reshape(-1,1))\n",
    "plt.plot(np.array(testY)[0:limit].reshape(-1,),c='black')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.show()\n",
    "real=(np.array(testY)[0:limit].reshape(-1,)[-1]/np.array(testY)[0:limit].reshape(-1,)[0]-1)*100\n",
    "prevista=(np.array(prev)[0:limit].reshape(-1,1)[-1]/np.array(prev)[0:limit].reshape(-1,1)[0]-1)*100\n",
    "print('Variao Real',\"%.2f\" % real + '%')\n",
    "print('Variao Prevista',[\"%.2f\" % prevista+'%'])\n",
    "print('Erro',[\"%.2f\" % float((prevista-real))+'%'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=testX[-1].reshape(-1,look_back,1)\n",
    "prev=[]\n",
    "with tf.Session(graph=graph, config=config) as session:\n",
    "    ckpt = \"/home/rubensvectomobile/BOVESPA/real/model.ckpt\"\n",
    "    saver.restore(session, ckpt)\n",
    "    for i in range(0,21):\n",
    "        pred02 = session.run([prediction2], feed_dict={X: x_test, is_training: False})[0][0]\n",
    "        prev.append(pred02)\n",
    "        #print(pred02)\n",
    "        x_test=np.concatenate([x_test[0][1:look_back],[pred02]],axis=0).reshape(-1,look_back,1)\n",
    "        #print(x_test)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(testY)[0:limit].reshape(-1,)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(prev)[0:limit].reshape(-1,1))\n",
    "#plt.plot(np.array(testY)[0:limit].reshape(-1,),c='black')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.show()\n",
    "#real=(np.array(testY)[0:limit].reshape(-1,)[-1]/np.array(testY)[0:limit].reshape(-1,)[0]-1)*100\n",
    "prevista=(np.array(prev)[0:limit].reshape(-1,1)[-1]/np.array(prev)[0:limit].reshape(-1,1)[0]-1)*100\n",
    "#print('Variao Real',\"%.2f\" % real + '%')\n",
    "print('Variao Prevista',[\"%.2f\" % prevista+'%'])\n",
    "#print('Erro',[\"%.2f\" % float((prevista-real))+'%'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import tensorflow as tf\n",
    "\n",
    "tf_path = os.path.abspath('/home/rubensvectomobile/BOVESPA/real/model.ckpt')  # Path to our TensorFlow checkpoint\n",
    "tf_vars = tf.train.list_variables(tf_path)\n",
    "pprint(tf_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
