{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6bb82374a8>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_datareader import data\n",
    "#pip install pandas-datareader\n",
    "\n",
    "stock = 'RENT3.SA'\n",
    "source = 'yahoo'\n",
    "\n",
    "# Set date range (Google went public August 19, 2004)\n",
    "start = datetime.datetime(2005, 8, 19)\n",
    "end = datetime.datetime(2019, 8, 6)\n",
    "\n",
    "# Collect Google stock data\n",
    "goog_df = data.DataReader(stock, source, start, end)\n",
    "\n",
    "dataset = goog_df['Adj Close']\n",
    "print(len(dataset))\n",
    "goog_df['Adj Close'].plot(kind='line', grid=True, title='GOOG Adjusted Closes, IPO through 2016')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.900001525878906"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goog_df['Adj Close'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3420 35\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "\n",
    "dataset = np.array(dataset.astype('float32')).reshape(-1,1)\n",
    "\n",
    "def norm(x):\n",
    "    return (x-np.min(x))/(np.max(x)-np.min(x))\n",
    "\n",
    "#dataset=norm(dataset)\n",
    "\n",
    "look_back=4\n",
    "np.random.seed(7)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "train_size = int(len(dataset) * 0.99)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print(len(train), len(test))\n",
    "\n",
    "def create_dataset(dataset, look_back=look_back):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn np.array(dataX), np.array(dataY)\n",
    "\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "trainX\n",
    "\n",
    "trainY = trainY.reshape(len(trainY), 1)\n",
    "testY = testY.reshape(len(testY), 1)\n",
    "trainY\n",
    "\n",
    "X0=trainX\n",
    "Y0=trainY\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rubensvectomobile_gmail_com/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py:1735: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense/BiasAdd:0\", shape=(?, 4, 1), dtype=float32)\n",
      "All parameters: 328200.0\n",
      "Trainable parameters: 109446\n"
     ]
    }
   ],
   "source": [
    "tfd = tfp.distributions\n",
    "\n",
    "class TemporalConvNet(tf.layers.Layer):\n",
    "    def __init__(self, num_channels, kernel_size=2, dropout=0.2,\n",
    "                 trainable=True, name=None, dtype=None, \n",
    "                 activity_regularizer=None, **kwargs):\n",
    "        super(TemporalConvNet, self).__init__(\n",
    "            trainable=trainable, dtype=dtype,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            name=name, **kwargs\n",
    "        )\n",
    "        self.layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            out_channels = num_channels[i]\n",
    "            self.layers.append(\n",
    "                TemporalBlock(out_channels, kernel_size, strides=1, dilation_rate=dilation_size,\n",
    "                              dropout=dropout, name=\"tblock_{}\".format(i))\n",
    "            )\n",
    "    \n",
    "    def call(self, inputs, training=True):\n",
    "        outputs = inputs\n",
    "        for layer in self.layers:\n",
    "            outputs = layer(outputs, training=training)\n",
    "        return outputs\n",
    "\n",
    "learning_rate = 0.001\n",
    "display_step = 10\n",
    "num_input = 1\n",
    "num_hidden = 35\n",
    "num_classes = 1\n",
    "\n",
    "dropout = 0\n",
    "kernel_size = 8\n",
    "levels = 6\n",
    "\n",
    "class CausalConv1D(tf.layers.Conv1D):\n",
    "    def __init__(self, filters,\n",
    "               kernel_size,\n",
    "               strides=1,\n",
    "               dilation_rate=1,\n",
    "               activation=None,\n",
    "               use_bias=True,\n",
    "               kernel_initializer=None,\n",
    "               bias_initializer=tf.zeros_initializer(),\n",
    "               kernel_regularizer=None,\n",
    "               bias_regularizer=None,\n",
    "               activity_regularizer=None,\n",
    "               kernel_constraint=None,\n",
    "               bias_constraint=None,\n",
    "               trainable=True,\n",
    "               name=None,\n",
    "               **kwargs):\n",
    "        super(CausalConv1D, self).__init__(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding='valid',\n",
    "            data_format='channels_last',\n",
    "            dilation_rate=dilation_rate,\n",
    "            activation=activation,\n",
    "            use_bias=use_bias,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=bias_regularizer,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=bias_constraint,\n",
    "            trainable=trainable,\n",
    "            name=name, **kwargs\n",
    "        )\n",
    "       \n",
    "    def call(self, inputs):\n",
    "        padding = (self.kernel_size[0] - 1) * self.dilation_rate[0]\n",
    "        inputs = tf.pad(inputs, tf.constant([(0, 0,), (1, 0), (0, 0)]) * padding)\n",
    "        return super(CausalConv1D, self).call(inputs)\n",
    "\n",
    "\n",
    "\n",
    "class TemporalBlock(tf.layers.Layer):\n",
    "    def __init__(self, n_outputs, kernel_size, strides, dilation_rate, dropout=0.1, \n",
    "                 trainable=True, name=None, dtype=None, \n",
    "                 activity_regularizer=None, **kwargs):\n",
    "        super(TemporalBlock, self).__init__(\n",
    "            trainable=trainable, dtype=dtype,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            name=name, **kwargs\n",
    "        )        \n",
    "        self.dropout = dropout\n",
    "        self.n_outputs = n_outputs\n",
    "        self.conv1 = CausalConv1D(\n",
    "            n_outputs, kernel_size, strides=strides, \n",
    "            dilation_rate=dilation_rate, activation=tf.nn.relu, \n",
    "            name=\"conv1\")\n",
    "        self.conv2 = CausalConv1D(\n",
    "            n_outputs, kernel_size, strides=strides, \n",
    "            dilation_rate=dilation_rate, activation=tf.nn.relu, \n",
    "            name=\"conv2\")\n",
    "        self.down_sample = None\n",
    "\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        channel_dim = 2\n",
    "        self.dropout1 = tf.layers.Dropout(self.dropout, [tf.constant(1), tf.constant(1), tf.constant(self.n_outputs)])\n",
    "        self.dropout2 = tf.layers.Dropout(self.dropout, [tf.constant(1), tf.constant(1), tf.constant(self.n_outputs)])\n",
    "        if input_shape[channel_dim] != self.n_outputs:\n",
    "            self.down_sample = tf.layers.Dense(self.n_outputs, activation=None)\n",
    "    \n",
    "    def call(self, inputs, training=True):\n",
    "        x = self.conv1(inputs)\n",
    "        x = tf.contrib.layers.layer_norm(x)\n",
    "        x = self.dropout1(x, training=training)\n",
    "        x = self.conv2(x)\n",
    "        x = tf.contrib.layers.layer_norm(x)\n",
    "        x = self.dropout2(x, training=training)\n",
    "        #x = tfp.layers.DistributionLambda(make_distribution_fn=lambda t: tfd.Normal(loc=t, scale=1))(x)\n",
    "        #x = tf.contrib.layers.layer_norm(x)\n",
    "        #x = tf.layers.dense(inputs=x,units=3)\n",
    "        if self.down_sample is not None:\n",
    "          inputs = self.down_sample(inputs)\n",
    "        return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    tf.set_random_seed(2)\n",
    "    \n",
    "    X = tf.placeholder(\"float\", [None, look_back,1])\n",
    "    Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "    is_training = tf.placeholder(\"bool\")\n",
    "    \n",
    "    logits = tf.layers.dense(\n",
    "        TemporalConvNet([num_hidden] * levels, kernel_size, dropout)(\n",
    "            X, training=is_training),\n",
    "        num_classes, activation=None, \n",
    "        kernel_initializer=tf.glorot_uniform_initializer()\n",
    "    )\n",
    "    print(logits)\n",
    "\n",
    "    mm,_=tf.nn.moments(tf.reshape(tf.nn.relu(logits),[-1,look_back]),axes=[1])\n",
    "    prediction=tf.nn.relu(logits)\n",
    "    \n",
    "    prediction2 = tf.reshape(tf.cast(mm,tf.float32),[-1,1])\n",
    "    \n",
    "    loss_op = tf.reduce_mean(tf.losses.mean_squared_error(\n",
    "        labels=Y,predictions=prediction2))\n",
    "    \n",
    "    accuracy=1-tf.sqrt(loss_op)\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    print(\"All parameters:\", np.sum([np.product([xi.value for xi in x.get_shape()]) for x in tf.global_variables()]))\n",
    "    print(\"Trainable parameters:\", np.sum([np.product([xi.value for xi in x.get_shape()]) for x in tf.trainable_variables()]))\n",
    "\n",
    "def next_batch(num, data, labels):\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "    return np.asarray(data_shuffle).astype(np.float32), np.asarray(labels_shuffle).astype(np.float32)\n",
    "\n",
    "log_dir = \"/home/rubensvectomobile/BOVESPA/\"\n",
    "tb_writer = tf.summary.FileWriter(log_dir, graph)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "best_val_acc = 0.93\n",
    "\n",
    "training_epochs = 8000\n",
    "batch_size = int(trainX.shape[0]/4)\n",
    "\n",
    "\n",
    "X0=X0.reshape(-1,look_back,1)\n",
    "testX=testX.reshape(-1,look_back,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 0.0511, Training Accuracy= 0.7739, Test Accuracy= 0.0976\n",
      "Step 10, Minibatch Loss= 0.0126, Training Accuracy= 0.8877, Test Accuracy= 0.4759\n",
      "Step 20, Minibatch Loss= 0.0041, Training Accuracy= 0.9357, Test Accuracy= 0.6000\n",
      "Step 30, Minibatch Loss= 0.0016, Training Accuracy= 0.9602, Test Accuracy= 0.6851\n",
      "Step 40, Minibatch Loss= 0.0007, Training Accuracy= 0.9742, Test Accuracy= 0.8038\n",
      "Step 50, Minibatch Loss= 0.0003, Training Accuracy= 0.9839, Test Accuracy= 0.9008\n",
      "Step 60, Minibatch Loss= 0.0002, Training Accuracy= 0.9859, Test Accuracy= 0.9177\n",
      "Step 70, Minibatch Loss= 0.0001, Training Accuracy= 0.9899, Test Accuracy= 0.9259\n",
      "Step 80, Minibatch Loss= 0.0001, Training Accuracy= 0.9903, Test Accuracy= 0.9263\n",
      "Step 90, Minibatch Loss= 0.0001, Training Accuracy= 0.9907, Test Accuracy= 0.9374\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 100, Minibatch Loss= 0.0001, Training Accuracy= 0.9914, Test Accuracy= 0.9360\n",
      "Step 110, Minibatch Loss= 0.0001, Training Accuracy= 0.9922, Test Accuracy= 0.9386\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 120, Minibatch Loss= 0.0001, Training Accuracy= 0.9914, Test Accuracy= 0.9363\n",
      "Step 130, Minibatch Loss= 0.0001, Training Accuracy= 0.9904, Test Accuracy= 0.9474\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 140, Minibatch Loss= 0.0001, Training Accuracy= 0.9903, Test Accuracy= 0.9520\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 150, Minibatch Loss= 0.0001, Training Accuracy= 0.9891, Test Accuracy= 0.9576\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 160, Minibatch Loss= 0.0001, Training Accuracy= 0.9917, Test Accuracy= 0.9367\n",
      "Step 170, Minibatch Loss= 0.0001, Training Accuracy= 0.9917, Test Accuracy= 0.9365\n",
      "Step 180, Minibatch Loss= 0.0001, Training Accuracy= 0.9916, Test Accuracy= 0.9545\n",
      "Step 190, Minibatch Loss= 0.0001, Training Accuracy= 0.9906, Test Accuracy= 0.9318\n",
      "Step 200, Minibatch Loss= 0.0001, Training Accuracy= 0.9905, Test Accuracy= 0.9328\n",
      "Step 210, Minibatch Loss= 0.0001, Training Accuracy= 0.9922, Test Accuracy= 0.9463\n",
      "Step 220, Minibatch Loss= 0.0001, Training Accuracy= 0.9902, Test Accuracy= 0.9508\n",
      "Step 230, Minibatch Loss= 0.0000, Training Accuracy= 0.9932, Test Accuracy= 0.9434\n",
      "Step 240, Minibatch Loss= 0.0001, Training Accuracy= 0.9928, Test Accuracy= 0.9451\n",
      "Step 250, Minibatch Loss= 0.0002, Training Accuracy= 0.9873, Test Accuracy= 0.9574\n",
      "Step 260, Minibatch Loss= 0.0001, Training Accuracy= 0.9917, Test Accuracy= 0.9447\n",
      "Step 270, Minibatch Loss= 0.0001, Training Accuracy= 0.9889, Test Accuracy= 0.9291\n",
      "Step 280, Minibatch Loss= 0.0001, Training Accuracy= 0.9927, Test Accuracy= 0.9380\n",
      "Step 290, Minibatch Loss= 0.0001, Training Accuracy= 0.9902, Test Accuracy= 0.9249\n",
      "Step 300, Minibatch Loss= 0.0001, Training Accuracy= 0.9878, Test Accuracy= 0.9167\n",
      "Step 310, Minibatch Loss= 0.0001, Training Accuracy= 0.9927, Test Accuracy= 0.9306\n",
      "Step 320, Minibatch Loss= 0.0002, Training Accuracy= 0.9873, Test Accuracy= 0.9389\n",
      "Step 330, Minibatch Loss= 0.0001, Training Accuracy= 0.9880, Test Accuracy= 0.9090\n",
      "Step 340, Minibatch Loss= 0.0001, Training Accuracy= 0.9917, Test Accuracy= 0.9327\n",
      "Step 350, Minibatch Loss= 0.0001, Training Accuracy= 0.9925, Test Accuracy= 0.9256\n",
      "Step 360, Minibatch Loss= 0.0001, Training Accuracy= 0.9898, Test Accuracy= 0.9341\n",
      "Step 370, Minibatch Loss= 0.0002, Training Accuracy= 0.9852, Test Accuracy= 0.8927\n",
      "Step 380, Minibatch Loss= 0.0001, Training Accuracy= 0.9915, Test Accuracy= 0.9260\n",
      "Step 390, Minibatch Loss= 0.0002, Training Accuracy= 0.9856, Test Accuracy= 0.9191\n",
      "Step 400, Minibatch Loss= 0.0001, Training Accuracy= 0.9884, Test Accuracy= 0.8712\n",
      "Step 410, Minibatch Loss= 0.0003, Training Accuracy= 0.9814, Test Accuracy= 0.8908\n",
      "Step 420, Minibatch Loss= 0.0001, Training Accuracy= 0.9905, Test Accuracy= 0.8979\n",
      "Step 430, Minibatch Loss= 0.0001, Training Accuracy= 0.9925, Test Accuracy= 0.9005\n",
      "Step 440, Minibatch Loss= 0.0001, Training Accuracy= 0.9927, Test Accuracy= 0.9178\n",
      "Step 450, Minibatch Loss= 0.0001, Training Accuracy= 0.9919, Test Accuracy= 0.9152\n",
      "Step 460, Minibatch Loss= 0.0000, Training Accuracy= 0.9930, Test Accuracy= 0.9208\n",
      "Step 470, Minibatch Loss= 0.0000, Training Accuracy= 0.9930, Test Accuracy= 0.9239\n",
      "Step 480, Minibatch Loss= 0.0001, Training Accuracy= 0.9908, Test Accuracy= 0.9153\n",
      "Step 490, Minibatch Loss= 0.0001, Training Accuracy= 0.9905, Test Accuracy= 0.9287\n",
      "Step 500, Minibatch Loss= 0.0001, Training Accuracy= 0.9915, Test Accuracy= 0.9312\n",
      "Step 510, Minibatch Loss= 0.0001, Training Accuracy= 0.9906, Test Accuracy= 0.9166\n",
      "Step 520, Minibatch Loss= 0.0001, Training Accuracy= 0.9882, Test Accuracy= 0.9350\n",
      "Step 530, Minibatch Loss= 0.0001, Training Accuracy= 0.9904, Test Accuracy= 0.9181\n",
      "Step 540, Minibatch Loss= 0.0001, Training Accuracy= 0.9911, Test Accuracy= 0.9243\n",
      "Step 550, Minibatch Loss= 0.0000, Training Accuracy= 0.9936, Test Accuracy= 0.9294\n",
      "Step 560, Minibatch Loss= 0.0002, Training Accuracy= 0.9876, Test Accuracy= 0.9392\n",
      "Step 570, Minibatch Loss= 0.0001, Training Accuracy= 0.9880, Test Accuracy= 0.9058\n",
      "Step 580, Minibatch Loss= 0.0001, Training Accuracy= 0.9927, Test Accuracy= 0.9269\n",
      "Step 590, Minibatch Loss= 0.0000, Training Accuracy= 0.9936, Test Accuracy= 0.9210\n",
      "Step 600, Minibatch Loss= 0.0001, Training Accuracy= 0.9905, Test Accuracy= 0.9127\n",
      "Step 610, Minibatch Loss= 0.0001, Training Accuracy= 0.9893, Test Accuracy= 0.9299\n",
      "Step 620, Minibatch Loss= 0.0002, Training Accuracy= 0.9858, Test Accuracy= 0.9005\n",
      "Step 630, Minibatch Loss= 0.0002, Training Accuracy= 0.9866, Test Accuracy= 0.9316\n",
      "Step 640, Minibatch Loss= 0.0003, Training Accuracy= 0.9825, Test Accuracy= 0.8747\n",
      "Step 650, Minibatch Loss= 0.0001, Training Accuracy= 0.9890, Test Accuracy= 0.8827\n",
      "Step 660, Minibatch Loss= 0.0001, Training Accuracy= 0.9905, Test Accuracy= 0.9091\n",
      "Step 670, Minibatch Loss= 0.0001, Training Accuracy= 0.9910, Test Accuracy= 0.9123\n",
      "Step 680, Minibatch Loss= 0.0000, Training Accuracy= 0.9929, Test Accuracy= 0.9261\n",
      "Step 690, Minibatch Loss= 0.0001, Training Accuracy= 0.9928, Test Accuracy= 0.9290\n",
      "Step 700, Minibatch Loss= 0.0001, Training Accuracy= 0.9904, Test Accuracy= 0.9161\n",
      "Step 710, Minibatch Loss= 0.0001, Training Accuracy= 0.9892, Test Accuracy= 0.9408\n",
      "Step 720, Minibatch Loss= 0.0001, Training Accuracy= 0.9922, Test Accuracy= 0.9179\n",
      "Step 730, Minibatch Loss= 0.0000, Training Accuracy= 0.9931, Test Accuracy= 0.9259\n",
      "Step 740, Minibatch Loss= 0.0001, Training Accuracy= 0.9927, Test Accuracy= 0.9320\n",
      "Step 750, Minibatch Loss= 0.0001, Training Accuracy= 0.9897, Test Accuracy= 0.9205\n",
      "Step 760, Minibatch Loss= 0.0001, Training Accuracy= 0.9915, Test Accuracy= 0.9318\n",
      "Step 770, Minibatch Loss= 0.0001, Training Accuracy= 0.9898, Test Accuracy= 0.9201\n",
      "Step 780, Minibatch Loss= 0.0001, Training Accuracy= 0.9888, Test Accuracy= 0.9419\n",
      "Step 790, Minibatch Loss= 0.0005, Training Accuracy= 0.9786, Test Accuracy= 0.8588\n",
      "Step 800, Minibatch Loss= 0.0002, Training Accuracy= 0.9854, Test Accuracy= 0.8672\n",
      "Step 810, Minibatch Loss= 0.0001, Training Accuracy= 0.9898, Test Accuracy= 0.9029\n",
      "Step 820, Minibatch Loss= 0.0001, Training Accuracy= 0.9894, Test Accuracy= 0.9248\n",
      "Step 830, Minibatch Loss= 0.0000, Training Accuracy= 0.9930, Test Accuracy= 0.9316\n",
      "Step 840, Minibatch Loss= 0.0001, Training Accuracy= 0.9919, Test Accuracy= 0.9229\n",
      "Step 850, Minibatch Loss= 0.0001, Training Accuracy= 0.9927, Test Accuracy= 0.9288\n",
      "Step 860, Minibatch Loss= 0.0001, Training Accuracy= 0.9902, Test Accuracy= 0.9329\n",
      "Step 870, Minibatch Loss= 0.0000, Training Accuracy= 0.9931, Test Accuracy= 0.9256\n",
      "Step 880, Minibatch Loss= 0.0001, Training Accuracy= 0.9896, Test Accuracy= 0.9354\n",
      "Step 890, Minibatch Loss= 0.0000, Training Accuracy= 0.9930, Test Accuracy= 0.9326\n",
      "Step 900, Minibatch Loss= 0.0000, Training Accuracy= 0.9934, Test Accuracy= 0.9296\n",
      "Step 910, Minibatch Loss= 0.0001, Training Accuracy= 0.9928, Test Accuracy= 0.9159\n",
      "Step 920, Minibatch Loss= 0.0001, Training Accuracy= 0.9926, Test Accuracy= 0.9264\n",
      "Step 930, Minibatch Loss= 0.0001, Training Accuracy= 0.9915, Test Accuracy= 0.9151\n",
      "Step 940, Minibatch Loss= 0.0000, Training Accuracy= 0.9932, Test Accuracy= 0.9175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 950, Minibatch Loss= 0.0000, Training Accuracy= 0.9937, Test Accuracy= 0.9232\n",
      "Step 960, Minibatch Loss= 0.0000, Training Accuracy= 0.9931, Test Accuracy= 0.9239\n",
      "Step 970, Minibatch Loss= 0.0000, Training Accuracy= 0.9933, Test Accuracy= 0.9276\n",
      "Step 980, Minibatch Loss= 0.0000, Training Accuracy= 0.9931, Test Accuracy= 0.9272\n",
      "Step 990, Minibatch Loss= 0.0001, Training Accuracy= 0.9918, Test Accuracy= 0.9339\n",
      "Step 1000, Minibatch Loss= 0.0001, Training Accuracy= 0.9921, Test Accuracy= 0.9205\n",
      "Step 1010, Minibatch Loss= 0.0001, Training Accuracy= 0.9919, Test Accuracy= 0.9174\n",
      "Step 1020, Minibatch Loss= 0.0001, Training Accuracy= 0.9910, Test Accuracy= 0.9368\n",
      "Step 1030, Minibatch Loss= 0.0001, Training Accuracy= 0.9909, Test Accuracy= 0.9107\n",
      "Step 1040, Minibatch Loss= 0.0000, Training Accuracy= 0.9936, Test Accuracy= 0.9221\n",
      "Step 1050, Minibatch Loss= 0.0001, Training Accuracy= 0.9903, Test Accuracy= 0.9279\n",
      "Step 1060, Minibatch Loss= 0.0001, Training Accuracy= 0.9892, Test Accuracy= 0.9086\n",
      "Step 1070, Minibatch Loss= 0.0001, Training Accuracy= 0.9925, Test Accuracy= 0.9196\n",
      "Step 1080, Minibatch Loss= 0.0001, Training Accuracy= 0.9924, Test Accuracy= 0.9301\n",
      "Step 1090, Minibatch Loss= 0.0000, Training Accuracy= 0.9933, Test Accuracy= 0.9249\n",
      "Step 1100, Minibatch Loss= 0.0000, Training Accuracy= 0.9930, Test Accuracy= 0.9264\n",
      "Step 1110, Minibatch Loss= 0.0001, Training Accuracy= 0.9927, Test Accuracy= 0.9036\n",
      "Step 1120, Minibatch Loss= 0.0001, Training Accuracy= 0.9915, Test Accuracy= 0.8962\n",
      "Step 1130, Minibatch Loss= 0.0001, Training Accuracy= 0.9927, Test Accuracy= 0.9264\n",
      "Step 1140, Minibatch Loss= 0.0001, Training Accuracy= 0.9915, Test Accuracy= 0.9202\n",
      "Step 1150, Minibatch Loss= 0.0001, Training Accuracy= 0.9903, Test Accuracy= 0.9331\n",
      "Step 1160, Minibatch Loss= 0.0001, Training Accuracy= 0.9926, Test Accuracy= 0.9242\n",
      "Step 1170, Minibatch Loss= 0.0001, Training Accuracy= 0.9908, Test Accuracy= 0.9201\n",
      "Step 1180, Minibatch Loss= 0.0000, Training Accuracy= 0.9930, Test Accuracy= 0.9344\n",
      "Step 1190, Minibatch Loss= 0.0001, Training Accuracy= 0.9924, Test Accuracy= 0.9237\n",
      "Step 1200, Minibatch Loss= 0.0001, Training Accuracy= 0.9907, Test Accuracy= 0.9064\n",
      "Step 1210, Minibatch Loss= 0.0003, Training Accuracy= 0.9823, Test Accuracy= 0.9118\n",
      "Step 1220, Minibatch Loss= 0.0001, Training Accuracy= 0.9923, Test Accuracy= 0.9001\n",
      "Step 1230, Minibatch Loss= 0.0001, Training Accuracy= 0.9897, Test Accuracy= 0.9037\n",
      "Step 1240, Minibatch Loss= 0.0000, Training Accuracy= 0.9929, Test Accuracy= 0.9304\n",
      "Step 1250, Minibatch Loss= 0.0000, Training Accuracy= 0.9937, Test Accuracy= 0.9296\n",
      "Step 1260, Minibatch Loss= 0.0000, Training Accuracy= 0.9930, Test Accuracy= 0.9277\n",
      "Step 1270, Minibatch Loss= 0.0001, Training Accuracy= 0.9904, Test Accuracy= 0.9393\n",
      "Step 1280, Minibatch Loss= 0.0001, Training Accuracy= 0.9925, Test Accuracy= 0.9396\n",
      "Step 1290, Minibatch Loss= 0.0001, Training Accuracy= 0.9909, Test Accuracy= 0.9323\n",
      "Step 1300, Minibatch Loss= 0.0001, Training Accuracy= 0.9913, Test Accuracy= 0.9364\n",
      "Step 1310, Minibatch Loss= 0.0000, Training Accuracy= 0.9930, Test Accuracy= 0.9434\n",
      "Step 1320, Minibatch Loss= 0.0001, Training Accuracy= 0.9909, Test Accuracy= 0.9320\n",
      "Step 1330, Minibatch Loss= 0.0001, Training Accuracy= 0.9901, Test Accuracy= 0.9437\n",
      "Step 1340, Minibatch Loss= 0.0001, Training Accuracy= 0.9921, Test Accuracy= 0.9244\n",
      "Step 1350, Minibatch Loss= 0.0001, Training Accuracy= 0.9923, Test Accuracy= 0.9291\n",
      "Step 1360, Minibatch Loss= 0.0001, Training Accuracy= 0.9909, Test Accuracy= 0.9285\n",
      "Step 1370, Minibatch Loss= 0.0001, Training Accuracy= 0.9922, Test Accuracy= 0.9435\n",
      "Step 1380, Minibatch Loss= 0.0000, Training Accuracy= 0.9933, Test Accuracy= 0.9319\n",
      "Step 1390, Minibatch Loss= 0.0001, Training Accuracy= 0.9896, Test Accuracy= 0.9192\n",
      "Step 1400, Minibatch Loss= 0.0001, Training Accuracy= 0.9901, Test Accuracy= 0.9298\n",
      "Step 1410, Minibatch Loss= 0.0001, Training Accuracy= 0.9910, Test Accuracy= 0.9164\n",
      "Step 1420, Minibatch Loss= 0.0001, Training Accuracy= 0.9920, Test Accuracy= 0.9172\n",
      "Step 1430, Minibatch Loss= 0.0001, Training Accuracy= 0.9914, Test Accuracy= 0.9264\n",
      "Step 1440, Minibatch Loss= 0.0000, Training Accuracy= 0.9936, Test Accuracy= 0.9319\n",
      "Step 1450, Minibatch Loss= 0.0001, Training Accuracy= 0.9911, Test Accuracy= 0.9326\n",
      "Step 1460, Minibatch Loss= 0.0001, Training Accuracy= 0.9881, Test Accuracy= 0.9251\n",
      "Step 1470, Minibatch Loss= 0.0000, Training Accuracy= 0.9935, Test Accuracy= 0.9144\n",
      "Step 1480, Minibatch Loss= 0.0001, Training Accuracy= 0.9909, Test Accuracy= 0.9281\n",
      "Step 1490, Minibatch Loss= 0.0000, Training Accuracy= 0.9935, Test Accuracy= 0.9262\n",
      "Step 1500, Minibatch Loss= 0.0000, Training Accuracy= 0.9937, Test Accuracy= 0.9241\n",
      "Step 1510, Minibatch Loss= 0.0001, Training Accuracy= 0.9928, Test Accuracy= 0.9239\n",
      "Step 1520, Minibatch Loss= 0.0000, Training Accuracy= 0.9936, Test Accuracy= 0.9244\n",
      "Step 1530, Minibatch Loss= 0.0000, Training Accuracy= 0.9938, Test Accuracy= 0.9358\n",
      "Step 1540, Minibatch Loss= 0.0000, Training Accuracy= 0.9934, Test Accuracy= 0.9336\n",
      "Step 1550, Minibatch Loss= 0.0001, Training Accuracy= 0.9923, Test Accuracy= 0.9077\n",
      "Step 1560, Minibatch Loss= 0.0001, Training Accuracy= 0.9927, Test Accuracy= 0.9035\n",
      "Step 1570, Minibatch Loss= 0.0000, Training Accuracy= 0.9937, Test Accuracy= 0.9186\n",
      "Step 1580, Minibatch Loss= 0.0001, Training Accuracy= 0.9929, Test Accuracy= 0.9218\n",
      "Step 1590, Minibatch Loss= 0.0001, Training Accuracy= 0.9919, Test Accuracy= 0.9284\n",
      "Step 1600, Minibatch Loss= 0.0001, Training Accuracy= 0.9898, Test Accuracy= 0.9442\n",
      "Step 1610, Minibatch Loss= 0.0001, Training Accuracy= 0.9888, Test Accuracy= 0.9192\n",
      "Step 1620, Minibatch Loss= 0.0001, Training Accuracy= 0.9903, Test Accuracy= 0.9316\n",
      "Step 1630, Minibatch Loss= 0.0001, Training Accuracy= 0.9926, Test Accuracy= 0.9252\n",
      "Step 1640, Minibatch Loss= 0.0000, Training Accuracy= 0.9931, Test Accuracy= 0.9245\n",
      "Step 1650, Minibatch Loss= 0.0001, Training Accuracy= 0.9908, Test Accuracy= 0.9121\n",
      "Step 1660, Minibatch Loss= 0.0001, Training Accuracy= 0.9928, Test Accuracy= 0.9253\n",
      "Step 1670, Minibatch Loss= 0.0001, Training Accuracy= 0.9923, Test Accuracy= 0.9245\n",
      "Step 1680, Minibatch Loss= 0.0001, Training Accuracy= 0.9916, Test Accuracy= 0.9234\n",
      "Step 1690, Minibatch Loss= 0.0001, Training Accuracy= 0.9903, Test Accuracy= 0.9344\n",
      "Step 1700, Minibatch Loss= 0.0001, Training Accuracy= 0.9910, Test Accuracy= 0.9213\n",
      "Step 1710, Minibatch Loss= 0.0001, Training Accuracy= 0.9892, Test Accuracy= 0.9050\n",
      "Step 1720, Minibatch Loss= 0.0001, Training Accuracy= 0.9928, Test Accuracy= 0.9289\n",
      "Step 1730, Minibatch Loss= 0.0000, Training Accuracy= 0.9934, Test Accuracy= 0.9262\n",
      "Step 1740, Minibatch Loss= 0.0001, Training Accuracy= 0.9879, Test Accuracy= 0.9090\n",
      "Step 1750, Minibatch Loss= 0.0001, Training Accuracy= 0.9917, Test Accuracy= 0.9316\n",
      "Step 1760, Minibatch Loss= 0.0000, Training Accuracy= 0.9935, Test Accuracy= 0.9308\n",
      "Step 1770, Minibatch Loss= 0.0000, Training Accuracy= 0.9932, Test Accuracy= 0.9236\n",
      "Step 1780, Minibatch Loss= 0.0001, Training Accuracy= 0.9928, Test Accuracy= 0.9184\n",
      "Step 1790, Minibatch Loss= 0.0001, Training Accuracy= 0.9920, Test Accuracy= 0.9086\n",
      "Step 1800, Minibatch Loss= 0.0001, Training Accuracy= 0.9909, Test Accuracy= 0.9172\n",
      "Step 1810, Minibatch Loss= 0.0000, Training Accuracy= 0.9940, Test Accuracy= 0.9251\n",
      "Step 1820, Minibatch Loss= 0.0000, Training Accuracy= 0.9932, Test Accuracy= 0.9244\n",
      "Step 1830, Minibatch Loss= 0.0000, Training Accuracy= 0.9929, Test Accuracy= 0.9227\n",
      "Step 1840, Minibatch Loss= 0.0001, Training Accuracy= 0.9885, Test Accuracy= 0.9400\n",
      "Step 1850, Minibatch Loss= 0.0000, Training Accuracy= 0.9937, Test Accuracy= 0.9228\n",
      "Step 1860, Minibatch Loss= 0.0000, Training Accuracy= 0.9935, Test Accuracy= 0.9135\n",
      "Step 1870, Minibatch Loss= 0.0000, Training Accuracy= 0.9929, Test Accuracy= 0.9224\n",
      "Step 1880, Minibatch Loss= 0.0001, Training Accuracy= 0.9927, Test Accuracy= 0.9309\n",
      "Step 1890, Minibatch Loss= 0.0001, Training Accuracy= 0.9914, Test Accuracy= 0.9137\n",
      "Step 1900, Minibatch Loss= 0.0000, Training Accuracy= 0.9938, Test Accuracy= 0.9274\n",
      "Step 1910, Minibatch Loss= 0.0000, Training Accuracy= 0.9932, Test Accuracy= 0.9285\n",
      "Step 1920, Minibatch Loss= 0.0001, Training Accuracy= 0.9926, Test Accuracy= 0.9144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1930, Minibatch Loss= 0.0002, Training Accuracy= 0.9872, Test Accuracy= 0.9066\n",
      "Step 1940, Minibatch Loss= 0.0001, Training Accuracy= 0.9891, Test Accuracy= 0.9215\n",
      "Step 1950, Minibatch Loss= 0.0001, Training Accuracy= 0.9918, Test Accuracy= 0.9092\n",
      "Step 1960, Minibatch Loss= 0.0000, Training Accuracy= 0.9931, Test Accuracy= 0.9211\n",
      "Step 1970, Minibatch Loss= 0.0001, Training Accuracy= 0.9926, Test Accuracy= 0.9246\n",
      "Step 1980, Minibatch Loss= 0.0001, Training Accuracy= 0.9918, Test Accuracy= 0.9134\n",
      "Step 1990, Minibatch Loss= 0.0000, Training Accuracy= 0.9934, Test Accuracy= 0.9323\n",
      "Step 2000, Minibatch Loss= 0.0000, Training Accuracy= 0.9931, Test Accuracy= 0.9339\n",
      "Step 2010, Minibatch Loss= 0.0001, Training Accuracy= 0.9910, Test Accuracy= 0.9191\n",
      "Step 2020, Minibatch Loss= 0.0001, Training Accuracy= 0.9890, Test Accuracy= 0.9225\n",
      "Step 2030, Minibatch Loss= 0.0000, Training Accuracy= 0.9937, Test Accuracy= 0.9338\n",
      "Step 2040, Minibatch Loss= 0.0001, Training Accuracy= 0.9921, Test Accuracy= 0.9299\n",
      "Step 2050, Minibatch Loss= 0.0001, Training Accuracy= 0.9925, Test Accuracy= 0.9198\n",
      "Step 2060, Minibatch Loss= 0.0001, Training Accuracy= 0.9925, Test Accuracy= 0.9183\n",
      "Step 2070, Minibatch Loss= 0.0000, Training Accuracy= 0.9940, Test Accuracy= 0.9326\n",
      "Step 2080, Minibatch Loss= 0.0001, Training Accuracy= 0.9908, Test Accuracy= 0.9221\n",
      "Step 2090, Minibatch Loss= 0.0001, Training Accuracy= 0.9898, Test Accuracy= 0.9069\n",
      "Step 2100, Minibatch Loss= 0.0001, Training Accuracy= 0.9918, Test Accuracy= 0.9065\n",
      "Step 2110, Minibatch Loss= 0.0001, Training Accuracy= 0.9907, Test Accuracy= 0.9196\n",
      "Step 2120, Minibatch Loss= 0.0000, Training Accuracy= 0.9941, Test Accuracy= 0.9323\n",
      "Step 2130, Minibatch Loss= 0.0001, Training Accuracy= 0.9911, Test Accuracy= 0.9211\n",
      "Step 2140, Minibatch Loss= 0.0001, Training Accuracy= 0.9908, Test Accuracy= 0.9163\n",
      "Step 2150, Minibatch Loss= 0.0000, Training Accuracy= 0.9935, Test Accuracy= 0.9326\n",
      "Step 2160, Minibatch Loss= 0.0000, Training Accuracy= 0.9930, Test Accuracy= 0.9179\n",
      "Step 2170, Minibatch Loss= 0.0003, Training Accuracy= 0.9841, Test Accuracy= 0.9026\n",
      "Step 2180, Minibatch Loss= 0.0001, Training Accuracy= 0.9928, Test Accuracy= 0.9016\n",
      "Step 2190, Minibatch Loss= 0.0001, Training Accuracy= 0.9904, Test Accuracy= 0.9076\n",
      "Step 2200, Minibatch Loss= 0.0001, Training Accuracy= 0.9919, Test Accuracy= 0.9019\n",
      "Step 2210, Minibatch Loss= 0.0001, Training Accuracy= 0.9923, Test Accuracy= 0.8974\n",
      "Step 2220, Minibatch Loss= 0.0002, Training Accuracy= 0.9867, Test Accuracy= 0.9199\n",
      "Step 2230, Minibatch Loss= 0.0001, Training Accuracy= 0.9922, Test Accuracy= 0.9056\n",
      "Step 2240, Minibatch Loss= 0.0001, Training Accuracy= 0.9908, Test Accuracy= 0.9163\n",
      "Step 2250, Minibatch Loss= 0.0000, Training Accuracy= 0.9933, Test Accuracy= 0.9355\n",
      "Step 2260, Minibatch Loss= 0.0001, Training Accuracy= 0.9917, Test Accuracy= 0.9337\n",
      "Step 2270, Minibatch Loss= 0.0001, Training Accuracy= 0.9927, Test Accuracy= 0.9355\n",
      "Step 2280, Minibatch Loss= 0.0001, Training Accuracy= 0.9923, Test Accuracy= 0.9148\n",
      "Step 2290, Minibatch Loss= 0.0001, Training Accuracy= 0.9910, Test Accuracy= 0.9254\n",
      "Step 2300, Minibatch Loss= 0.0000, Training Accuracy= 0.9930, Test Accuracy= 0.9168\n",
      "Step 2310, Minibatch Loss= 0.0000, Training Accuracy= 0.9938, Test Accuracy= 0.9248\n",
      "Step 2320, Minibatch Loss= 0.0000, Training Accuracy= 0.9933, Test Accuracy= 0.9227\n",
      "Step 2330, Minibatch Loss= 0.0000, Training Accuracy= 0.9933, Test Accuracy= 0.9304\n",
      "Step 2340, Minibatch Loss= 0.0001, Training Accuracy= 0.9923, Test Accuracy= 0.9419\n",
      "Step 2350, Minibatch Loss= 0.0001, Training Accuracy= 0.9913, Test Accuracy= 0.9288\n",
      "Step 2360, Minibatch Loss= 0.0000, Training Accuracy= 0.9940, Test Accuracy= 0.9356\n",
      "Step 2370, Minibatch Loss= 0.0001, Training Accuracy= 0.9898, Test Accuracy= 0.9432\n",
      "Step 2380, Minibatch Loss= 0.0000, Training Accuracy= 0.9932, Test Accuracy= 0.9319\n",
      "Step 2390, Minibatch Loss= 0.0001, Training Accuracy= 0.9914, Test Accuracy= 0.9357\n",
      "Step 2400, Minibatch Loss= 0.0000, Training Accuracy= 0.9941, Test Accuracy= 0.9304\n",
      "Step 2410, Minibatch Loss= 0.0000, Training Accuracy= 0.9932, Test Accuracy= 0.9151\n",
      "Step 2420, Minibatch Loss= 0.0000, Training Accuracy= 0.9933, Test Accuracy= 0.9174\n",
      "Step 2430, Minibatch Loss= 0.0001, Training Accuracy= 0.9921, Test Accuracy= 0.9170\n",
      "Step 2440, Minibatch Loss= 0.0001, Training Accuracy= 0.9911, Test Accuracy= 0.9109\n",
      "Step 2450, Minibatch Loss= 0.0000, Training Accuracy= 0.9932, Test Accuracy= 0.9364\n",
      "Step 2460, Minibatch Loss= 0.0001, Training Accuracy= 0.9910, Test Accuracy= 0.9088\n",
      "Step 2470, Minibatch Loss= 0.0001, Training Accuracy= 0.9928, Test Accuracy= 0.9150\n",
      "Step 2480, Minibatch Loss= 0.0001, Training Accuracy= 0.9916, Test Accuracy= 0.9386\n",
      "Step 2490, Minibatch Loss= 0.0001, Training Accuracy= 0.9923, Test Accuracy= 0.9199\n",
      "Step 2500, Minibatch Loss= 0.0001, Training Accuracy= 0.9891, Test Accuracy= 0.9464\n",
      "Step 2510, Minibatch Loss= 0.0002, Training Accuracy= 0.9852, Test Accuracy= 0.8877\n",
      "Step 2520, Minibatch Loss= 0.0001, Training Accuracy= 0.9925, Test Accuracy= 0.9122\n",
      "Step 2530, Minibatch Loss= 0.0002, Training Accuracy= 0.9868, Test Accuracy= 0.9293\n",
      "Step 2540, Minibatch Loss= 0.0001, Training Accuracy= 0.9897, Test Accuracy= 0.9217\n",
      "Step 2550, Minibatch Loss= 0.0001, Training Accuracy= 0.9895, Test Accuracy= 0.9143\n",
      "Step 2560, Minibatch Loss= 0.0001, Training Accuracy= 0.9926, Test Accuracy= 0.9510\n",
      "Step 2570, Minibatch Loss= 0.0001, Training Accuracy= 0.9908, Test Accuracy= 0.9604\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 2580, Minibatch Loss= 0.0001, Training Accuracy= 0.9926, Test Accuracy= 0.9365\n",
      "Step 2590, Minibatch Loss= 0.0000, Training Accuracy= 0.9938, Test Accuracy= 0.9533\n",
      "Step 2600, Minibatch Loss= 0.0000, Training Accuracy= 0.9938, Test Accuracy= 0.9544\n",
      "Step 2610, Minibatch Loss= 0.0001, Training Accuracy= 0.9923, Test Accuracy= 0.9762\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 2620, Minibatch Loss= 0.0001, Training Accuracy= 0.9900, Test Accuracy= 0.9212\n",
      "Step 2630, Minibatch Loss= 0.0001, Training Accuracy= 0.9924, Test Accuracy= 0.9545\n",
      "Step 2640, Minibatch Loss= 0.0001, Training Accuracy= 0.9903, Test Accuracy= 0.9290\n",
      "Step 2650, Minibatch Loss= 0.0000, Training Accuracy= 0.9937, Test Accuracy= 0.9466\n",
      "Step 2660, Minibatch Loss= 0.0001, Training Accuracy= 0.9914, Test Accuracy= 0.9547\n",
      "Step 2670, Minibatch Loss= 0.0001, Training Accuracy= 0.9914, Test Accuracy= 0.9442\n",
      "Step 2680, Minibatch Loss= 0.0000, Training Accuracy= 0.9937, Test Accuracy= 0.9543\n",
      "Step 2690, Minibatch Loss= 0.0001, Training Accuracy= 0.9906, Test Accuracy= 0.9773\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 2700, Minibatch Loss= 0.0000, Training Accuracy= 0.9936, Test Accuracy= 0.9547\n",
      "Step 2710, Minibatch Loss= 0.0001, Training Accuracy= 0.9879, Test Accuracy= 0.9163\n",
      "Step 2720, Minibatch Loss= 0.0001, Training Accuracy= 0.9911, Test Accuracy= 0.9441\n",
      "Step 2730, Minibatch Loss= 0.0000, Training Accuracy= 0.9944, Test Accuracy= 0.9572\n",
      "Step 2740, Minibatch Loss= 0.0000, Training Accuracy= 0.9945, Test Accuracy= 0.9551\n",
      "Step 2750, Minibatch Loss= 0.0000, Training Accuracy= 0.9938, Test Accuracy= 0.9668\n",
      "Step 2760, Minibatch Loss= 0.0001, Training Accuracy= 0.9919, Test Accuracy= 0.9686\n",
      "Step 2770, Minibatch Loss= 0.0001, Training Accuracy= 0.9914, Test Accuracy= 0.9678\n",
      "Step 2780, Minibatch Loss= 0.0001, Training Accuracy= 0.9909, Test Accuracy= 0.9580\n",
      "Step 2790, Minibatch Loss= 0.0001, Training Accuracy= 0.9919, Test Accuracy= 0.9630\n",
      "Step 2800, Minibatch Loss= 0.0001, Training Accuracy= 0.9922, Test Accuracy= 0.9119\n",
      "Step 2810, Minibatch Loss= 0.0000, Training Accuracy= 0.9935, Test Accuracy= 0.9171\n",
      "Step 2820, Minibatch Loss= 0.0001, Training Accuracy= 0.9920, Test Accuracy= 0.9165\n",
      "Step 2830, Minibatch Loss= 0.0002, Training Accuracy= 0.9865, Test Accuracy= 0.9189\n",
      "Step 2840, Minibatch Loss= 0.0001, Training Accuracy= 0.9910, Test Accuracy= 0.9421\n",
      "Step 2850, Minibatch Loss= 0.0001, Training Accuracy= 0.9918, Test Accuracy= 0.9351\n",
      "Step 2860, Minibatch Loss= 0.0000, Training Accuracy= 0.9933, Test Accuracy= 0.9741\n",
      "Step 2870, Minibatch Loss= 0.0000, Training Accuracy= 0.9938, Test Accuracy= 0.9553\n",
      "Step 2880, Minibatch Loss= 0.0000, Training Accuracy= 0.9934, Test Accuracy= 0.9692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2890, Minibatch Loss= 0.0001, Training Accuracy= 0.9902, Test Accuracy= 0.9379\n",
      "Step 2900, Minibatch Loss= 0.0001, Training Accuracy= 0.9927, Test Accuracy= 0.9438\n",
      "Step 2910, Minibatch Loss= 0.0001, Training Accuracy= 0.9922, Test Accuracy= 0.9504\n",
      "Step 2920, Minibatch Loss= 0.0000, Training Accuracy= 0.9946, Test Accuracy= 0.9673\n",
      "Step 2930, Minibatch Loss= 0.0000, Training Accuracy= 0.9932, Test Accuracy= 0.9500\n",
      "Step 2940, Minibatch Loss= 0.0000, Training Accuracy= 0.9938, Test Accuracy= 0.9629\n",
      "Step 2950, Minibatch Loss= 0.0001, Training Accuracy= 0.9913, Test Accuracy= 0.9742\n",
      "Step 2960, Minibatch Loss= 0.0001, Training Accuracy= 0.9918, Test Accuracy= 0.9620\n",
      "Step 2970, Minibatch Loss= 0.0000, Training Accuracy= 0.9936, Test Accuracy= 0.9712\n",
      "Step 2980, Minibatch Loss= 0.0001, Training Accuracy= 0.9921, Test Accuracy= 0.9416\n",
      "Step 2990, Minibatch Loss= 0.0000, Training Accuracy= 0.9940, Test Accuracy= 0.9528\n",
      "Step 3000, Minibatch Loss= 0.0001, Training Accuracy= 0.9912, Test Accuracy= 0.9302\n",
      "Step 3010, Minibatch Loss= 0.0000, Training Accuracy= 0.9943, Test Accuracy= 0.9431\n",
      "Step 3020, Minibatch Loss= 0.0000, Training Accuracy= 0.9941, Test Accuracy= 0.9250\n",
      "Step 3030, Minibatch Loss= 0.0000, Training Accuracy= 0.9943, Test Accuracy= 0.9319\n",
      "Step 3040, Minibatch Loss= 0.0000, Training Accuracy= 0.9933, Test Accuracy= 0.9436\n",
      "Step 3050, Minibatch Loss= 0.0001, Training Accuracy= 0.9908, Test Accuracy= 0.9780\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 3060, Minibatch Loss= 0.0001, Training Accuracy= 0.9912, Test Accuracy= 0.9732\n",
      "Step 3070, Minibatch Loss= 0.0000, Training Accuracy= 0.9943, Test Accuracy= 0.9362\n",
      "Step 3080, Minibatch Loss= 0.0001, Training Accuracy= 0.9924, Test Accuracy= 0.9336\n",
      "Step 3090, Minibatch Loss= 0.0001, Training Accuracy= 0.9915, Test Accuracy= 0.9396\n",
      "Step 3100, Minibatch Loss= 0.0000, Training Accuracy= 0.9936, Test Accuracy= 0.9413\n",
      "Step 3110, Minibatch Loss= 0.0001, Training Accuracy= 0.9920, Test Accuracy= 0.9429\n",
      "Step 3120, Minibatch Loss= 0.0000, Training Accuracy= 0.9941, Test Accuracy= 0.9370\n",
      "Step 3130, Minibatch Loss= 0.0001, Training Accuracy= 0.9917, Test Accuracy= 0.9511\n",
      "Step 3140, Minibatch Loss= 0.0001, Training Accuracy= 0.9915, Test Accuracy= 0.9418\n",
      "Step 3150, Minibatch Loss= 0.0001, Training Accuracy= 0.9913, Test Accuracy= 0.9403\n",
      "Step 3160, Minibatch Loss= 0.0000, Training Accuracy= 0.9938, Test Accuracy= 0.9446\n",
      "Step 3170, Minibatch Loss= 0.0001, Training Accuracy= 0.9906, Test Accuracy= 0.9411\n",
      "Step 3180, Minibatch Loss= 0.0001, Training Accuracy= 0.9903, Test Accuracy= 0.9232\n",
      "Step 3190, Minibatch Loss= 0.0000, Training Accuracy= 0.9941, Test Accuracy= 0.9500\n",
      "Step 3200, Minibatch Loss= 0.0001, Training Accuracy= 0.9911, Test Accuracy= 0.9730\n",
      "Step 3210, Minibatch Loss= 0.0001, Training Accuracy= 0.9896, Test Accuracy= 0.9638\n",
      "Step 3220, Minibatch Loss= 0.0002, Training Accuracy= 0.9871, Test Accuracy= 0.9723\n",
      "Step 3230, Minibatch Loss= 0.0001, Training Accuracy= 0.9908, Test Accuracy= 0.9035\n",
      "Step 3240, Minibatch Loss= 0.0001, Training Accuracy= 0.9908, Test Accuracy= 0.9454\n",
      "Step 3250, Minibatch Loss= 0.0001, Training Accuracy= 0.9927, Test Accuracy= 0.9330\n",
      "Step 3260, Minibatch Loss= 0.0001, Training Accuracy= 0.9918, Test Accuracy= 0.9406\n",
      "Step 3270, Minibatch Loss= 0.0000, Training Accuracy= 0.9935, Test Accuracy= 0.9596\n",
      "Step 3280, Minibatch Loss= 0.0001, Training Accuracy= 0.9928, Test Accuracy= 0.9337\n",
      "Step 3290, Minibatch Loss= 0.0002, Training Accuracy= 0.9860, Test Accuracy= 0.9545\n",
      "Step 3300, Minibatch Loss= 0.0001, Training Accuracy= 0.9920, Test Accuracy= 0.9231\n",
      "Step 3310, Minibatch Loss= 0.0001, Training Accuracy= 0.9899, Test Accuracy= 0.9150\n",
      "Step 3320, Minibatch Loss= 0.0000, Training Accuracy= 0.9935, Test Accuracy= 0.9409\n",
      "Step 3330, Minibatch Loss= 0.0000, Training Accuracy= 0.9935, Test Accuracy= 0.9800\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 3340, Minibatch Loss= 0.0000, Training Accuracy= 0.9941, Test Accuracy= 0.9577\n",
      "Step 3350, Minibatch Loss= 0.0000, Training Accuracy= 0.9939, Test Accuracy= 0.9431\n",
      "Step 3360, Minibatch Loss= 0.0001, Training Accuracy= 0.9928, Test Accuracy= 0.9742\n",
      "Step 3370, Minibatch Loss= 0.0000, Training Accuracy= 0.9937, Test Accuracy= 0.9430\n",
      "Step 3380, Minibatch Loss= 0.0000, Training Accuracy= 0.9941, Test Accuracy= 0.9694\n",
      "Step 3390, Minibatch Loss= 0.0000, Training Accuracy= 0.9942, Test Accuracy= 0.9493\n",
      "Step 3400, Minibatch Loss= 0.0000, Training Accuracy= 0.9938, Test Accuracy= 0.9663\n",
      "Step 3410, Minibatch Loss= 0.0001, Training Accuracy= 0.9913, Test Accuracy= 0.9383\n",
      "Step 3420, Minibatch Loss= 0.0002, Training Accuracy= 0.9872, Test Accuracy= 0.8908\n",
      "Step 3430, Minibatch Loss= 0.0001, Training Accuracy= 0.9914, Test Accuracy= 0.9408\n",
      "Step 3440, Minibatch Loss= 0.0001, Training Accuracy= 0.9916, Test Accuracy= 0.9432\n",
      "Step 3450, Minibatch Loss= 0.0001, Training Accuracy= 0.9919, Test Accuracy= 0.9709\n",
      "Step 3460, Minibatch Loss= 0.0000, Training Accuracy= 0.9939, Test Accuracy= 0.9312\n",
      "Step 3470, Minibatch Loss= 0.0001, Training Accuracy= 0.9918, Test Accuracy= 0.9576\n",
      "Step 3480, Minibatch Loss= 0.0001, Training Accuracy= 0.9907, Test Accuracy= 0.9238\n",
      "Step 3490, Minibatch Loss= 0.0001, Training Accuracy= 0.9905, Test Accuracy= 0.9553\n",
      "Step 3500, Minibatch Loss= 0.0000, Training Accuracy= 0.9937, Test Accuracy= 0.9441\n",
      "Step 3510, Minibatch Loss= 0.0000, Training Accuracy= 0.9935, Test Accuracy= 0.9611\n",
      "Step 3520, Minibatch Loss= 0.0000, Training Accuracy= 0.9942, Test Accuracy= 0.9586\n",
      "Step 3530, Minibatch Loss= 0.0000, Training Accuracy= 0.9939, Test Accuracy= 0.9689\n",
      "Step 3540, Minibatch Loss= 0.0001, Training Accuracy= 0.9916, Test Accuracy= 0.9218\n",
      "Step 3550, Minibatch Loss= 0.0000, Training Accuracy= 0.9942, Test Accuracy= 0.9330\n",
      "Step 3560, Minibatch Loss= 0.0001, Training Accuracy= 0.9901, Test Accuracy= 0.9746\n",
      "Step 3570, Minibatch Loss= 0.0001, Training Accuracy= 0.9926, Test Accuracy= 0.9277\n",
      "Step 3580, Minibatch Loss= 0.0001, Training Accuracy= 0.9913, Test Accuracy= 0.9634\n",
      "Step 3590, Minibatch Loss= 0.0001, Training Accuracy= 0.9912, Test Accuracy= 0.9407\n",
      "Step 3600, Minibatch Loss= 0.0001, Training Accuracy= 0.9912, Test Accuracy= 0.9508\n",
      "Step 3610, Minibatch Loss= 0.0001, Training Accuracy= 0.9917, Test Accuracy= 0.9373\n",
      "Step 3620, Minibatch Loss= 0.0001, Training Accuracy= 0.9919, Test Accuracy= 0.9704\n",
      "Step 3630, Minibatch Loss= 0.0001, Training Accuracy= 0.9925, Test Accuracy= 0.9438\n",
      "Step 3640, Minibatch Loss= 0.0001, Training Accuracy= 0.9913, Test Accuracy= 0.9733\n",
      "Step 3650, Minibatch Loss= 0.0000, Training Accuracy= 0.9938, Test Accuracy= 0.9507\n",
      "Step 3660, Minibatch Loss= 0.0001, Training Accuracy= 0.9896, Test Accuracy= 0.9192\n",
      "Step 3670, Minibatch Loss= 0.0001, Training Accuracy= 0.9898, Test Accuracy= 0.9429\n",
      "Step 3680, Minibatch Loss= 0.0001, Training Accuracy= 0.9889, Test Accuracy= 0.9080\n",
      "Step 3690, Minibatch Loss= 0.0001, Training Accuracy= 0.9889, Test Accuracy= 0.9399\n",
      "Step 3700, Minibatch Loss= 0.0001, Training Accuracy= 0.9910, Test Accuracy= 0.9132\n",
      "Step 3710, Minibatch Loss= 0.0001, Training Accuracy= 0.9894, Test Accuracy= 0.9506\n",
      "Step 3720, Minibatch Loss= 0.0002, Training Accuracy= 0.9872, Test Accuracy= 0.8953\n",
      "Step 3730, Minibatch Loss= 0.0001, Training Accuracy= 0.9906, Test Accuracy= 0.8981\n",
      "Step 3740, Minibatch Loss= 0.0001, Training Accuracy= 0.9919, Test Accuracy= 0.9293\n",
      "Step 3750, Minibatch Loss= 0.0001, Training Accuracy= 0.9907, Test Accuracy= 0.9690\n",
      "Step 3760, Minibatch Loss= 0.0000, Training Accuracy= 0.9931, Test Accuracy= 0.9361\n",
      "Step 3770, Minibatch Loss= 0.0000, Training Accuracy= 0.9939, Test Accuracy= 0.9393\n",
      "Step 3780, Minibatch Loss= 0.0000, Training Accuracy= 0.9940, Test Accuracy= 0.9506\n",
      "Step 3790, Minibatch Loss= 0.0000, Training Accuracy= 0.9931, Test Accuracy= 0.9636\n",
      "Step 3800, Minibatch Loss= 0.0000, Training Accuracy= 0.9941, Test Accuracy= 0.9594\n",
      "Step 3810, Minibatch Loss= 0.0001, Training Accuracy= 0.9922, Test Accuracy= 0.9710\n",
      "Step 3820, Minibatch Loss= 0.0001, Training Accuracy= 0.9913, Test Accuracy= 0.9254\n",
      "Step 3830, Minibatch Loss= 0.0000, Training Accuracy= 0.9938, Test Accuracy= 0.9670\n",
      "Step 3840, Minibatch Loss= 0.0000, Training Accuracy= 0.9945, Test Accuracy= 0.9738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3850, Minibatch Loss= 0.0000, Training Accuracy= 0.9938, Test Accuracy= 0.9631\n",
      "Step 3860, Minibatch Loss= 0.0000, Training Accuracy= 0.9932, Test Accuracy= 0.9397\n",
      "Step 3870, Minibatch Loss= 0.0001, Training Accuracy= 0.9927, Test Accuracy= 0.9561\n",
      "Step 3880, Minibatch Loss= 0.0001, Training Accuracy= 0.9888, Test Accuracy= 0.9143\n",
      "Step 3890, Minibatch Loss= 0.0001, Training Accuracy= 0.9879, Test Accuracy= 0.9840\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 3900, Minibatch Loss= 0.0002, Training Accuracy= 0.9860, Test Accuracy= 0.9032\n",
      "Step 3910, Minibatch Loss= 0.0001, Training Accuracy= 0.9888, Test Accuracy= 0.8927\n",
      "Step 3920, Minibatch Loss= 0.0000, Training Accuracy= 0.9935, Test Accuracy= 0.9351\n",
      "Step 3930, Minibatch Loss= 0.0001, Training Accuracy= 0.9916, Test Accuracy= 0.9433\n",
      "Step 3940, Minibatch Loss= 0.0000, Training Accuracy= 0.9936, Test Accuracy= 0.9574\n",
      "Step 3950, Minibatch Loss= 0.0001, Training Accuracy= 0.9922, Test Accuracy= 0.9392\n",
      "Step 3960, Minibatch Loss= 0.0000, Training Accuracy= 0.9934, Test Accuracy= 0.9445\n",
      "Step 3970, Minibatch Loss= 0.0001, Training Accuracy= 0.9917, Test Accuracy= 0.9368\n",
      "Step 3980, Minibatch Loss= 0.0000, Training Accuracy= 0.9937, Test Accuracy= 0.9432\n",
      "Step 3990, Minibatch Loss= 0.0001, Training Accuracy= 0.9909, Test Accuracy= 0.9320\n",
      "Step 4000, Minibatch Loss= 0.0000, Training Accuracy= 0.9937, Test Accuracy= 0.9433\n",
      "Step 4010, Minibatch Loss= 0.0000, Training Accuracy= 0.9938, Test Accuracy= 0.9487\n",
      "Step 4020, Minibatch Loss= 0.0001, Training Accuracy= 0.9918, Test Accuracy= 0.9451\n",
      "Step 4030, Minibatch Loss= 0.0000, Training Accuracy= 0.9942, Test Accuracy= 0.9523\n",
      "Step 4040, Minibatch Loss= 0.0000, Training Accuracy= 0.9938, Test Accuracy= 0.9328\n",
      "Step 4050, Minibatch Loss= 0.0000, Training Accuracy= 0.9937, Test Accuracy= 0.9407\n",
      "Step 4060, Minibatch Loss= 0.0000, Training Accuracy= 0.9929, Test Accuracy= 0.9374\n",
      "Step 4070, Minibatch Loss= 0.0000, Training Accuracy= 0.9943, Test Accuracy= 0.9506\n",
      "Step 4080, Minibatch Loss= 0.0000, Training Accuracy= 0.9946, Test Accuracy= 0.9444\n",
      "Step 4090, Minibatch Loss= 0.0000, Training Accuracy= 0.9937, Test Accuracy= 0.9402\n",
      "Step 4100, Minibatch Loss= 0.0001, Training Accuracy= 0.9926, Test Accuracy= 0.9226\n",
      "Step 4110, Minibatch Loss= 0.0000, Training Accuracy= 0.9932, Test Accuracy= 0.9527\n",
      "Step 4120, Minibatch Loss= 0.0000, Training Accuracy= 0.9941, Test Accuracy= 0.9465\n",
      "Step 4130, Minibatch Loss= 0.0001, Training Accuracy= 0.9918, Test Accuracy= 0.9273\n",
      "Step 4140, Minibatch Loss= 0.0001, Training Accuracy= 0.9884, Test Accuracy= 0.9504\n",
      "Step 4150, Minibatch Loss= 0.0003, Training Accuracy= 0.9834, Test Accuracy= 0.8858\n",
      "Step 4160, Minibatch Loss= 0.0001, Training Accuracy= 0.9920, Test Accuracy= 0.9222\n",
      "Step 4170, Minibatch Loss= 0.0001, Training Accuracy= 0.9910, Test Accuracy= 0.9667\n",
      "Step 4180, Minibatch Loss= 0.0001, Training Accuracy= 0.9909, Test Accuracy= 0.9541\n",
      "Step 4190, Minibatch Loss= 0.0001, Training Accuracy= 0.9921, Test Accuracy= 0.9711\n",
      "Step 4200, Minibatch Loss= 0.0000, Training Accuracy= 0.9942, Test Accuracy= 0.9512\n",
      "Step 4210, Minibatch Loss= 0.0001, Training Accuracy= 0.9917, Test Accuracy= 0.9511\n",
      "Step 4220, Minibatch Loss= 0.0000, Training Accuracy= 0.9938, Test Accuracy= 0.9457\n",
      "Step 4230, Minibatch Loss= 0.0000, Training Accuracy= 0.9934, Test Accuracy= 0.9367\n",
      "Step 4240, Minibatch Loss= 0.0001, Training Accuracy= 0.9907, Test Accuracy= 0.9704\n",
      "Step 4250, Minibatch Loss= 0.0000, Training Accuracy= 0.9940, Test Accuracy= 0.9554\n",
      "Step 4260, Minibatch Loss= 0.0000, Training Accuracy= 0.9940, Test Accuracy= 0.9517\n",
      "Step 4270, Minibatch Loss= 0.0001, Training Accuracy= 0.9917, Test Accuracy= 0.9716\n",
      "Step 4280, Minibatch Loss= 0.0001, Training Accuracy= 0.9911, Test Accuracy= 0.9277\n",
      "Step 4290, Minibatch Loss= 0.0000, Training Accuracy= 0.9944, Test Accuracy= 0.9424\n",
      "Step 4300, Minibatch Loss= 0.0001, Training Accuracy= 0.9911, Test Accuracy= 0.9350\n",
      "Step 4310, Minibatch Loss= 0.0000, Training Accuracy= 0.9940, Test Accuracy= 0.9472\n",
      "Step 4320, Minibatch Loss= 0.0000, Training Accuracy= 0.9947, Test Accuracy= 0.9543\n",
      "Step 4330, Minibatch Loss= 0.0000, Training Accuracy= 0.9935, Test Accuracy= 0.9716\n",
      "Step 4340, Minibatch Loss= 0.0000, Training Accuracy= 0.9929, Test Accuracy= 0.9327\n",
      "Step 4350, Minibatch Loss= 0.0000, Training Accuracy= 0.9930, Test Accuracy= 0.9364\n",
      "Step 4360, Minibatch Loss= 0.0000, Training Accuracy= 0.9932, Test Accuracy= 0.9481\n",
      "Step 4370, Minibatch Loss= 0.0001, Training Accuracy= 0.9929, Test Accuracy= 0.9373\n",
      "Step 4380, Minibatch Loss= 0.0001, Training Accuracy= 0.9897, Test Accuracy= 0.9690\n",
      "Step 4390, Minibatch Loss= 0.0000, Training Accuracy= 0.9934, Test Accuracy= 0.9350\n",
      "Step 4400, Minibatch Loss= 0.0001, Training Accuracy= 0.9916, Test Accuracy= 0.9624\n",
      "Step 4410, Minibatch Loss= 0.0001, Training Accuracy= 0.9899, Test Accuracy= 0.9142\n",
      "Step 4420, Minibatch Loss= 0.0001, Training Accuracy= 0.9926, Test Accuracy= 0.9084\n",
      "Step 4430, Minibatch Loss= 0.0001, Training Accuracy= 0.9893, Test Accuracy= 0.9488\n",
      "Step 4440, Minibatch Loss= 0.0001, Training Accuracy= 0.9918, Test Accuracy= 0.9304\n",
      "Step 4450, Minibatch Loss= 0.0000, Training Accuracy= 0.9945, Test Accuracy= 0.9514\n",
      "Step 4460, Minibatch Loss= 0.0000, Training Accuracy= 0.9935, Test Accuracy= 0.9680\n",
      "Step 4470, Minibatch Loss= 0.0001, Training Accuracy= 0.9916, Test Accuracy= 0.9366\n",
      "Step 4480, Minibatch Loss= 0.0000, Training Accuracy= 0.9939, Test Accuracy= 0.9338\n",
      "Step 4490, Minibatch Loss= 0.0001, Training Accuracy= 0.9920, Test Accuracy= 0.9556\n",
      "Step 4500, Minibatch Loss= 0.0000, Training Accuracy= 0.9930, Test Accuracy= 0.9324\n",
      "Step 4510, Minibatch Loss= 0.0001, Training Accuracy= 0.9923, Test Accuracy= 0.9726\n",
      "Step 4520, Minibatch Loss= 0.0001, Training Accuracy= 0.9909, Test Accuracy= 0.9204\n",
      "Step 4530, Minibatch Loss= 0.0001, Training Accuracy= 0.9915, Test Accuracy= 0.9512\n",
      "Step 4540, Minibatch Loss= 0.0000, Training Accuracy= 0.9932, Test Accuracy= 0.9648\n",
      "Step 4550, Minibatch Loss= 0.0000, Training Accuracy= 0.9931, Test Accuracy= 0.9376\n",
      "Step 4560, Minibatch Loss= 0.0001, Training Accuracy= 0.9916, Test Accuracy= 0.9645\n",
      "Step 4570, Minibatch Loss= 0.0001, Training Accuracy= 0.9900, Test Accuracy= 0.9206\n",
      "Step 4580, Minibatch Loss= 0.0000, Training Accuracy= 0.9938, Test Accuracy= 0.9368\n",
      "Step 4590, Minibatch Loss= 0.0000, Training Accuracy= 0.9944, Test Accuracy= 0.9479\n",
      "Step 4600, Minibatch Loss= 0.0000, Training Accuracy= 0.9935, Test Accuracy= 0.9380\n",
      "Step 4610, Minibatch Loss= 0.0000, Training Accuracy= 0.9930, Test Accuracy= 0.9269\n",
      "Step 4620, Minibatch Loss= 0.0000, Training Accuracy= 0.9936, Test Accuracy= 0.9691\n",
      "Step 4630, Minibatch Loss= 0.0000, Training Accuracy= 0.9944, Test Accuracy= 0.9490\n",
      "Step 4640, Minibatch Loss= 0.0000, Training Accuracy= 0.9944, Test Accuracy= 0.9681\n",
      "Step 4650, Minibatch Loss= 0.0001, Training Accuracy= 0.9917, Test Accuracy= 0.9603\n",
      "Step 4660, Minibatch Loss= 0.0000, Training Accuracy= 0.9934, Test Accuracy= 0.9628\n",
      "Step 4670, Minibatch Loss= 0.0001, Training Accuracy= 0.9912, Test Accuracy= 0.9778\n",
      "Step 4680, Minibatch Loss= 0.0001, Training Accuracy= 0.9922, Test Accuracy= 0.9425\n",
      "Step 4690, Minibatch Loss= 0.0000, Training Accuracy= 0.9933, Test Accuracy= 0.9331\n",
      "Step 4700, Minibatch Loss= 0.0000, Training Accuracy= 0.9944, Test Accuracy= 0.9516\n",
      "Step 4710, Minibatch Loss= 0.0000, Training Accuracy= 0.9938, Test Accuracy= 0.9517\n",
      "Step 4720, Minibatch Loss= 0.0000, Training Accuracy= 0.9950, Test Accuracy= 0.9384\n",
      "Step 4730, Minibatch Loss= 0.0000, Training Accuracy= 0.9950, Test Accuracy= 0.9425\n",
      "Step 4740, Minibatch Loss= 0.0000, Training Accuracy= 0.9948, Test Accuracy= 0.9488\n",
      "Step 4750, Minibatch Loss= 0.0001, Training Accuracy= 0.9914, Test Accuracy= 0.9468\n",
      "Step 4760, Minibatch Loss= 0.0000, Training Accuracy= 0.9942, Test Accuracy= 0.9633\n",
      "Step 4770, Minibatch Loss= 0.0000, Training Accuracy= 0.9939, Test Accuracy= 0.9643\n",
      "Step 4780, Minibatch Loss= 0.0001, Training Accuracy= 0.9926, Test Accuracy= 0.9795\n",
      "Step 4790, Minibatch Loss= 0.0001, Training Accuracy= 0.9921, Test Accuracy= 0.9640\n",
      "Step 4800, Minibatch Loss= 0.0000, Training Accuracy= 0.9936, Test Accuracy= 0.9513\n",
      "Step 4810, Minibatch Loss= 0.0001, Training Accuracy= 0.9927, Test Accuracy= 0.9826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4820, Minibatch Loss= 0.0001, Training Accuracy= 0.9927, Test Accuracy= 0.9194\n",
      "Step 4830, Minibatch Loss= 0.0001, Training Accuracy= 0.9928, Test Accuracy= 0.9649\n",
      "Step 4840, Minibatch Loss= 0.0002, Training Accuracy= 0.9867, Test Accuracy= 0.8991\n",
      "Step 4850, Minibatch Loss= 0.0001, Training Accuracy= 0.9916, Test Accuracy= 0.9831\n",
      "Step 4860, Minibatch Loss= 0.0001, Training Accuracy= 0.9882, Test Accuracy= 0.9221\n",
      "Step 4870, Minibatch Loss= 0.0001, Training Accuracy= 0.9890, Test Accuracy= 0.9857\n",
      "Model saved in path: /home/rubensvectomobile/BOVESPA/real/model.ckpt\n",
      "Step 4880, Minibatch Loss= 0.0001, Training Accuracy= 0.9906, Test Accuracy= 0.9674\n",
      "Step 4890, Minibatch Loss= 0.0001, Training Accuracy= 0.9919, Test Accuracy= 0.9695\n",
      "Step 4900, Minibatch Loss= 0.0001, Training Accuracy= 0.9896, Test Accuracy= 0.9507\n",
      "Step 4910, Minibatch Loss= 0.0001, Training Accuracy= 0.9922, Test Accuracy= 0.9494\n",
      "Step 4920, Minibatch Loss= 0.0001, Training Accuracy= 0.9912, Test Accuracy= 0.9671\n",
      "Step 4930, Minibatch Loss= 0.0000, Training Accuracy= 0.9943, Test Accuracy= 0.9570\n",
      "Step 4940, Minibatch Loss= 0.0000, Training Accuracy= 0.9940, Test Accuracy= 0.9652\n",
      "Step 4950, Minibatch Loss= 0.0001, Training Accuracy= 0.9915, Test Accuracy= 0.9384\n",
      "Step 4960, Minibatch Loss= 0.0000, Training Accuracy= 0.9935, Test Accuracy= 0.9570\n",
      "Step 4970, Minibatch Loss= 0.0000, Training Accuracy= 0.9934, Test Accuracy= 0.9596\n",
      "Step 4980, Minibatch Loss= 0.0000, Training Accuracy= 0.9944, Test Accuracy= 0.9515\n",
      "Step 4990, Minibatch Loss= 0.0000, Training Accuracy= 0.9940, Test Accuracy= 0.9397\n",
      "Step 5000, Minibatch Loss= 0.0000, Training Accuracy= 0.9932, Test Accuracy= 0.9778\n",
      "Step 5010, Minibatch Loss= 0.0000, Training Accuracy= 0.9943, Test Accuracy= 0.9397\n",
      "Step 5020, Minibatch Loss= 0.0000, Training Accuracy= 0.9937, Test Accuracy= 0.9750\n",
      "Step 5030, Minibatch Loss= 0.0000, Training Accuracy= 0.9931, Test Accuracy= 0.9791\n",
      "Step 5040, Minibatch Loss= 0.0001, Training Accuracy= 0.9885, Test Accuracy= 0.9081\n",
      "Step 5050, Minibatch Loss= 0.0001, Training Accuracy= 0.9914, Test Accuracy= 0.9669\n",
      "Step 5060, Minibatch Loss= 0.0001, Training Accuracy= 0.9929, Test Accuracy= 0.9411\n",
      "Step 5070, Minibatch Loss= 0.0000, Training Accuracy= 0.9937, Test Accuracy= 0.9727\n",
      "Step 5080, Minibatch Loss= 0.0001, Training Accuracy= 0.9913, Test Accuracy= 0.9314\n",
      "Step 5090, Minibatch Loss= 0.0000, Training Accuracy= 0.9936, Test Accuracy= 0.9266\n",
      "Step 5100, Minibatch Loss= 0.0001, Training Accuracy= 0.9922, Test Accuracy= 0.9836\n",
      "Step 5110, Minibatch Loss= 0.0000, Training Accuracy= 0.9939, Test Accuracy= 0.9342\n",
      "Step 5120, Minibatch Loss= 0.0001, Training Accuracy= 0.9918, Test Accuracy= 0.9469\n",
      "Step 5130, Minibatch Loss= 0.0001, Training Accuracy= 0.9919, Test Accuracy= 0.9483\n",
      "Step 5140, Minibatch Loss= 0.0000, Training Accuracy= 0.9944, Test Accuracy= 0.9485\n",
      "Step 5150, Minibatch Loss= 0.0000, Training Accuracy= 0.9941, Test Accuracy= 0.9453\n",
      "Step 5160, Minibatch Loss= 0.0001, Training Accuracy= 0.9909, Test Accuracy= 0.9273\n",
      "Step 5170, Minibatch Loss= 0.0000, Training Accuracy= 0.9940, Test Accuracy= 0.9620\n",
      "Step 5180, Minibatch Loss= 0.0001, Training Accuracy= 0.9920, Test Accuracy= 0.9665\n",
      "Step 5190, Minibatch Loss= 0.0001, Training Accuracy= 0.9903, Test Accuracy= 0.9275\n",
      "Step 5200, Minibatch Loss= 0.0001, Training Accuracy= 0.9902, Test Accuracy= 0.9854\n",
      "Step 5210, Minibatch Loss= 0.0001, Training Accuracy= 0.9905, Test Accuracy= 0.9235\n",
      "Step 5220, Minibatch Loss= 0.0000, Training Accuracy= 0.9930, Test Accuracy= 0.9722\n",
      "Step 5230, Minibatch Loss= 0.0000, Training Accuracy= 0.9944, Test Accuracy= 0.9557\n",
      "Step 5240, Minibatch Loss= 0.0001, Training Accuracy= 0.9911, Test Accuracy= 0.9577\n",
      "Step 5250, Minibatch Loss= 0.0001, Training Accuracy= 0.9919, Test Accuracy= 0.9425\n",
      "Step 5260, Minibatch Loss= 0.0000, Training Accuracy= 0.9935, Test Accuracy= 0.9505\n",
      "Step 5270, Minibatch Loss= 0.0000, Training Accuracy= 0.9941, Test Accuracy= 0.9552\n",
      "Step 5280, Minibatch Loss= 0.0000, Training Accuracy= 0.9931, Test Accuracy= 0.9291\n",
      "Step 5290, Minibatch Loss= 0.0001, Training Accuracy= 0.9911, Test Accuracy= 0.9277\n",
      "Step 5300, Minibatch Loss= 0.0001, Training Accuracy= 0.9919, Test Accuracy= 0.9849\n",
      "Step 5310, Minibatch Loss= 0.0001, Training Accuracy= 0.9904, Test Accuracy= 0.9390\n",
      "Step 5320, Minibatch Loss= 0.0000, Training Accuracy= 0.9934, Test Accuracy= 0.9470\n",
      "Step 5330, Minibatch Loss= 0.0001, Training Accuracy= 0.9928, Test Accuracy= 0.9580\n",
      "Step 5340, Minibatch Loss= 0.0000, Training Accuracy= 0.9939, Test Accuracy= 0.9416\n",
      "Step 5350, Minibatch Loss= 0.0000, Training Accuracy= 0.9937, Test Accuracy= 0.9456\n",
      "Step 5360, Minibatch Loss= 0.0000, Training Accuracy= 0.9949, Test Accuracy= 0.9430\n",
      "Step 5370, Minibatch Loss= 0.0001, Training Accuracy= 0.9896, Test Accuracy= 0.9300\n",
      "Step 5380, Minibatch Loss= 0.0000, Training Accuracy= 0.9930, Test Accuracy= 0.9408\n",
      "Step 5390, Minibatch Loss= 0.0001, Training Accuracy= 0.9907, Test Accuracy= 0.9532\n",
      "Step 5400, Minibatch Loss= 0.0001, Training Accuracy= 0.9929, Test Accuracy= 0.9680\n",
      "Step 5410, Minibatch Loss= 0.0001, Training Accuracy= 0.9898, Test Accuracy= 0.9828\n",
      "Step 5420, Minibatch Loss= 0.0001, Training Accuracy= 0.9913, Test Accuracy= 0.9233\n",
      "Step 5430, Minibatch Loss= 0.0001, Training Accuracy= 0.9915, Test Accuracy= 0.9373\n",
      "Step 5440, Minibatch Loss= 0.0001, Training Accuracy= 0.9919, Test Accuracy= 0.9169\n",
      "Step 5450, Minibatch Loss= 0.0000, Training Accuracy= 0.9930, Test Accuracy= 0.9272\n",
      "Step 5460, Minibatch Loss= 0.0000, Training Accuracy= 0.9946, Test Accuracy= 0.9222\n",
      "Step 5470, Minibatch Loss= 0.0000, Training Accuracy= 0.9942, Test Accuracy= 0.9360\n",
      "Step 5480, Minibatch Loss= 0.0001, Training Accuracy= 0.9914, Test Accuracy= 0.9351\n",
      "Step 5490, Minibatch Loss= 0.0000, Training Accuracy= 0.9936, Test Accuracy= 0.9179\n",
      "Step 5500, Minibatch Loss= 0.0001, Training Accuracy= 0.9909, Test Accuracy= 0.9340\n",
      "Step 5510, Minibatch Loss= 0.0002, Training Accuracy= 0.9860, Test Accuracy= 0.9015\n",
      "Step 5520, Minibatch Loss= 0.0000, Training Accuracy= 0.9944, Test Accuracy= 0.9524\n",
      "Step 5530, Minibatch Loss= 0.0001, Training Accuracy= 0.9885, Test Accuracy= 0.9487\n",
      "Step 5540, Minibatch Loss= 0.0002, Training Accuracy= 0.9847, Test Accuracy= 0.9072\n",
      "Step 5550, Minibatch Loss= 0.0001, Training Accuracy= 0.9894, Test Accuracy= 0.9530\n",
      "Step 5560, Minibatch Loss= 0.0003, Training Accuracy= 0.9838, Test Accuracy= 0.9415\n",
      "Step 5570, Minibatch Loss= 0.0001, Training Accuracy= 0.9919, Test Accuracy= 0.9045\n",
      "Step 5580, Minibatch Loss= 0.0001, Training Accuracy= 0.9905, Test Accuracy= 0.9233\n",
      "Step 5590, Minibatch Loss= 0.0001, Training Accuracy= 0.9915, Test Accuracy= 0.9421\n",
      "Step 5600, Minibatch Loss= 0.0000, Training Accuracy= 0.9931, Test Accuracy= 0.9520\n",
      "Step 5610, Minibatch Loss= 0.0001, Training Accuracy= 0.9899, Test Accuracy= 0.9284\n",
      "Step 5620, Minibatch Loss= 0.0000, Training Accuracy= 0.9937, Test Accuracy= 0.9327\n",
      "Step 5630, Minibatch Loss= 0.0000, Training Accuracy= 0.9937, Test Accuracy= 0.9353\n",
      "Step 5640, Minibatch Loss= 0.0000, Training Accuracy= 0.9940, Test Accuracy= 0.9362\n",
      "Step 5650, Minibatch Loss= 0.0000, Training Accuracy= 0.9941, Test Accuracy= 0.9392\n",
      "Step 5660, Minibatch Loss= 0.0001, Training Accuracy= 0.9900, Test Accuracy= 0.9342\n",
      "Step 5670, Minibatch Loss= 0.0000, Training Accuracy= 0.9931, Test Accuracy= 0.9288\n",
      "Step 5680, Minibatch Loss= 0.0001, Training Accuracy= 0.9915, Test Accuracy= 0.9258\n",
      "Step 5690, Minibatch Loss= 0.0001, Training Accuracy= 0.9925, Test Accuracy= 0.9352\n",
      "Step 5700, Minibatch Loss= 0.0002, Training Accuracy= 0.9852, Test Accuracy= 0.8976\n",
      "Step 5710, Minibatch Loss= 0.0000, Training Accuracy= 0.9936, Test Accuracy= 0.9270\n",
      "Step 5720, Minibatch Loss= 0.0001, Training Accuracy= 0.9903, Test Accuracy= 0.9282\n",
      "Step 5730, Minibatch Loss= 0.0000, Training Accuracy= 0.9944, Test Accuracy= 0.9195\n",
      "Step 5740, Minibatch Loss= 0.0001, Training Accuracy= 0.9914, Test Accuracy= 0.9321\n",
      "Step 5750, Minibatch Loss= 0.0000, Training Accuracy= 0.9939, Test Accuracy= 0.9310\n",
      "Step 5760, Minibatch Loss= 0.0001, Training Accuracy= 0.9918, Test Accuracy= 0.9291\n",
      "Step 5770, Minibatch Loss= 0.0000, Training Accuracy= 0.9939, Test Accuracy= 0.9349\n",
      "Step 5780, Minibatch Loss= 0.0000, Training Accuracy= 0.9936, Test Accuracy= 0.9303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5790, Minibatch Loss= 0.0001, Training Accuracy= 0.9914, Test Accuracy= 0.9172\n",
      "Step 5800, Minibatch Loss= 0.0000, Training Accuracy= 0.9935, Test Accuracy= 0.9318\n",
      "Step 5810, Minibatch Loss= 0.0000, Training Accuracy= 0.9934, Test Accuracy= 0.9169\n",
      "Step 5820, Minibatch Loss= 0.0001, Training Accuracy= 0.9915, Test Accuracy= 0.9386\n",
      "Step 5830, Minibatch Loss= 0.0001, Training Accuracy= 0.9911, Test Accuracy= 0.9234\n",
      "Step 5840, Minibatch Loss= 0.0000, Training Accuracy= 0.9935, Test Accuracy= 0.9154\n",
      "Step 5850, Minibatch Loss= 0.0001, Training Accuracy= 0.9917, Test Accuracy= 0.9326\n",
      "Step 5860, Minibatch Loss= 0.0000, Training Accuracy= 0.9944, Test Accuracy= 0.9286\n",
      "Step 5870, Minibatch Loss= 0.0000, Training Accuracy= 0.9940, Test Accuracy= 0.9315\n",
      "Step 5880, Minibatch Loss= 0.0001, Training Accuracy= 0.9919, Test Accuracy= 0.9289\n",
      "Step 5890, Minibatch Loss= 0.0000, Training Accuracy= 0.9932, Test Accuracy= 0.9182\n",
      "Step 5900, Minibatch Loss= 0.0000, Training Accuracy= 0.9946, Test Accuracy= 0.9206\n",
      "Step 5910, Minibatch Loss= 0.0000, Training Accuracy= 0.9946, Test Accuracy= 0.9276\n",
      "Step 5920, Minibatch Loss= 0.0001, Training Accuracy= 0.9914, Test Accuracy= 0.9314\n",
      "Step 5930, Minibatch Loss= 0.0000, Training Accuracy= 0.9938, Test Accuracy= 0.9079\n",
      "Step 5940, Minibatch Loss= 0.0001, Training Accuracy= 0.9920, Test Accuracy= 0.9253\n",
      "Step 5950, Minibatch Loss= 0.0001, Training Accuracy= 0.9918, Test Accuracy= 0.9296\n",
      "Step 5960, Minibatch Loss= 0.0000, Training Accuracy= 0.9943, Test Accuracy= 0.9182\n",
      "Step 5970, Minibatch Loss= 0.0001, Training Accuracy= 0.9924, Test Accuracy= 0.9225\n",
      "Step 5980, Minibatch Loss= 0.0000, Training Accuracy= 0.9934, Test Accuracy= 0.9310\n",
      "Step 5990, Minibatch Loss= 0.0000, Training Accuracy= 0.9938, Test Accuracy= 0.9212\n",
      "Step 6000, Minibatch Loss= 0.0001, Training Accuracy= 0.9918, Test Accuracy= 0.9294\n",
      "Step 6010, Minibatch Loss= 0.0000, Training Accuracy= 0.9939, Test Accuracy= 0.9310\n",
      "Step 6020, Minibatch Loss= 0.0000, Training Accuracy= 0.9946, Test Accuracy= 0.9250\n",
      "Step 6030, Minibatch Loss= 0.0001, Training Accuracy= 0.9924, Test Accuracy= 0.9256\n",
      "Step 6040, Minibatch Loss= 0.0001, Training Accuracy= 0.9921, Test Accuracy= 0.9193\n",
      "Step 6050, Minibatch Loss= 0.0000, Training Accuracy= 0.9948, Test Accuracy= 0.9325\n",
      "Step 6060, Minibatch Loss= 0.0001, Training Accuracy= 0.9917, Test Accuracy= 0.9223\n",
      "Step 6070, Minibatch Loss= 0.0001, Training Accuracy= 0.9904, Test Accuracy= 0.9337\n",
      "Step 6080, Minibatch Loss= 0.0001, Training Accuracy= 0.9905, Test Accuracy= 0.9063\n",
      "Step 6090, Minibatch Loss= 0.0000, Training Accuracy= 0.9936, Test Accuracy= 0.9154\n",
      "Step 6100, Minibatch Loss= 0.0001, Training Accuracy= 0.9929, Test Accuracy= 0.9301\n",
      "Step 6110, Minibatch Loss= 0.0001, Training Accuracy= 0.9916, Test Accuracy= 0.9319\n",
      "Step 6120, Minibatch Loss= 0.0001, Training Accuracy= 0.9923, Test Accuracy= 0.9182\n",
      "Step 6130, Minibatch Loss= 0.0001, Training Accuracy= 0.9921, Test Accuracy= 0.9237\n",
      "Step 6140, Minibatch Loss= 0.0000, Training Accuracy= 0.9937, Test Accuracy= 0.9268\n",
      "Step 6150, Minibatch Loss= 0.0000, Training Accuracy= 0.9946, Test Accuracy= 0.9207\n",
      "Step 6160, Minibatch Loss= 0.0000, Training Accuracy= 0.9941, Test Accuracy= 0.9129\n",
      "Step 6170, Minibatch Loss= 0.0000, Training Accuracy= 0.9934, Test Accuracy= 0.9330\n",
      "Step 6180, Minibatch Loss= 0.0001, Training Accuracy= 0.9907, Test Accuracy= 0.9088\n",
      "Step 6190, Minibatch Loss= 0.0001, Training Accuracy= 0.9904, Test Accuracy= 0.9212\n",
      "Step 6200, Minibatch Loss= 0.0000, Training Accuracy= 0.9943, Test Accuracy= 0.9265\n",
      "Step 6210, Minibatch Loss= 0.0000, Training Accuracy= 0.9936, Test Accuracy= 0.9133\n",
      "Step 6220, Minibatch Loss= 0.0001, Training Accuracy= 0.9906, Test Accuracy= 0.9217\n",
      "Step 6230, Minibatch Loss= 0.0000, Training Accuracy= 0.9938, Test Accuracy= 0.9108\n",
      "Step 6240, Minibatch Loss= 0.0000, Training Accuracy= 0.9932, Test Accuracy= 0.9125\n",
      "Step 6250, Minibatch Loss= 0.0000, Training Accuracy= 0.9939, Test Accuracy= 0.9339\n",
      "Step 6260, Minibatch Loss= 0.0000, Training Accuracy= 0.9935, Test Accuracy= 0.9265\n",
      "Step 6270, Minibatch Loss= 0.0001, Training Accuracy= 0.9920, Test Accuracy= 0.9096\n",
      "Step 6280, Minibatch Loss= 0.0000, Training Accuracy= 0.9938, Test Accuracy= 0.9223\n",
      "Step 6290, Minibatch Loss= 0.0001, Training Accuracy= 0.9922, Test Accuracy= 0.9236\n",
      "Step 6300, Minibatch Loss= 0.0000, Training Accuracy= 0.9943, Test Accuracy= 0.9215\n",
      "Step 6310, Minibatch Loss= 0.0000, Training Accuracy= 0.9938, Test Accuracy= 0.9290\n",
      "Step 6320, Minibatch Loss= 0.0000, Training Accuracy= 0.9941, Test Accuracy= 0.9170\n",
      "Step 6330, Minibatch Loss= 0.0001, Training Accuracy= 0.9898, Test Accuracy= 0.9088\n",
      "Step 6340, Minibatch Loss= 0.0000, Training Accuracy= 0.9944, Test Accuracy= 0.9215\n",
      "Step 6350, Minibatch Loss= 0.0001, Training Accuracy= 0.9921, Test Accuracy= 0.9064\n",
      "Step 6360, Minibatch Loss= 0.0000, Training Accuracy= 0.9937, Test Accuracy= 0.9100\n",
      "Step 6370, Minibatch Loss= 0.0001, Training Accuracy= 0.9898, Test Accuracy= 0.9402\n",
      "Step 6380, Minibatch Loss= 0.0001, Training Accuracy= 0.9905, Test Accuracy= 0.8938\n",
      "Step 6390, Minibatch Loss= 0.0001, Training Accuracy= 0.9923, Test Accuracy= 0.9182\n",
      "Step 6400, Minibatch Loss= 0.0000, Training Accuracy= 0.9935, Test Accuracy= 0.9197\n",
      "Step 6410, Minibatch Loss= 0.0000, Training Accuracy= 0.9938, Test Accuracy= 0.9270\n",
      "Step 6420, Minibatch Loss= 0.0000, Training Accuracy= 0.9931, Test Accuracy= 0.9141\n",
      "Step 6430, Minibatch Loss= 0.0000, Training Accuracy= 0.9941, Test Accuracy= 0.9190\n",
      "Step 6440, Minibatch Loss= 0.0000, Training Accuracy= 0.9940, Test Accuracy= 0.9330\n",
      "Step 6450, Minibatch Loss= 0.0000, Training Accuracy= 0.9942, Test Accuracy= 0.9125\n",
      "Step 6460, Minibatch Loss= 0.0000, Training Accuracy= 0.9937, Test Accuracy= 0.9221\n",
      "Step 6470, Minibatch Loss= 0.0001, Training Accuracy= 0.9907, Test Accuracy= 0.9116\n",
      "Step 6480, Minibatch Loss= 0.0001, Training Accuracy= 0.9922, Test Accuracy= 0.9313\n",
      "Step 6490, Minibatch Loss= 0.0001, Training Accuracy= 0.9878, Test Accuracy= 0.9077\n",
      "Step 6500, Minibatch Loss= 0.0001, Training Accuracy= 0.9922, Test Accuracy= 0.9303\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session(graph=graph, config=config) as sess:\n",
    "    init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    sess.run(init)\n",
    "    for step in range(1, training_epochs+1):\n",
    "        Xt, Yt = next_batch(batch_size, X0, Y0)\n",
    "        batch_x, batch_y = Xt,Yt\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, is_training: True})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={\n",
    "                X: batch_x, Y: batch_y, is_training: False})\n",
    "            test_data = testX\n",
    "            test_label = testY\n",
    "            val_acc = sess.run(accuracy, feed_dict={X: test_data, Y: test_label, is_training: False})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.4f}\".format(acc) + \", Test Accuracy= \" + \\\n",
    "                  \"{:.4f}\".format(val_acc))\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                save_path = saver.save(sess, \"/home/rubensvectomobile/BOVESPA/real/model.ckpt\")\n",
    "                print(\"Model saved in path: %s\" % save_path)\n",
    "    pred00 = sess.run([prediction], feed_dict={X: test_data, is_training: False})\n",
    "    pred01 = sess.run([prediction2], feed_dict={X: test_data, is_training: False})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph, config=config) as session:\n",
    "    ckpt = \"/home/rubensvectomobile/BOVESPA/real/model.ckpt\"\n",
    "    saver.restore(session, ckpt)\n",
    "    pred00 = session.run([prediction], feed_dict={X: test_data, is_training: False})\n",
    "    pred01 = session.run([prediction2], feed_dict={X: test_data, is_training: False})\n",
    "    pred02 = session.run([prediction2], feed_dict={X: trainX.reshape(-1,look_back,1), is_training: False})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.array(pred02).reshape(-1,1)[-200:])\n",
    "plt.plot(np.array(trainX).reshape(-1,)[-200:],c='black')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.array(pred01).reshape(-1,1))\n",
    "plt.plot(np.array(testY).reshape(-1,),c='black')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.show()\n",
    "\n",
    "x=list(range(0,len(pred00[0])))\n",
    "y1=np.array(pred01).reshape(1,-1)[0]+2*np.std(np.array(pred01).reshape(1,-1))\n",
    "y2=np.array(pred01).reshape(1,-1)[0]-2*np.std(np.array(pred01).reshape(1,-1))\n",
    "fig, ax1 = plt.subplots(1, 1, sharex=True)\n",
    "ax1.plot(np.array(pred01).reshape(1,-1)[0],'--',color='blue',alpha=0.5)\n",
    "ax1.fill_between(x, y1, y2,color='blue',alpha=0.3)\n",
    "ax1.plot(x,np.array(testY).reshape(-1,),c='red')\n",
    "plt.xlabel('Days')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print('R2',r2_score(testY.reshape(1,-1)[0],np.array(pred01).reshape(1,-1)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=testX[-1].reshape(-1,look_back,1)\n",
    "prev=[]\n",
    "with tf.Session(graph=graph, config=config) as session:\n",
    "    ckpt = \"/home/rubensvectomobile/BOVESPA/real/model.ckpt\"\n",
    "    saver.restore(session, ckpt)\n",
    "    for i in range(0,21):\n",
    "        pred02 = session.run([prediction2], feed_dict={X: x_test, is_training: False})[0][0]\n",
    "        prev.append(pred02)\n",
    "        #print(pred02)\n",
    "        x_test=np.concatenate([x_test[0][1:look_back],[pred02]],axis=0).reshape(-1,look_back,1)\n",
    "        #print(x_test)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(testY)[0:limit].reshape(-1,)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(prev)[0:limit].reshape(-1,1))\n",
    "#plt.plot(np.array(testY)[0:limit].reshape(-1,),c='black')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.show()\n",
    "#real=(np.array(testY)[0:limit].reshape(-1,)[-1]/np.array(testY)[0:limit].reshape(-1,)[0]-1)*100\n",
    "prevista=(np.array(prev)[0:limit].reshape(-1,1)[-1]/np.array(prev)[0:limit].reshape(-1,1)[0]-1)*100\n",
    "#print('Variao Real',\"%.2f\" % real + '%')\n",
    "print('Variao Prevista',[\"%.2f\" % prevista+'%'])\n",
    "#print('Erro',[\"%.2f\" % float((prevista-real))+'%'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
